2025-05-15 15:47:39.359 | INFO     | main:websocket_endpoint:36 - WebSocket connection accepted from 127.0.0.1:54328
2025-05-15 15:47:42.823 | INFO     | main:websocket_endpoint:60 - WebSocket connection disconnected from 127.0.0.1:54328
2025-05-15 15:47:42.823 | INFO     | main:websocket_endpoint:75 - Cleaned up resources for 127.0.0.1:54328
2025-05-15 15:47:43.230 | INFO     | main:websocket_endpoint:36 - WebSocket connection accepted from 127.0.0.1:54336
2025-05-15 15:48:45.763 | INFO     | main:websocket_endpoint:56 - Received message from 127.0.0.1:54336: æˆ‘æƒ³å­¦ä¹ å…³äºloraçš„å¤§æ¨¡å‹é¡¹ç›®ï¼Œç»™æˆ‘ä»‹ç»ä¸€ä¸ªï¼Œåˆ†æä»£ç çš„uml
2025-05-15 15:48:45.763 | INFO     | agents.umlagent:create_initial_plan:214 - Creating initial plan with ID: plan_1747295325
2025-05-15 15:48:51.631 | INFO     | agents.umlagent:create_initial_plan:243 -  ç»“æœä¸º:  `å·¥å…·:planning`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
Plan created successfully with ID: plan_1747295325

Plan: åˆ†æå…³äºLoRAçš„å¤§æ¨¡å‹é¡¹ç›®å¹¶ç”ŸæˆUMLå›¾ (ID: plan_1747295325)
==================================================

Progress: 0/4 steps completed (0.0%)
Status: 0 completed, 0 in progress, 0 blocked, 4 not started

Steps:
0. [ ] æœç´¢ä¸€ä¸ªå…³äºLoRAçš„å¤§æ¨¡å‹é¡¹ç›®
1. [ ] å…‹éš†æ‰¾åˆ°çš„GitHubä»“åº“åˆ°æœ¬åœ°
2. [ ] ç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLç±»å›¾
3. [ ] æä¾›é¡¹ç›®ç®€ä»‹å’ŒUMLå›¾ç»™ç”¨æˆ·

2025-05-15 15:48:51.633 | INFO     | agents.base:run:119 - websocket initialized finish, state:<starlette.datastructures.State object at 0x0000018E2CB27FE0>
2025-05-15 15:48:51.633 | INFO     | agents.base:run:129 - Executing step 1/20
2025-05-15 15:48:54.783 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: è®¡åˆ’å·²åˆ›å»ºï¼Œä¸‹ä¸€æ­¥æ˜¯æ‰§è¡Œç¬¬ä¸€ä¸ªæ­¥éª¤ï¼šæœç´¢ä¸€ä¸ªå…³äºLoRAçš„å¤§æ¨¡å‹é¡¹ç›®ã€‚
2025-05-15 15:48:54.785 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:48:54.785 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['baidu_search']
2025-05-15 15:48:54.786 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"query": "lora å¤§æ¨¡å‹ é¡¹ç›® github"}']
2025-05-15 15:48:56.042 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'baidu_search' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:baidu_search`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
[{'title': 'lora Â· GitHub Topics Â· GitHub', 'abstract': 'lora Â· GitHub Topics Â· GitHub\n\n2025å¹´4æœˆ28æ—¥Code for loralib, an implementation of "LoRA: Low-Rank Adaptation of Large Language Models" deep-learningpytorchloralanguage-modeladaptationrobertalow-rankgpt-2gpt-3deberta UpdatedDec 17, 2024 Python BELLE: Be Everyone\'s Large Language model Engine(å¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹)', 'url': 'http://www.baidu.com/link?url=7_VX5p-yxJ3kuId9iChvpGVU_9em_qPQL20QSHFIj0Q0YrLcPPGKAtJM9hcM8t2R', 'rank': 1}, {'title': 'ç¦»è°±åˆ°ä¼˜ç§€!ä»é›¶æ„å»ºå¤§æ¨¡å‹çš„é¡¹ç›®å¼€æºäº†!_githubå¤§æ¨¡å‹é¡¹ç›®-CSDNåšå®¢', 'abstract': 'ç¦»è°±åˆ°ä¼˜ç§€!ä»é›¶æ„å»ºå¤§æ¨¡å‹çš„é¡¹ç›®å¼€æºäº†!_githubå¤§æ¨¡å‹é¡¹ç›®-CSDNåšå®¢\n\n\n\n\n\n\n\n\n\n2025å¹´2æœˆ20æ—¥å‘å¸ƒäº†å¤§æ¨¡å‹æç®€ç»“æ„,æ•°æ®é›†æ¸…æ´—å’Œé¢„å¤„ç†ã€ç›‘ç£é¢„è®­ç»ƒ(Pretrain)ã€æœ‰ç›‘ç£æŒ‡ä»¤å¾®è°ƒ(SFT)ã€ä½ç§©è‡ªé€‚åº”(LoRA) å¾®è°ƒ,æ— å¥–åŠ±å¼ºåŒ–å­¦ä¹ ç›´æ¥åå¥½å¯¹é½(DPO)çš„å…¨é˜¶æ®µä»£ç ,ä¹ŸåŒ…å«æ‹“å±•å…±äº«æ··åˆä¸“å®¶(MoE) çš„ç¨€ç–æ¨¡å‹; è¿™ä¸ä»…æ˜¯ä¸€ä¸ªå¼€æºæ¨¡å‹çš„å®ç°,ä¹Ÿæ˜¯å…¥é—¨å¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ•™ç¨‹ã€‚ å¸Œæœ›æ­¤é¡¹ç›®èƒ½ä¸ºç ”ç©¶è€…æä¾›ä¸€ä¸ªæŠ›ç –å¼•ç‰çš„å…¥...\n\n\nCSDNåšå®¢\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=Iw7UZ1ubf7hhesAHVzE_w-_zyRt3m7yxI_rdRSvy0qPn6NJAjbyvh-ZS-3_mjdmrXMRTUzg4gDzL8sVAXunBCOyChDBAQBl-ZovcHEWCAau', 'rank': 2}, {'title': 'å¤§å®¶è¿˜åœ¨æœè®­ç»ƒä¸€ä¸ªLORAæ¨¡å‹è¦å¤šä¹…githubä¼˜ç§€å¼€æºé¡¹ç›®githubå¥½ç©çš„é¡¹ç›®loraæ˜¯ä»€ä¹ˆaiæ¨¡å‹githubä¸Šæœ‰å“ªäº›å¥½çš„å¼€æºé¡¹ç›®githubçƒ­é—¨å¼€æºé¡¹ç›®githubæ–°æ‰‹å¼€æºé¡¹ç›®æ¨ègithubçƒ­é—¨é¡¹ç›®', 'abstract': 'å¤§å®¶è¿˜åœ¨æœè®­ç»ƒä¸€ä¸ªLORAæ¨¡å‹è¦å¤šä¹…githubä¼˜ç§€å¼€æºé¡¹ç›®githubå¥½ç©çš„é¡¹ç›®loraæ˜¯ä»€ä¹ˆaiæ¨¡å‹githubä¸Šæœ‰å“ªäº›å¥½çš„å¼€æºé¡¹ç›®githubçƒ­é—¨å¼€æºé¡¹ç›®githubæ–°æ‰‹å¼€æºé¡¹ç›®æ¨ègithubçƒ­é—¨é¡¹ç›®', 'url': '/s?wd=%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AALORA%E6%A8%A1%E5%9E%8B%E8%A6%81%E5%A4%9A%E4%B9%85&usm=7&ie=utf-8&rsv_pq=c3545d8a00302989&oq=lora%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%20%E9%A1%B9%E7%9B%AE%20github&rsv_t=537dbPJNY46xoAGBfjqwQ97wVTt5lDa7%2BTcMAADcUEyNq8msZgLNypcwF90&rsf=101636803&rsv_dl=0_prs_28608_1', 'rank': 3}, {'title': 'ã€ŒGithubä¸€å‘¨çƒ­ç‚¹20ã€æœ¬åœ°å¤§æ¨¡å‹è¿è¡Œå·¥å…·ã€å¼€æºCRMç­‰5ä¸ªç«çˆ†é¡¹ç›®', 'abstract': 'ã€ŒGithubä¸€å‘¨çƒ­ç‚¹20ã€æœ¬åœ°å¤§æ¨¡å‹è¿è¡Œå·¥å…·ã€å¼€æºCRMç­‰5ä¸ªç«çˆ†é¡¹ç›®\n\n\n\n\n\n\n\n\n\n2024å¹´4æœˆ28æ—¥GitHub é“¾æ¥:https://github.com/hiyouga/LLaMA-Factory ä¸Šå‘¨Star æ•°:3000+ LLaMA-Factoryæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶,é›†æˆäº†ä¸€å¥—å…ˆè¿›çš„é«˜æ•ˆè®­ç»ƒæ–¹æ³•ã€‚å®ƒå…è®¸ç”¨æˆ·é€šè¿‡å†…ç½®çš„Web UIçµæ´»å®šåˆ¶100å¤šä¸ªLLMsçš„å¾®è°ƒ,è€Œæ— éœ€ç¼–å†™ä»£ç ã€‚ é«˜æ•ˆçš„ fine-tuning å¯¹äºå°†å¤§å‹è¯­è¨€æ¨¡å‹è½åœ°å¼è‡³å…³é‡è¦çš„,å¾ˆå¤šæ—¶å€™å¾®è°ƒæ‰€å¸¦æ¥çš„æ•ˆæœå¯ä»¥è®©å¤§è¯­è¨€æ¨¡...\n\n\nçŸ¥ä¹\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ\n\n\n\nLORA:å¤§æ¨¡å‹è½»é‡çº§å¾®è°ƒ ', 'url': 'http://www.baidu.com/link?url=PymthoqPoxS7HVpPbBR4e6TAd0glbjBa03g2_nqr9mBjKe4Zr6b2kyf2N8OA0sbd', 'rank': 4}, {'title': 'GitHubæ˜æ˜Ÿé¡¹ç›®:ç‹‚æ½40k starçš„å¤§æ¨¡å‹å¼€æºæ•™ç¨‹!-CSDNåšå®¢', 'abstract': 'GitHubæ˜æ˜Ÿé¡¹ç›®:ç‹‚æ½40k starçš„å¤§æ¨¡å‹å¼€æºæ•™ç¨‹!-CSDNåšå®¢\n\n\n\n\n\n\n\n\n\n6å¤©å‰ğŸ¥± LazyMergekit:è½»æ¾ä½¿ç”¨MergeKitä¸€é”®åˆå¹¶æ¨¡å‹,colab âš¡ AutoGGUF:ä¸€é”®å°†å¤§è¯­è¨€æ¨¡å‹(LLMs)é‡åŒ–ä¸ºGGUFæ ¼å¼,colab ğŸŒ³ Model Family Tree:å¯è§†åŒ–è¢«åˆå¹¶æ¨¡å‹çš„å®¶æ—æ ‘,colab Fine-tuning: ä½¿ç”¨Colab å¯¹Llama2 è¿›è¡Œ fine-tuning:æ–‡ç« ,colab ä½¿ç”¨Axolotlå¯¹ LLMs è¿›è¡Œ fine-tuning:æ–‡ç« ,colab ...\n\n\nCSDNåšå®¢\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=lMAEKW9tkDRFF78mYiO-VF2o92mbbmYMLGKx2hCkVcqwS6QoJVUYHxnsStOcTmz1EeAH_YtuLyLCEoDjFJH_QqT1NnnW4pnN-HyI68G3jHW', 'rank': 5}, {'title': 'lora å¤§æ¨¡å‹ é¡¹ç›® github - èŠä¸€ä¸‹æ›´å¤šç²¾å½©', 'abstract': 'lora å¤§æ¨¡å‹ é¡¹ç›® github - èŠä¸€ä¸‹æ›´å¤šç²¾å½©githubåŠ©æ‰‹1.3ä¸‡äººèŠè¿‡\n\n\n\ngithubåŠ©æ‰‹1.3ä¸‡äººèŠè¿‡\n\nGITHUBä¸“å®¶724äººèŠè¿‡\n\nGITHUBæŒ‡å—14äººèŠè¿‡\n\n\n\n\n\n\nä½ å¥½ï¼Œæˆ‘æ˜¯GitHubä¸“å®¶åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„GitHubä½¿ç”¨ç»éªŒå’Œä¸“ä¸šæŠ€èƒ½ã€‚å¾ˆé«˜å…´ä¸ä½ äº¤æµï¼Œè¯·é—®æœ‰ä»€ä¹ˆå…³äºGitHubçš„é—®é¢˜æˆ–éœ€æ±‚ï¼Œæˆ‘å¯ä»¥å¸®ä½ è§£ç­”æˆ–ååŠ©è§£å†³å—ï¼Ÿ\n\nä½ å¥½ï¼Œæˆ‘æ˜¯GITHUBæ¢ç´¢è€…ï¼Œå¯ä»¥å¸®ä½ å‘ç°GITHUBä¸Šæœ€æ–°æµè¡Œçš„å¼€æºé¡¹ç›®ï¼Œå¹¶ä¸ºä½ å½’çº³æ€»ç»“ï¼Œä½ æƒ³äº†è§£å“ªæ–¹é¢çš„é¡¹ç›®å‘¢ï¼Ÿ\n\næ‚¨å¥½ï¼æˆ‘æ˜¯GITHUBæŒ‡å—å®æˆ˜ä¸“å®¶åŠ©æ‰‹ï¼Œå¯ä»¥ç”¨AIé˜…è¯»å¤§æ¨¡å‹æå–å¹¶æµè§ˆGITHUBå¹³å°ä¿¡æ¯ï¼ŒåŒæ­¥ç¿»è¯‘ä¸å›½å†…çš„GITHU', 'url': 'http://www.baidu.com/link?url=Iw7UZ1ubf7hhesAHVzE_wzO19FgkzsIvY9Bc_pmMKUQOiL6Manem0V2aUU3NL8aNh11ZwSJX4Uxflp42j7iWHxptG5hGb5c3UJh5qQofnFQQxi3EDNG_RHjU52TvS0kqm-r3sSXXRdqXAIOu2mBopS7431_A_8JUlaHv0D4Y3OBUhIkAZqiLLVa_RCIt6ZtcswZV2KyEXhyEV3Mavt11aKgiB-zrqN3AgKCXYc8dej4cV4wnSWJbw-XHPHPPsUbYLhX-2TyxzfHjUqlEg1NXwPMwbEIthVD1QIKm4-jmM2ltZW3JoveUkQrH9GZDwfv-C7UXJZugaEJMeDWRcId1XatWC0D7gvndv0b9PpjIZkfuJpg6OU5LEhECFjrRTZKMlHWyLEJUB9CS321XViY_cAQcuFh-IKddzqtDprv-TontrWqsw7RLvrMTHHNWCc1zBa0EwrV0PVfRAOUFHwlhI6xcDsyPQjRR1LeCO331m8qJEJwPg4VYfWTxDYvno_oZjFBeYCpyK0xEN2XKYggMBSu4EhCvxgMS8ukBRd6D8SXdyArvdw3UcCCKdn3FK5CoOSkjj0vR9HY7_Q6TfgoEG_', 'rank': 6}, {'title': 'LoRA å¼•é¢†å¤šæ¨¡æ€æ¨¡å‹é©å‘½,å¤§æ¨¡å‹çš„å¾®è°ƒæ–¹æ¡ˆ', 'abstract': 'LoRA å¼•é¢†å¤šæ¨¡æ€æ¨¡å‹é©å‘½,å¤§æ¨¡å‹çš„å¾®è°ƒæ–¹æ¡ˆ\n\n\n\n\n\n\n\n\n\n2024å¹´4æœˆ28æ—¥å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆäº”ï¼‰-LoRAã€AdaLoRAã€QLoRAå¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆäº”ï¼‰-LoRA æ¨¡å‹å¾®è°ƒ ä¼˜åŒ–ä»£ç ï¼Œæ”¹è¿›ç²¾åº¦ï¼æˆ‘ä»¬çš„å¾®è°ƒä»£ç ç°å¯ä» GitHub çš„ llm-action é¡¹ç›®è·å–ï¼Œå…·ä½“ä½äº blip2_lora_int8_fine_tune.py æ–‡ä»¶ä¸­ã€‚å…³é”®æ­¥éª¤åŒ…æ‹¬ï¼š- å°†æ¨¡å‹ç²¾åº¦è°ƒæ•´ä¸º 8 ä½æ•´æ•°ã€‚- å¾®è°ƒæ¨¡å‹ä»¥æå‡æ€§èƒ½ã€‚\n\n\nITäº’è”äººç”Ÿ\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=PymthoqPoxS7HVpPbBR4eqYGhyetawki2qyHZRFgdQJhpaNOD6NoUmRg17kloXOOZC0wlzxlBOHvgfqsvMAuppRxkcB0KZCYH5s1ZFDDu-G', 'rank': 7}, {'title': 'S-LoRA:ä¸€ä¸ªGPUè¿è¡Œæ•°åƒå¤§æ¨¡å‹æˆä¸ºå¯èƒ½', 'abstract': 'S-LoRA:ä¸€ä¸ªGPUè¿è¡Œæ•°åƒå¤§æ¨¡å‹æˆä¸ºå¯èƒ½\n\n\n\n\n\n\n\n\n\n2023å¹´11æœˆ15æ—¥å¼ é‡å¹¶è¡Œå¯ä»¥å‡å°‘ä¸ºå¤§æ¨¡å‹æä¾›æœåŠ¡æ—¶æ¯ä¸ª GPU çš„å†…å­˜ä½¿ç”¨é‡å’Œå»¶è¿Ÿã€‚åœ¨æœ¬æ–‡è®¾ç½®ä¸­ï¼Œé¢å¤–çš„ LoRA é€‚é…å™¨å¼•å…¥äº†æ–°çš„æƒé‡çŸ©é˜µå’ŒçŸ©é˜µä¹˜æ³•ï¼Œè¿™å°±éœ€è¦ä¸ºè¿™äº›æ–°å¢é¡¹ç›®åˆ¶å®šæ–°çš„åˆ†åŒºç­–ç•¥ã€‚è¯„ä¼° æœ€åï¼Œç ”ç©¶è€…é€šè¿‡ä¸º Llama-7B/13B/30B/70B æä¾›æœåŠ¡æ¥è¯„ä¼° S-LoRAã€‚ç»“æœè¡¨æ˜ï¼ŒS-LoRA å¯ä»¥åœ¨å•ä¸ª GPU æˆ–å¤šä¸ª GPU ä¸Šä¸ºæ•°åƒä¸ª ...\n\n\næœºå™¨ä¹‹å¿ƒPro\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=PymthoqPoxS7HVpPbBR4eqYGhyetawki2qyHZRFgdQICFKdcLSxjHXJY_-fUc0zB6jr_oeRAAal2mBLB_ykUWRn6A77D9ibASR5s0aKLK0u', 'rank': 8}, {'title': 'lora å¤§æ¨¡å‹ é¡¹ç›® github\n\xa0-\xa0ç²¾é€‰ç¬”è®°', 'abstract': 'lora å¤§æ¨¡å‹ é¡¹ç›® github\n\xa0-\xa0ç²¾é€‰ç¬”è®°\n\n\n\n\n\n\n\n\n\nollamaä½¿ç”¨æŒ‡å—è¶…å…¨ç‰ˆèµ›say181èµ\n\n\n\n\n\n\nloralowrankadaptationoflargelanguagemodelsloraå¤§å‹è¯­è¨€æ¨¡å‹çš„ä½ç§©è‡ªé€‚åº”Snowman1èµ\n\n\n\n\n\n\nåªéœ€3ä¸ªè„šæœ¬å®ŒæˆåŸºäºllamafactoryçš„å¤§æ¨¡å‹è®­ç»ƒloraæƒé‡åˆå¹¶ä»¥åŠæ„å»ºæ¨ç†æœåŠ¡ç¨‹åºé”…25èµ\n\n\n\n\n\n\næ¨¡å‹å¾®è°ƒllamafactoryäºŒæ²§æµªä¹‹æ°´7èµ\n\n        æŸ¥çœ‹æ›´å¤šç¬”è®° >', 'url': 'http://www.baidu.com/link?url=5TbsTQFcj9Yikcb1oHcX0hhSlWvDCf-79FQZjvhZ6xx8IOFjly-161oOXTtRn7uReLXh6j_feOkKGrnCrl-foAhHwixu0TAOhqAEYM2SvHFvztgEjD-m2rK5JJk7N_p8Pb4GdulXa2B1ISTUJ5qyZl6AxF5eWaG7MF9_b6tchsLEtD23L7SVotxl6FOo2GVd', 'rank': 9}]
2025-05-15 15:48:56.045 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 0 as completed in plan plan_1747295325
2025-05-15 15:48:56.045 | INFO     | agents.base:run:129 - Executing step 2/20
2025-05-15 15:49:01.055 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: æˆ‘å·²ç»æ‰¾åˆ°äº†ä¸€ä¸ªå…³äºLoRAçš„å¤§æ¨¡å‹é¡¹ç›®ï¼Œä¸‹ä¸€æ­¥æ˜¯å…‹éš†è¿™ä¸ªGitHubä»“åº“åˆ°æœ¬åœ°ã€‚ç°åœ¨æˆ‘å°†æ‰§è¡Œè¿™ä¸€æ­¥éª¤ã€‚
2025-05-15 15:49:01.057 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:49:01.057 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['github_repo_cloner_ssh']
2025-05-15 15:49:01.058 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_name": "EdwardLeeCloud/LLM-LoRA"}']
2025-05-15 15:49:06.472 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'github_repo_cloner_ssh' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:github_repo_cloner_ssh`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
é”™è¯¯ï¼šé€šè¿‡ SSH å…‹éš†ä»“åº“ 'EdwardLeeCloud/LLM-LoRA' å¤±è´¥ã€‚
å‘½ä»¤é€€å‡ºç : 128
Git æ ‡å‡†é”™è¯¯è¾“å‡º:
Cloning into 'D:\deep_learning\codes\workspace\LLM-LoRA'...
ERROR: Repository not found.
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
Git æ ‡å‡†è¾“å‡º:

2025-05-15 15:49:06.472 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 1 as completed in plan plan_1747295325
2025-05-15 15:49:06.472 | INFO     | agents.base:run:129 - Executing step 3/20
2025-05-15 15:49:13.111 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: è™½ç„¶å…‹éš†ä»“åº“æ—¶é‡åˆ°äº†é”™è¯¯ï¼Œä½†æˆ‘å¯ä»¥å°è¯•å¦ä¸€ä¸ªé¡¹ç›®ã€‚æ ¹æ®æœç´¢ç»“æœï¼Œæˆ‘é€‰æ‹© 'hiyouga/LLaMA-Factory' ä½œä¸ºæ›¿ä»£é¡¹ç›®ã€‚ç°åœ¨æˆ‘å°†å…‹éš†è¿™ä¸ªGitHubä»“åº“åˆ°æœ¬åœ°ã€‚
2025-05-15 15:49:13.112 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:49:13.112 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['github_repo_cloner_ssh']
2025-05-15 15:49:13.114 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_name": "hiyouga/LLaMA-Factory"}']
2025-05-15 15:49:28.088 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'github_repo_cloner_ssh' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:github_repo_cloner_ssh`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
D:\deep_learning\codes\workspace\LLaMA-Factory
2025-05-15 15:49:28.088 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 2 as completed in plan plan_1747295325
2025-05-15 15:49:28.088 | INFO     | agents.base:run:129 - Executing step 4/20
2025-05-15 15:49:36.321 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: å·²æˆåŠŸå…‹éš† 'hiyouga/LLaMA-Factory' ä»“åº“åˆ°æœ¬åœ°ã€‚ä¸‹ä¸€æ­¥æ˜¯ç”Ÿæˆè¯¥é¡¹ç›®çš„UMLç±»å›¾ã€‚
2025-05-15 15:49:36.321 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:49:36.321 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['code_to_uml_generator_multilang']
2025-05-15 15:49:36.321 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_path": "D:\\\\deep_learning\\\\codes\\\\workspace\\\\LLaMA-Factory", "output_png_path": "D:\\\\deep_learning\\\\codes\\\\workspace\\\\LLaMA-Factory\\\\llama_factory_uml.png", "target_languages": ["python"]}']
2025-05-15 15:49:39.270 | INFO     | tools.uml:execute:696 - å‡†å¤‡é€šè¿‡ WebSocket å‘é€ UML å›¾ç‰‡ 'llama_factory_uml.png'ã€‚
2025-05-15 15:49:39.289 | INFO     | tools.uml:execute:711 - UML å›¾ç‰‡ 'llama_factory_uml.png' å·²é€šè¿‡ WebSocket å‘é€ (754155 å­—èŠ‚)ã€‚
2025-05-15 15:49:39.292 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'code_to_uml_generator_multilang' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:code_to_uml_generator_multilang`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
UML å›¾è¡¨å’Œæ–‡æœ¬æè¿°å·²æˆåŠŸç”Ÿæˆã€‚
PNG å›¾åƒä¿å­˜è·¯å¾„: 'D:\deep_learning\codes\workspace\LLaMA-Factory\llama_factory_uml.png'

---
UML å›¾è¡¨æ–‡æœ¬æè¿°å†…å®¹:
---
# UML å›¾è¡¨æ–‡æœ¬æè¿°

## Class: `AlpacaDatasetConverter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `converter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DatasetConverter`

### æ–¹æ³• (Methods)
- `__call__(self, example: dict[str, Any]) -> dict[str, Any]`

---

## Class: `ApolloArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### å±æ€§ (Attributes)
- `apollo_layerwise: bool`
- `apollo_proj: Literal['svd', 'random']`
- `apollo_proj_type: Literal['std', 'right', 'left']`
- `apollo_rank: int`
- `apollo_scale: float`
- `apollo_scale_front: bool`
- `apollo_scale_type: Literal['channel', 'tensor']`
- `apollo_target: str`
- `apollo_update_interval: int`
- `use_apollo: bool`

---

## Class: `AttentionFunction`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `constants`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `str`, `Enum`

### å±æ€§ (Attributes)
- `AUTO`
- `DISABLED`
- `FA2`
- `SDPA`

---

## Class: `AverageMeter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `misc`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `reset(self)`
- `update(self, val, n)`

---

## Class: `BAdamArgument`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### å±æ€§ (Attributes)
- `badam_mask_mode: Literal['adjacent', 'scatter']`
- `badam_mode: Literal['layer', 'ratio']`
- `badam_start_block: Optional[int]`
- `badam_switch_interval: Optional[int]`
- `badam_switch_mode: Optional[Literal['ascending', 'descending', 'random', 'fixed']]`
- `badam_update_ratio: float`
- `badam_verbose: int`
- `use_badam: bool`

---

## Class: `BaseEngine`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `base_engine`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ABC`

### å±æ€§ (Attributes)
- `can_generate: bool`
- `generating_args: dict[str, Any]`
- `model: Union['PreTrainedModel', 'AsyncLLMEngine']`
- `name: 'EngineName'`
- `template: 'Template'`
- `tokenizer: 'PreTrainedTokenizer'`

### æ–¹æ³• (Methods)
- `__init__(self, model_args: 'ModelArguments', data_args: 'DataArguments', finetuning_args: 'FinetuningArguments', generating_args: 'GeneratingArguments') -> None`

---

## Class: `BaseModelArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_args`

### å±æ€§ (Attributes)
- `adapter_folder: Optional[str]`
- `adapter_name_or_path: Optional[str]`
- `add_special_tokens: Optional[str]`
- `add_tokens: Optional[str]`
- `cache_dir: Optional[str]`
- `disable_gradient_checkpointing: bool`
- `enable_liger_kernel: bool`
- `flash_attn: AttentionFunction`
- `hf_hub_token: Optional[str]`
- `infer_backend: EngineName`
- `infer_dtype: Literal['auto', 'float16', 'bfloat16', 'float32']`
- `low_cpu_mem_usage: bool`
- `mixture_of_depths: Optional[Literal['convert', 'load']]`
- `model_name_or_path: Optional[str]`
- `model_revision: str`
- `moe_aux_loss_coef: Optional[float]`
- `ms_hub_token: Optional[str]`
- `offload_folder: str`
- `om_hub_token: Optional[str]`
- `print_param_status: bool`
- `resize_vocab: bool`
- `rope_scaling: Optional[RopeScaling]`
- `shift_attn: bool`
- `split_special_tokens: bool`
- `train_from_scratch: bool`
- `trust_remote_code: bool`
- `upcast_layernorm: bool`
- `upcast_lmhead_output: bool`
- `use_cache: bool`
- `use_fast_tokenizer: bool`
- `use_reentrant_gc: bool`
- `use_unsloth: bool`
- `use_unsloth_gc: bool`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `BasePlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MMPluginMixin`

### æ–¹æ³• (Methods)
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`
- `process_token_ids(self, input_ids: list[int], labels: Optional[list[int]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], tokenizer: 'PreTrainedTokenizer', processor: Optional['MMProcessor']) -> tuple[list[int], Optional[list[int]]]`

---

## Class: `BelleMultiturn`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `belle_multiturn`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.GeneratorBasedBuilder`

### å±æ€§ (Attributes)
- `VERSION`

### æ–¹æ³• (Methods)
- `_generate_examples(self, filepath: str)`
- `_info(self)`
- `_split_generators(self, dl_manager: datasets.DownloadManager)`

---

## Class: `CMMLU`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `cmmlu`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.GeneratorBasedBuilder`

### å±æ€§ (Attributes)
- `BUILDER_CONFIGS`

### æ–¹æ³• (Methods)
- `_generate_examples(self, filepath)`
- `_info(self)`
- `_split_generators(self, dl_manager)`

---

## Class: `CMMLUConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `cmmlu`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.BuilderConfig`

### æ–¹æ³• (Methods)
- `__init__(self, **kwargs)`

---

## Class: `Ceval`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `ceval`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.GeneratorBasedBuilder`

### å±æ€§ (Attributes)
- `BUILDER_CONFIGS`

### æ–¹æ³• (Methods)
- `_generate_examples(self, filepath)`
- `_info(self)`
- `_split_generators(self, dl_manager)`

---

## Class: `CevalConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `ceval`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.BuilderConfig`

### æ–¹æ³• (Methods)
- `__init__(self, **kwargs)`

---

## Class: `ChatCompletionMessage`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `content: Optional[str]`
- `role: Optional[Role]`
- `tool_calls: Optional[list[FunctionCall]]`

---

## Class: `ChatCompletionRequest`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `do_sample: Optional[bool]`
- `max_tokens: Optional[int]`
- `messages: list[ChatMessage]`
- `model: str`
- `n: int`
- `stop: Optional[Union[str, list[str]]]`
- `stream: bool`
- `temperature: Optional[float]`
- `tools: Optional[list[FunctionAvailable]]`
- `top_p: Optional[float]`

---

## Class: `ChatCompletionResponse`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `choices: list[ChatCompletionResponseChoice]`
- `created: int`
- `id: str`
- `model: str`
- `object: Literal['chat.completion']`
- `usage: ChatCompletionResponseUsage`

---

## Class: `ChatCompletionResponseChoice`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `finish_reason: Finish`
- `index: int`
- `message: ChatCompletionMessage`

---

## Class: `ChatCompletionResponseUsage`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `completion_tokens: int`
- `prompt_tokens: int`
- `total_tokens: int`

---

## Class: `ChatCompletionStreamResponse`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `choices: list[ChatCompletionStreamResponseChoice]`
- `created: int`
- `id: str`
- `model: str`
- `object: Literal['chat.completion.chunk']`

---

## Class: `ChatCompletionStreamResponseChoice`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `delta: ChatCompletionMessage`
- `finish_reason: Optional[Finish]`
- `index: int`

---

## Class: `ChatMessage`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `content: Optional[Union[str, list[MultimodalInputItem]]]`
- `role: Role`
- `tool_calls: Optional[list[FunctionCall]]`

---

## Class: `ChatModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `chat_model`

### å±æ€§ (Attributes)
- `_loop`
- `_thread`

### æ–¹æ³• (Methods)
- `__init__(self, args: Optional[dict[str, Any]]) -> None`
- `chat(self, messages: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: Optional[list['ImageInput']], videos: Optional[list['VideoInput']], audios: Optional[list['AudioInput']], **input_kwargs) -> list['Response']`
- `get_scores(self, batch_input: list[str], **input_kwargs) -> list[float]`
- `stream_chat(self, messages: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: Optional[list['ImageInput']], videos: Optional[list['VideoInput']], audios: Optional[list['AudioInput']], **input_kwargs) -> Generator[str, None, None]`

---

## Class: `CompositeModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `visual`

### å±æ€§ (Attributes)
- `language_model_keys: list[str]`
- `lora_conflict_keys: list[str]`
- `model_type: str`
- `projector_key: str`
- `vision_model_keys: list[str]`

### æ–¹æ³• (Methods)
- `get_projector(self, module: 'torch.nn.Module') -> 'torch.nn.Module'`

---

## Class: `ComputeAccuracy`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `metric`

### æ–¹æ³• (Methods)
- `__call__(self, eval_preds: 'EvalPrediction', compute_result: bool) -> Optional[dict[str, float]]`
- `__post_init__(self)`
- `_dump(self) -> Optional[dict[str, float]]`

---

## Class: `ComputeSimilarity`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `metric`

### å±æ€§ (Attributes)
- `tokenizer: 'PreTrainedTokenizer'`

### æ–¹æ³• (Methods)
- `__call__(self, eval_preds: 'EvalPrediction', compute_result: bool) -> Optional[dict[str, float]]`
- `__post_init__(self)`
- `_dump(self) -> Optional[dict[str, float]]`

---

## Class: `CustomDPOTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DPOTrainer`

### å±æ€§ (Attributes)
- `_peft_has_been_casted_to_bf16`
- `_precomputed_eval_ref_log_probs`
- `_precomputed_train_ref_log_probs`
- `_stored_metrics`
- `beta`
- `f_divergence_type`
- `finetuning_args`
- `ftx_gamma`
- `generate_during_eval`
- `is_encoder_decoder`
- `label_pad_token_id`
- `label_smoothing`
- `loss_type`
- `model_accepts_loss_kwargs`
- `padding_value`
- `precompute_ref_log_probs`
- `ref_model`
- `reference_free`
- `simpo_gamma`
- `use_dpo_data_collator`

### æ–¹æ³• (Methods)
- `__init__(self, model: Union['PreTrainedModel', torch.nn.Module], ref_model: Optional[Union['PreTrainedModel', torch.nn.Module]], finetuning_args: 'FinetuningArguments', processor: Optional['ProcessorMixin'], disable_dropout: bool, **kwargs)`
- `_get_train_sampler(self) -> Optional['torch.utils.data.Sampler']`
- `compute_loss(self, model: 'PreTrainedModel', inputs: dict[str, 'torch.Tensor'], return_outputs: bool, **kwargs) -> Union['torch.Tensor', tuple['torch.Tensor', list['torch.Tensor']]]`
- `compute_preference_loss(self, policy_chosen_logps: 'torch.Tensor', policy_rejected_logps: 'torch.Tensor', reference_chosen_logps: Optional['torch.Tensor'], reference_rejected_logps: Optional['torch.Tensor']) -> tuple['torch.Tensor', 'torch.Tensor', 'torch.Tensor']`
- `compute_reference_log_probs(self, model: 'PreTrainedModel', batch: dict[str, 'torch.Tensor']) -> tuple[Optional['torch.Tensor'], Optional['torch.Tensor']]`
- `concatenated_forward(self, model: 'PreTrainedModel', batch: dict[str, 'torch.Tensor']) -> tuple['torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor']`
- `create_optimizer(self) -> 'torch.optim.Optimizer'`
- `create_scheduler(self, num_training_steps: int, optimizer: Optional['torch.optim.Optimizer']) -> 'torch.optim.lr_scheduler.LRScheduler'`
- `get_batch_loss_metrics(self, model: 'PreTrainedModel', batch: dict[str, 'torch.Tensor'], train_eval: Literal['train', 'eval']) -> tuple['torch.Tensor', dict[str, 'torch.Tensor']]`
- `get_batch_samples(self, *args, **kwargs)`
- `log(self, logs: dict[str, float], *args, **kwargs) -> None`
- `odds_ratio_loss(self, chosen_logps: 'torch.Tensor', rejected_logps: 'torch.Tensor') -> 'torch.Tensor'`
- `simpo_loss(self, chosen_logps: 'torch.Tensor', rejected_logps: 'torch.Tensor') -> 'torch.Tensor'`

---

## Class: `CustomKTOTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `KTOTrainer`

### å±æ€§ (Attributes)
- `_peft_has_been_casted_to_bf16`
- `_precomputed_eval_ref_log_probs`
- `_precomputed_train_ref_log_probs`
- `_stored_metrics`
- `beta`
- `desirable_weight`
- `finetuning_args`
- `ftx_gamma`
- `generate_during_eval`
- `is_encoder_decoder`
- `label_pad_token_id`
- `model_accepts_loss_kwargs`
- `padding_value`
- `precompute_ref_log_probs`
- `ref_model`
- `reference_free`
- `undesirable_weight`
- `use_dpo_data_collator`

### æ–¹æ³• (Methods)
- `__init__(self, model: Union['PreTrainedModel', torch.nn.Module], ref_model: Optional[Union['PreTrainedModel', torch.nn.Module]], finetuning_args: 'FinetuningArguments', processor: Optional['ProcessorMixin'], disable_dropout: bool, **kwargs)`
- `_get_train_sampler(self) -> Optional['torch.utils.data.Sampler']`
- `compute_loss(self, model: 'PreTrainedModel', inputs: dict[str, 'torch.Tensor'], return_outputs: bool, **kwargs) -> Union['torch.Tensor', tuple['torch.Tensor', list['torch.Tensor']]]`
- `compute_reference_log_probs(self, model: 'PreTrainedModel', batch: dict[str, 'torch.Tensor']) -> tuple['torch.Tensor', 'torch.Tensor', 'torch.Tensor']`
- `concatenated_forward(self, model: 'PreTrainedModel', batch: dict[str, 'torch.Tensor']) -> tuple['torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor']`
- `create_optimizer(self) -> 'torch.optim.Optimizer'`
- `create_scheduler(self, num_training_steps: int, optimizer: Optional['torch.optim.Optimizer']) -> 'torch.optim.lr_scheduler.LRScheduler'`
- `forward(self, model: 'PreTrainedModel', batch: dict[str, 'torch.Tensor'], prefix: Literal['', 'kl_']) -> tuple['torch.Tensor', 'torch.Tensor', 'torch.Tensor']`
- `get_batch_loss_metrics(self, model: 'PreTrainedModel', batch: dict[str, 'torch.Tensor']) -> tuple['torch.Tensor', dict[str, 'torch.Tensor']]`
- `get_batch_samples(self, *args, **kwargs)`
- `log(self, logs: dict[str, float], *args, **kwargs) -> None`

---

## Class: `CustomPPOTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PPOTrainer`, `Trainer`

### å±æ€§ (Attributes)
- `amp_context`
- `args`
- `callback_handler`
- `control`
- `current_device`
- `finetuning_args`
- `generation_config`
- `is_deepspeed_enabled`
- `is_fsdp_enabled`
- `model_args`
- `reward_model`
- `state`

### æ–¹æ³• (Methods)
- `__init__(self, model_args: 'ModelArguments', training_args: 'Seq2SeqTrainingArguments', finetuning_args: 'FinetuningArguments', generating_args: 'GeneratingArguments', callbacks: Optional[list['TrainerCallback']], model: 'AutoModelForCausalLMWithValueHead', reward_model: Optional['AutoModelForCausalLMWithValueHead'], ref_model: Optional['AutoModelForCausalLMWithValueHead'], tokenizer: 'PreTrainedTokenizer', processor: Optional['ProcessorMixin'], data_collator: 'DataCollatorWithPadding', train_dataset: Optional['Dataset'], eval_dataset: Optional['Dataset']) -> None`
- `batched_forward_pass(self, model: 'AutoModelForCausalLMWithValueHead', queries: 'torch.Tensor', responses: 'torch.Tensor', model_inputs: dict[str, Any], return_logits: bool, response_masks: Optional['torch.Tensor']) -> tuple['torch.Tensor', Optional['torch.Tensor'], 'torch.Tensor', 'torch.Tensor']`
- `create_optimizer(self, model: 'AutoModelForCausalLMWithValueHead', training_args: 'Seq2SeqTrainingArguments', finetuning_args: 'FinetuningArguments') -> 'torch.optim.Optimizer'`
- `create_scheduler(self, training_args: 'Seq2SeqTrainingArguments', num_training_steps: int, optimizer: 'torch.optim.Optimizer') -> 'torch.optim.lr_scheduler.LRScheduler'`
- `get_inputs(self, batch: dict[str, 'torch.Tensor']) -> tuple[list['torch.Tensor'], list['torch.Tensor']]`
- `get_rewards(self, queries: list['torch.Tensor'], responses: list['torch.Tensor']) -> list['torch.Tensor']`
- `ppo_train(self, resume_from_checkpoint: Optional[str]) -> None`
- `save_model(self, output_dir: Optional[str]) -> None`

---

## Class: `CustomSeq2SeqTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Seq2SeqTrainer`

### å±æ€§ (Attributes)
- `finetuning_args`

### æ–¹æ³• (Methods)
- `__init__(self, finetuning_args: 'FinetuningArguments', processor: Optional['ProcessorMixin'], gen_kwargs: Optional[dict[str, Any]], **kwargs) -> None`
- `_get_train_sampler(self) -> Optional['torch.utils.data.Sampler']`
- `compute_loss(self, model, inputs, *args, **kwargs)`
- `create_optimizer(self) -> 'torch.optim.Optimizer'`
- `create_scheduler(self, num_training_steps: int, optimizer: Optional['torch.optim.Optimizer']) -> 'torch.optim.lr_scheduler.LRScheduler'`
- `prediction_step(self, model: 'torch.nn.Module', inputs: dict[str, Union['torch.Tensor', Any]], prediction_loss_only: bool, ignore_keys: Optional[list[str]], **gen_kwargs) -> tuple[Optional[float], Optional['torch.Tensor'], Optional['torch.Tensor']]`
- `save_predictions(self, dataset: 'Dataset', predict_results: 'PredictionOutput', skip_special_tokens: bool) -> None`

---

## Class: `CustomTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### å±æ€§ (Attributes)
- `finetuning_args`

### æ–¹æ³• (Methods)
- `__init__(self, finetuning_args: 'FinetuningArguments', processor: Optional['ProcessorMixin'], **kwargs) -> None`
- `_get_train_sampler(self) -> Optional['torch.utils.data.Sampler']`
- `compute_loss(self, model, inputs, *args, **kwargs)`
- `create_optimizer(self) -> 'torch.optim.Optimizer'`
- `create_scheduler(self, num_training_steps: int, optimizer: Optional['torch.optim.Optimizer']) -> 'torch.optim.lr_scheduler.LRScheduler'`

---

## Class: `DataArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `data_args`

### å±æ€§ (Attributes)
- `buffer_size: int`
- `cutoff_len: int`
- `dataset: Optional[str]`
- `dataset_dir: str`
- `eval_dataset: Optional[str]`
- `eval_num_beams: Optional[int]`
- `eval_on_each_dataset: bool`
- `ignore_pad_token_for_loss: bool`
- `interleave_probs: Optional[str]`
- `mask_history: bool`
- `max_samples: Optional[int]`
- `media_dir: Optional[str]`
- `mix_strategy: Literal['concat', 'interleave_under', 'interleave_over']`
- `neat_packing: bool`
- `overwrite_cache: bool`
- `packing: Optional[bool]`
- `preprocessing_batch_size: int`
- `preprocessing_num_workers: Optional[int]`
- `streaming: bool`
- `template: Optional[str]`
- `tokenized_path: Optional[str]`
- `tool_format: Optional[str]`
- `train_on_prompt: bool`
- `val_size: float`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `to_dict(self) -> dict[str, Any]`

---

## Class: `DatasetAttr`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `parser`

### å±æ€§ (Attributes)
- `assistant_tag: Optional[str]`
- `audios: Optional[str]`
- `chosen: Optional[str]`
- `content_tag: Optional[str]`
- `dataset_name: str`
- `folder: Optional[str]`
- `formatting: Literal['alpaca', 'sharegpt']`
- `function_tag: Optional[str]`
- `history: Optional[str]`
- `images: Optional[str]`
- `kto_tag: Optional[str]`
- `load_from: Literal['hf_hub', 'ms_hub', 'om_hub', 'script', 'file']`
- `messages: Optional[str]`
- `num_samples: Optional[int]`
- `observation_tag: Optional[str]`
- `prompt: Optional[str]`
- `query: Optional[str]`
- `ranking: bool`
- `rejected: Optional[str]`
- `response: Optional[str]`
- `role_tag: Optional[str]`
- `split: str`
- `subset: Optional[str]`
- `system: Optional[str]`
- `system_tag: Optional[str]`
- `tools: Optional[str]`
- `user_tag: Optional[str]`
- `videos: Optional[str]`

### æ–¹æ³• (Methods)
- `__repr__(self) -> str`
- `join(self, attr: dict[str, Any]) -> None`
- `set_attr(self, key: str, obj: dict[str, Any], default: Optional[Any]) -> None`

---

## Class: `DatasetConverter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `converter`

### å±æ€§ (Attributes)
- `data_args: 'DataArguments'`
- `dataset_attr: 'DatasetAttr'`

### æ–¹æ³• (Methods)
- `__call__(self, example: dict[str, Any]) -> dict[str, Any]`
- `_find_medias(self, medias: Union['MediaType', list['MediaType'], None]) -> Optional[list['MediaType']]`

---

## Class: `DatasetModule`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `data_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TypedDict`

### å±æ€§ (Attributes)
- `eval_dataset: Optional[Union['Dataset', 'IterableDataset', dict[str, 'Dataset']]]`
- `train_dataset: Optional[Union['Dataset', 'IterableDataset']]`

---

## Class: `DatasetProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `processor_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ABC`

### å±æ€§ (Attributes)
- `data_args: 'DataArguments'`
- `processor: Optional['ProcessorMixin']`
- `template: 'Template'`
- `tokenizer: 'PreTrainedTokenizer'`

### æ–¹æ³• (Methods)
- `preprocess_dataset(self, examples: dict[str, list[Any]]) -> dict[str, list[Any]]`
- `print_data_example(self, example: dict[str, list[int]]) -> None`

---

## Class: `DefaultToolUtils`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tool_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ToolUtils`

### æ–¹æ³• (Methods)
- `function_formatter(functions: list['FunctionCall']) -> str`
- `tool_extractor(content: str) -> Union[str, list['FunctionCall']]`
- `tool_formatter(tools: list[dict[str, Any]]) -> str`

---

## Class: `DownloadSource`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `constants`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `str`, `Enum`

### å±æ€§ (Attributes)
- `DEFAULT`
- `MODELSCOPE`
- `OPENMIND`

---

## Class: `DummyOptimizer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.optim.Optimizer`

### å±æ€§ (Attributes)
- `optimizer_dict`

### æ–¹æ³• (Methods)
- `__init__(self, lr: float, optimizer_dict: Optional[dict['torch.nn.Parameter', 'torch.optim.Optimizer']]) -> None`
- `step(self, closure: Optional[Callable[[], float]]) -> Optional[float]`
- `zero_grad(self, set_to_none: bool) -> None`

---

## Class: `EmptyFormatter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `formatter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Formatter`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `apply(self, **kwargs) -> SLOTS`

---

## Class: `EncodedImage`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TypedDict`

### å±æ€§ (Attributes)
- `bytes: Optional[bytes]`
- `path: Optional[str]`

---

## Class: `Engine`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `engine`

### å±æ€§ (Attributes)
- `chatter`
- `demo_mode`
- `manager`
- `pure_chat`
- `runner`

### æ–¹æ³• (Methods)
- `__init__(self, demo_mode: bool, pure_chat: bool) -> None`
- `_update_component(self, input_dict: dict[str, dict[str, Any]]) -> dict['Component', 'Component']`
- `change_lang(self, lang: str)`
- `resume(self)`

---

## Class: `EngineName`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `constants`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `str`, `Enum`

### å±æ€§ (Attributes)
- `HF`
- `SGLANG`
- `VLLM`

---

## Class: `EvalTemplate`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `template`

### å±æ€§ (Attributes)
- `answer: str`
- `choice: str`
- `system: str`

### æ–¹æ³• (Methods)
- `_parse_example(self, example: dict[str, str]) -> tuple[str, str]`
- `format_example(self, target_data: dict[str, str], support_set: list[dict[str, str]], subject_name: str) -> list[dict[str, str]]`

---

## Class: `EvaluationArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `evaluation_args`

### å±æ€§ (Attributes)
- `batch_size: int`
- `download_mode: DownloadMode`
- `lang: Literal['en', 'zh']`
- `n_shot: int`
- `save_dir: Optional[str]`
- `seed: int`
- `task: str`
- `task_dir: str`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `Evaluator`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `evaluator`

### å±æ€§ (Attributes)
- `choice_inputs`
- `eval_template`
- `model`
- `template`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, args: Optional[dict[str, Any]]) -> None`
- `_save_results(self, category_corrects: dict[str, 'NDArray'], results: dict[str, dict[int, str]]) -> None`
- `batch_inference(self, batch_input: dict[str, 'torch.Tensor']) -> list[str]`
- `eval(self) -> None`

---

## Class: `ExportArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_args`

### å±æ€§ (Attributes)
- `export_device: Literal['cpu', 'auto']`
- `export_dir: Optional[str]`
- `export_hub_model_id: Optional[str]`
- `export_legacy_format: bool`
- `export_quantization_bit: Optional[int]`
- `export_quantization_dataset: Optional[str]`
- `export_quantization_maxlen: int`
- `export_quantization_nsamples: int`
- `export_size: int`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `FeedbackDatasetProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `feedback`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DatasetProcessor`

### æ–¹æ³• (Methods)
- `_encode_data_example(self, prompt: list[dict[str, str]], response: list[dict[str, str]], kl_response: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput']) -> tuple[list[int], list[int], list[int], list[int], bool]`
- `preprocess_dataset(self, examples: dict[str, list[Any]]) -> dict[str, list[Any]]`
- `print_data_example(self, example: dict[str, list[int]]) -> None`

---

## Class: `FinetuningArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `SwanLabArguments`, `BAdamArgument`, `ApolloArguments`, `GaloreArguments`, `RLHFArguments`, `LoraArguments`, `FreezeArguments`

### å±æ€§ (Attributes)
- `compute_accuracy: bool`
- `disable_shuffling: bool`
- `early_stopping_steps: Optional[int]`
- `finetuning_type: Literal['lora', 'freeze', 'full']`
- `freeze_language_model: bool`
- `freeze_multi_modal_projector: bool`
- `freeze_vision_tower: bool`
- `include_effective_tokens_per_second: bool`
- `plot_loss: bool`
- `pure_bf16: bool`
- `stage: Literal['pt', 'sft', 'rm', 'ppo', 'dpo', 'kto']`
- `use_adam_mini: bool`
- `use_llama_pro: bool`
- `use_muon: bool`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `to_dict(self) -> dict[str, Any]`

---

## Class: `Finish`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `str`, `Enum`

### å±æ€§ (Attributes)
- `LENGTH`
- `STOP`
- `TOOL`

---

## Class: `FixValueHeadModelCallback`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `callbacks`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TrainerCallback`

### æ–¹æ³• (Methods)
- `on_save(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`

---

## Class: `Formatter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `formatter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ABC`

### å±æ€§ (Attributes)
- `slots: SLOTS`
- `tool_format: Optional[str]`

### æ–¹æ³• (Methods)
- `apply(self, **kwargs) -> SLOTS`
- `extract(self, content: str) -> Union[str, list['FunctionCall']]`

---

## Class: `FreezeArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### å±æ€§ (Attributes)
- `freeze_extra_modules: Optional[str]`
- `freeze_trainable_layers: int`
- `freeze_trainable_modules: str`

---

## Class: `Function`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `arguments: str`
- `name: str`

---

## Class: `FunctionAvailable`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `function: Optional[FunctionDefinition]`
- `type: Literal['function', 'code_interpreter']`

---

## Class: `FunctionCall`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`, `NamedTuple`

### å±æ€§ (Attributes)
- `arguments: str`
- `function: Function`
- `id: str`
- `name: str`
- `type: Literal['function']`

---

## Class: `FunctionDefinition`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `description: str`
- `name: str`
- `parameters: dict[str, Any]`

---

## Class: `FunctionFormatter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `formatter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `StringFormatter`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `apply(self, **kwargs) -> SLOTS`

---

## Class: `GLM4ToolUtils`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tool_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ToolUtils`

### æ–¹æ³• (Methods)
- `function_formatter(functions: list['FunctionCall']) -> str`
- `tool_extractor(content: str) -> Union[str, list['FunctionCall']]`
- `tool_formatter(tools: list[dict[str, Any]]) -> str`

---

## Class: `GaloreArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### å±æ€§ (Attributes)
- `galore_layerwise: bool`
- `galore_proj_type: Literal['std', 'reverse_std', 'right', 'left', 'full']`
- `galore_rank: int`
- `galore_scale: float`
- `galore_target: str`
- `galore_update_interval: int`
- `use_galore: bool`

---

## Class: `Gemma3Plugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `GeneratingArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `generating_args`

### å±æ€§ (Attributes)
- `default_system: Optional[str]`
- `do_sample: bool`
- `enable_thinking: bool`
- `length_penalty: float`
- `max_length: int`
- `max_new_tokens: int`
- `num_beams: int`
- `repetition_penalty: float`
- `skip_special_tokens: bool`
- `temperature: float`
- `top_k: int`
- `top_p: float`

### æ–¹æ³• (Methods)
- `to_dict(self, obey_generation_config: bool) -> dict[str, Any]`

---

## Class: `HhRlhfEn`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hh_rlhf_en`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.GeneratorBasedBuilder`

### å±æ€§ (Attributes)
- `VERSION`

### æ–¹æ³• (Methods)
- `_generate_examples(self, filepaths: list[str])`
- `_info(self) -> datasets.DatasetInfo`
- `_split_generators(self, dl_manager: datasets.DownloadManager)`

---

## Class: `HuggingfaceEngine`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_engine`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseEngine`

### å±æ€§ (Attributes)
- `can_generate`
- `generating_args`
- `model`
- `name`
- `processor`
- `semaphore`
- `template`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, model_args: 'ModelArguments', data_args: 'DataArguments', finetuning_args: 'FinetuningArguments', generating_args: 'GeneratingArguments') -> None`
- `_chat(model: 'PreTrainedModel', tokenizer: 'PreTrainedTokenizer', processor: Optional['ProcessorMixin'], template: 'Template', generating_args: dict[str, Any], messages: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: Optional[list['ImageInput']], videos: Optional[list['VideoInput']], audios: Optional[list['AudioInput']], input_kwargs: Optional[dict[str, Any]]) -> list['Response']`
- `_get_scores(model: 'PreTrainedModelWrapper', tokenizer: 'PreTrainedTokenizer', batch_input: list[str], input_kwargs: Optional[dict[str, Any]]) -> list[float]`
- `_process_args(model: 'PreTrainedModel', tokenizer: 'PreTrainedTokenizer', processor: Optional['ProcessorMixin'], template: 'Template', generating_args: dict[str, Any], messages: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: Optional[list['ImageInput']], videos: Optional[list['VideoInput']], audios: Optional[list['AudioInput']], input_kwargs: Optional[dict[str, Any]]) -> tuple[dict[str, Any], int]`
- `_stream_chat(model: 'PreTrainedModel', tokenizer: 'PreTrainedTokenizer', processor: Optional['ProcessorMixin'], template: 'Template', generating_args: dict[str, Any], messages: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: Optional[list['ImageInput']], videos: Optional[list['VideoInput']], audios: Optional[list['AudioInput']], input_kwargs: Optional[dict[str, Any]]) -> Callable[[], str]`

---

## Class: `InternVLPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `_get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: 'ProcessorMixin', **kwargs) -> dict[str, 'torch.Tensor']`
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['ProcessorMixin']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['ProcessorMixin']) -> list[dict[str, str]]`

---

## Class: `KTODataCollatorWithPadding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `collator`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MultiModalDataCollatorForSeq2Seq`

### æ–¹æ³• (Methods)
- `__call__(self, features: list[dict[str, Any]]) -> dict[str, 'torch.Tensor']`

---

## Class: `KimiVLPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `process_messages(self, messages, images, videos, audios, processor)`

---

## Class: `Llama2Template`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `template`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Template`

### æ–¹æ³• (Methods)
- `_encode(self, tokenizer: 'PreTrainedTokenizer', messages: list[dict[str, str]], system: str, tools: str) -> list[list[int]]`
- `_get_jinja_template(self, tokenizer: 'PreTrainedTokenizer') -> str`

---

## Class: `Llama3ToolUtils`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tool_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ToolUtils`

### æ–¹æ³• (Methods)
- `function_formatter(functions: list['FunctionCall']) -> str`
- `tool_extractor(content: str) -> Union[str, list['FunctionCall']]`
- `tool_formatter(tools: list[dict[str, Any]]) -> str`

---

## Class: `Llama4Plugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `LlavaMultiModalProjectorForYiVL`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `visual`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.nn.Module`

### å±æ€§ (Attributes)
- `act`
- `config`
- `linear_1`
- `linear_2`
- `linear_3`
- `linear_4`

### æ–¹æ³• (Methods)
- `__init__(self, config: 'LlavaConfig') -> None`
- `forward(self, image_features: 'torch.Tensor') -> 'torch.Tensor'`

---

## Class: `LlavaMultiModalProjectorForYiVLForVLLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `visual`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMultiModalProjectorForYiVL`

### å±æ€§ (Attributes)
- `act`
- `linear_1`
- `linear_2`
- `linear_3`
- `linear_4`

### æ–¹æ³• (Methods)
- `__init__(self, vision_hidden_size: int, text_hidden_size: int, projector_hidden_act: str) -> None`

---

## Class: `LlavaNextPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `LlavaNextVideoPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `LlavaPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `LogCallback`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `callbacks`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TrainerCallback`

### å±æ€§ (Attributes)
- `aborted`
- `cur_steps`
- `do_train`
- `elapsed_time`
- `max_steps`
- `remaining_time`
- `start_time`
- `thread_pool: Optional[ThreadPoolExecutor]`
- `webui_mode`

### æ–¹æ³• (Methods)
- `__init__(self) -> None`
- `_close_thread_pool(self) -> None`
- `_create_thread_pool(self, output_dir: str) -> None`
- `_reset(self, max_steps: int) -> None`
- `_set_abort(self, signum, frame) -> None`
- `_timing(self, cur_steps: int) -> None`
- `_write_log(self, output_dir: str, logs: dict[str, Any]) -> None`
- `on_evaluate(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_init_end(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_log(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_predict(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_prediction_step(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_step_end(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_substep_end(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_train_begin(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_train_end(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`

---

## Class: `LoggerHandler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `logging`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `logging.Handler`

### å±æ€§ (Attributes)
- `_formatter`
- `running_log`
- `thread_pool`

### æ–¹æ³• (Methods)
- `__init__(self, output_dir: str) -> None`
- `_write_log(self, log_entry: str) -> None`
- `close(self) -> None`
- `emit(self, record) -> None`

---

## Class: `LoraArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### å±æ€§ (Attributes)
- `additional_target: Optional[str]`
- `create_new_adapter: bool`
- `lora_alpha: Optional[int]`
- `lora_dropout: float`
- `lora_rank: int`
- `lora_target: str`
- `loraplus_lr_embedding: float`
- `loraplus_lr_ratio: Optional[float]`
- `pissa_convert: bool`
- `pissa_init: bool`
- `pissa_iter: int`
- `use_dora: bool`
- `use_rslora: bool`

---

## Class: `MMLU`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mmlu`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.GeneratorBasedBuilder`

### å±æ€§ (Attributes)
- `BUILDER_CONFIGS`

### æ–¹æ³• (Methods)
- `_generate_examples(self, filepath)`
- `_info(self)`
- `_split_generators(self, dl_manager)`

---

## Class: `MMLUConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mmlu`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.BuilderConfig`

### æ–¹æ³• (Methods)
- `__init__(self, **kwargs)`

---

## Class: `MMPluginMixin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### å±æ€§ (Attributes)
- `audio_token: Optional[str]`
- `expand_mm_tokens: bool`
- `image_token: Optional[str]`
- `video_token: Optional[str]`

### æ–¹æ³• (Methods)
- `_get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: 'MMProcessor', imglens: Optional[list[int]]) -> dict[str, 'torch.Tensor']`
- `_get_video_sample_indices(self, video_stream: 'Stream', video_fps: float, video_maxlen: int, **kwargs) -> list[int]`
- `_preprocess_image(self, image: 'ImageObject', image_max_pixels: int, image_min_pixels: int, **kwargs) -> 'ImageObject'`
- `_regularize_audios(self, audios: list['AudioInput'], sampling_rate: float, **kwargs) -> dict[str, Union[list['NDArray'], list[float]]]`
- `_regularize_images(self, images: list['ImageInput'], **kwargs) -> dict[str, list['ImageObject']]`
- `_regularize_videos(self, videos: list['VideoInput'], **kwargs) -> dict[str, list[list['ImageObject']]]`
- `_validate_input(self, processor: Optional['MMProcessor'], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput']) -> None`
- `_validate_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'])`

---

## Class: `MMProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ProcessorMixin`

### å±æ€§ (Attributes)
- `image_seq_length: int`
- `num_additional_image_tokens: int`
- `patch_size: int`
- `vision_feature_select_strategy: Literal['default', 'full']`

### æ–¹æ³• (Methods)
- `_get_number_of_features(self, orig_height: int, orig_width: int, height: int, width: int) -> int`

---

## Class: `Manager`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `manager`

### å±æ€§ (Attributes)
- `_elem_to_id: dict[Component, str]`
- `_id_to_elem: dict[str, Component]`

### æ–¹æ³• (Methods)
- `__init__(self) -> None`
- `add_elems(self, tab_name: str, elem_dict: dict[str, 'Component']) -> None`
- `get_base_elems(self) -> set['Component']`
- `get_elem_by_id(self, elem_id: str) -> 'Component'`
- `get_elem_iter(self) -> Generator[tuple[str, 'Component'], None, None]`
- `get_elem_list(self) -> list['Component']`
- `get_id_by_elem(self, elem: 'Component') -> str`

---

## Class: `MiniCPMVPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `_get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: 'MMProcessor', **kwargs) -> dict[str, 'torch.Tensor']`
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `MistralToolUtils`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tool_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ToolUtils`

### æ–¹æ³• (Methods)
- `function_formatter(functions: list['FunctionCall']) -> str`
- `tool_extractor(content: str) -> Union[str, list['FunctionCall']]`
- `tool_formatter(tools: list[dict[str, Any]]) -> str`

---

## Class: `MllamaPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `ModelArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_args`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `SGLangArguments`, `VllmArguments`, `ExportArguments`, `ProcessorArguments`, `QuantizationArguments`, `BaseModelArguments`

### å±æ€§ (Attributes)
- `block_diag_attn: bool`
- `compute_dtype: Optional[torch.dtype]`
- `device_map: Optional[Union[str, dict[str, Any]]]`
- `model_max_length: Optional[int]`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `copyfrom(cls, source: 'Self', **kwargs) -> 'Self'`
- `to_dict(self) -> dict[str, Any]`

---

## Class: `ModelCard`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `created: int`
- `id: str`
- `object: Literal['model']`
- `owned_by: Literal['owner']`

---

## Class: `ModelList`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `data: list[ModelCard]`
- `object: Literal['list']`

---

## Class: `MultiModalDataCollatorForSeq2Seq`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `collator`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DataCollatorForSeq2Seq`

### å±æ€§ (Attributes)
- `processor: Optional['ProcessorMixin']`
- `template: Optional['Template']`

### æ–¹æ³• (Methods)
- `__call__(self, features: list[dict[str, Any]]) -> dict[str, 'torch.Tensor']`
- `__post_init__(self)`

---

## Class: `MultimodalInputItem`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `audio_url: Optional[URL]`
- `image_url: Optional[URL]`
- `text: Optional[str]`
- `type: Literal['text', 'image_url', 'video_url', 'audio_url']`
- `video_url: Optional[URL]`

---

## Class: `Muon`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `muon`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.optim.Optimizer`

### æ–¹æ³• (Methods)
- `__init__(self, lr, wd, muon_params, momentum, nesterov, ns_steps, adamw_params, adamw_betas, adamw_eps)`
- `adjust_lr_for_muon(self, lr: float, param_shape: list[int]) -> float`
- `step(self, closure)`

---

## Class: `PackedSupervisedDatasetProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `supervised`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `SupervisedDatasetProcessor`

### æ–¹æ³• (Methods)
- `preprocess_dataset(self, examples: dict[str, list[Any]]) -> dict[str, list[Any]]`

---

## Class: `PairwiseDataCollatorWithPadding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `cal_ppl`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MultiModalDataCollatorForSeq2Seq`, `MultiModalDataCollatorForSeq2Seq`

### å±æ€§ (Attributes)
- `train_on_prompt: bool`

### æ–¹æ³• (Methods)
- `__call__(self, features: list[dict[str, Any]]) -> dict[str, 'torch.Tensor']`
- `__call__(self, features: list[dict[str, Any]]) -> dict[str, torch.Tensor]`

---

## Class: `PairwiseDatasetProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `pairwise`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DatasetProcessor`

### æ–¹æ³• (Methods)
- `_encode_data_example(self, prompt: list[dict[str, str]], response: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput']) -> tuple[list[int], list[int], list[int], list[int]]`
- `preprocess_dataset(self, examples: dict[str, list[Any]]) -> dict[str, list[Any]]`
- `print_data_example(self, example: dict[str, list[int]]) -> None`

---

## Class: `PairwiseTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### å±æ€§ (Attributes)
- `can_return_loss`
- `finetuning_args`
- `model_accepts_loss_kwargs`

### æ–¹æ³• (Methods)
- `__init__(self, finetuning_args: 'FinetuningArguments', processor: Optional['ProcessorMixin'], **kwargs) -> None`
- `_get_train_sampler(self) -> Optional['torch.utils.data.Sampler']`
- `compute_loss(self, model: 'PreTrainedModel', inputs: dict[str, 'torch.Tensor'], return_outputs: bool, **kwargs) -> Union['torch.Tensor', tuple['torch.Tensor', list['torch.Tensor']]]`
- `create_optimizer(self) -> 'torch.optim.Optimizer'`
- `create_scheduler(self, num_training_steps: int, optimizer: Optional['torch.optim.Optimizer']) -> 'torch.optim.lr_scheduler.LRScheduler'`
- `save_predictions(self, predict_results: 'PredictionOutput') -> None`

---

## Class: `PaliGemmaPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`
- `process_token_ids(self, input_ids: list[int], labels: Optional[list[int]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], tokenizer: 'PreTrainedTokenizer', processor: Optional['MMProcessor']) -> tuple[list[int], Optional[list[int]]]`

---

## Class: `PissaConvertCallback`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `callbacks`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TrainerCallback`

### æ–¹æ³• (Methods)
- `on_train_begin(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_train_end(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`

---

## Class: `PixtralPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `PretrainDatasetProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `pretrain`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DatasetProcessor`

### æ–¹æ³• (Methods)
- `preprocess_dataset(self, examples: dict[str, list[Any]]) -> dict[str, list[Any]]`
- `print_data_example(self, example: dict[str, list[int]]) -> None`

---

## Class: `ProcessorArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_args`

### å±æ€§ (Attributes)
- `audio_sampling_rate: int`
- `crop_to_patches: bool`
- `image_do_pan_and_scan: bool`
- `image_max_pixels: int`
- `image_min_pixels: int`
- `use_audio_in_video: bool`
- `video_fps: float`
- `video_max_pixels: int`
- `video_maxlen: int`
- `video_min_pixels: int`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `QuantizationArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_args`

### å±æ€§ (Attributes)
- `double_quantization: bool`
- `quantization_bit: Optional[int]`
- `quantization_device_map: Optional[Literal['auto']]`
- `quantization_method: QuantizationMethod`
- `quantization_type: Literal['fp4', 'nf4']`

---

## Class: `QuantizationMethod`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `constants`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `str`, `Enum`

### å±æ€§ (Attributes)
- `AQLM`
- `AWQ`
- `BNB`
- `EETQ`
- `GPTQ`
- `HQQ`
- `QUANTO`

---

## Class: `Qwen2AudioPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], imglens: list[int], vidlens: list[int], audlens: list[int], batch_ids: list[list[int]], processor: Optional['MMProcessor']) -> dict[str, Union[list[int], 'torch.Tensor']]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `Qwen2OmniPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Qwen2VLPlugin`

### æ–¹æ³• (Methods)
- `_get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: 'MMProcessor') -> dict[str, 'torch.Tensor']`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `Qwen2VLPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `_get_mm_inputs(self, images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: 'MMProcessor') -> dict[str, 'torch.Tensor']`
- `_preprocess_image(self, image: 'ImageObject', **kwargs) -> 'ImageObject'`
- `_regularize_videos(self, videos: list['VideoInput'], **kwargs) -> dict[str, Union[list[list['ImageObject']], list[float]]]`
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `QwenToolUtils`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tool_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ToolUtils`

### æ–¹æ³• (Methods)
- `function_formatter(functions: list['FunctionCall']) -> str`
- `tool_extractor(content: str) -> Union[str, list['FunctionCall']]`
- `tool_formatter(tools: list[dict[str, Any]]) -> str`

---

## Class: `RLHFArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### å±æ€§ (Attributes)
- `dpo_label_smoothing: float`
- `kto_chosen_weight: float`
- `kto_rejected_weight: float`
- `ppo_buffer_size: int`
- `ppo_epochs: int`
- `ppo_score_norm: bool`
- `ppo_target: float`
- `ppo_whiten_rewards: bool`
- `pref_beta: float`
- `pref_ftx: float`
- `pref_loss: Literal['sigmoid', 'hinge', 'ipo', 'kto_pair', 'orpo', 'simpo']`
- `ref_model: Optional[str]`
- `ref_model_adapters: Optional[str]`
- `ref_model_quantization_bit: Optional[int]`
- `reward_model: Optional[str]`
- `reward_model_adapters: Optional[str]`
- `reward_model_quantization_bit: Optional[int]`
- `reward_model_type: Literal['lora', 'full', 'api']`
- `simpo_gamma: float`

---

## Class: `RayArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `training_args`

### å±æ€§ (Attributes)
- `placement_strategy: Literal['SPREAD', 'PACK', 'STRICT_SPREAD', 'STRICT_PACK']`
- `ray_init_kwargs: Optional[dict]`
- `ray_num_workers: int`
- `ray_run_name: Optional[str]`
- `ray_storage_filesystem: Optional[Literal['s3', 'gs', 'gcs']]`
- `ray_storage_path: str`
- `resources_per_worker: Union[dict, str]`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `ReasoningTemplate`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `template`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Template`

### æ–¹æ³• (Methods)
- `encode_multiturn(self, tokenizer: 'PreTrainedTokenizer', messages: list[dict[str, str]], system: Optional[str], tools: Optional[str]) -> list[tuple[list[int], list[int]]]`
- `encode_oneturn(self, tokenizer: 'PreTrainedTokenizer', messages: list[dict[str, str]], system: Optional[str], tools: Optional[str], enable_thinking: bool) -> tuple[list[int], list[int]]`

---

## Class: `ReporterCallback`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `callbacks`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TrainerCallback`

### å±æ€§ (Attributes)
- `data_args`
- `finetuning_args`
- `generating_args`
- `model_args`

### æ–¹æ³• (Methods)
- `__init__(self, model_args: 'ModelArguments', data_args: 'DataArguments', finetuning_args: 'FinetuningArguments', generating_args: 'GeneratingArguments') -> None`
- `on_train_begin(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`

---

## Class: `Response`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `base_engine`

### å±æ€§ (Attributes)
- `finish_reason: Literal['stop', 'length']`
- `prompt_length: int`
- `response_length: int`
- `response_text: str`

---

## Class: `Role`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `str`, `Enum`, `str`, `Enum`

### å±æ€§ (Attributes)
- `ASSISTANT`
- `FUNCTION`
- `OBSERVATION`
- `SYSTEM`
- `TOOL`
- `USER`

---

## Class: `RopeScaling`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `constants`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `str`, `Enum`

### å±æ€§ (Attributes)
- `DYNAMIC`
- `LINEAR`
- `LLAMA3`
- `YARN`

---

## Class: `Runner`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `runner`

### å±æ€§ (Attributes)
- `aborted`
- `demo_mode`
- `do_train`
- `manager`
- `running`
- `running_data: dict[Component, Any]`
- `trainer: Optional[Popen]`

### æ–¹æ³• (Methods)
- `__init__(self, manager: 'Manager', demo_mode: bool) -> None`
- `_build_config_dict(self, data: dict['Component', Any]) -> dict[str, Any]`
- `_finalize(self, lang: str, finish_info: str) -> str`
- `_initialize(self, data: dict['Component', Any], do_train: bool, from_preview: bool) -> str`
- `_launch(self, data: dict['Component', Any], do_train: bool) -> Generator[dict['Component', Any], None, None]`
- `_parse_eval_args(self, data: dict['Component', Any]) -> dict[str, Any]`
- `_parse_train_args(self, data: dict['Component', Any]) -> dict[str, Any]`
- `_preview(self, data: dict['Component', Any], do_train: bool) -> Generator[dict['Component', str], None, None]`
- `check_output_dir(self, lang: str, model_name: str, finetuning_type: str, output_dir: str)`
- `load_args(self, lang: str, config_path: str)`
- `monitor(self)`
- `preview_eval(self, data)`
- `preview_train(self, data)`
- `run_eval(self, data)`
- `run_train(self, data)`
- `save_args(self, data)`
- `set_abort(self) -> None`

---

## Class: `SFTDataCollatorWith4DAttentionMask`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `collator`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MultiModalDataCollatorForSeq2Seq`

### å±æ€§ (Attributes)
- `attn_implementation: Literal['eager', 'sdpa', 'flash_attention_2']`
- `block_diag_attn: bool`
- `compute_dtype: 'torch.dtype'`

### æ–¹æ³• (Methods)
- `__call__(self, features: list[dict[str, Any]]) -> dict[str, 'torch.Tensor']`

---

## Class: `SGLangArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_args`

### å±æ€§ (Attributes)
- `sglang_config: Optional[Union[dict, str]]`
- `sglang_maxlen: int`
- `sglang_mem_fraction: float`
- `sglang_tp_size: int`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `SGLangEngine`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `sglang_engine`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseEngine`

### å±æ€§ (Attributes)
- `can_generate`
- `generating_args`
- `model_args`
- `name`
- `processor`
- `template`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__del__(self)`
- `__init__(self, model_args: 'ModelArguments', data_args: 'DataArguments', finetuning_args: 'FinetuningArguments', generating_args: 'GeneratingArguments') -> None`
- `_cleanup_server(self)`

---

## Class: `SaveProcessorCallback`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `callbacks`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TrainerCallback`

### å±æ€§ (Attributes)
- `processor`

### æ–¹æ³• (Methods)
- `__init__(self, processor: 'ProcessorMixin') -> None`
- `on_save(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`
- `on_train_end(self, args: 'TrainingArguments', state: 'TrainerState', control: 'TrainerControl', **kwargs)`

---

## Class: `ScoreEvaluationRequest`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `max_length: Optional[int]`
- `messages: list[str]`
- `model: str`

---

## Class: `ScoreEvaluationResponse`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `id: str`
- `model: str`
- `object: Literal['score.evaluation']`
- `scores: list[float]`

---

## Class: `SharegptDatasetConverter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `converter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DatasetConverter`

### æ–¹æ³• (Methods)
- `__call__(self, example: dict[str, Any]) -> dict[str, Any]`

---

## Class: `StringFormatter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `formatter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Formatter`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `apply(self, **kwargs) -> SLOTS`

---

## Class: `SupervisedDatasetProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `supervised`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DatasetProcessor`

### æ–¹æ³• (Methods)
- `_encode_data_example(self, prompt: list[dict[str, str]], response: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput']) -> tuple[list[int], list[int]]`
- `preprocess_dataset(self, examples: dict[str, list[Any]]) -> dict[str, list[Any]]`
- `print_data_example(self, example: dict[str, list[int]]) -> None`

---

## Class: `SwanLabArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `finetuning_args`

### å±æ€§ (Attributes)
- `swanlab_api_key: Optional[str]`
- `swanlab_lark_secret: Optional[str]`
- `swanlab_lark_webhook_url: Optional[str]`
- `swanlab_logdir: Optional[str]`
- `swanlab_mode: Literal['cloud', 'local']`
- `swanlab_project: Optional[str]`
- `swanlab_run_name: Optional[str]`
- `swanlab_workspace: Optional[str]`
- `use_swanlab: bool`

---

## Class: `SwanLabCallbackExtension`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `trainer_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `SwanLabCallback`

### æ–¹æ³• (Methods)
- `setup(self, args: 'TrainingArguments', state: 'TrainerState', model: 'PreTrainedModel', **kwargs)`

---

## Class: `Template`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `template`

### å±æ€§ (Attributes)
- `default_system: str`
- `efficient_eos: bool`
- `format_assistant: 'Formatter'`
- `format_function: 'Formatter'`
- `format_observation: 'Formatter'`
- `format_prefix: 'Formatter'`
- `format_system: 'Formatter'`
- `format_tools: 'Formatter'`
- `format_user: 'Formatter'`
- `mm_plugin: 'BasePlugin'`
- `replace_eos: bool`
- `replace_jinja_template: bool`
- `stop_words: list[str]`
- `thought_words: tuple[str, str]`

### æ–¹æ³• (Methods)
- `_add_or_replace_eos_token(tokenizer: 'PreTrainedTokenizer', eos_token: str) -> None`
- `_convert_elements_to_ids(self, tokenizer: 'PreTrainedTokenizer', elements: 'SLOTS') -> list[int]`
- `_convert_slots_to_jinja(slots: 'SLOTS', tokenizer: 'PreTrainedTokenizer', placeholder: str) -> str`
- `_convert_slots_to_ollama(slots: 'SLOTS', tokenizer: 'PreTrainedTokenizer', placeholder: str) -> str`
- `_encode(self, tokenizer: 'PreTrainedTokenizer', messages: list[dict[str, str]], system: Optional[str], tools: Optional[str]) -> list[list[int]]`
- `_get_jinja_template(self, tokenizer: 'PreTrainedTokenizer') -> str`
- `_get_ollama_template(self, tokenizer: 'PreTrainedTokenizer') -> str`
- `_jinja_escape(content: str) -> str`
- `add_thought(self, content: str) -> str`
- `encode_multiturn(self, tokenizer: 'PreTrainedTokenizer', messages: list[dict[str, str]], system: Optional[str], tools: Optional[str]) -> list[tuple[list[int], list[int]]]`
- `encode_oneturn(self, tokenizer: 'PreTrainedTokenizer', messages: list[dict[str, str]], system: Optional[str], tools: Optional[str], enable_thinking: bool) -> tuple[list[int], list[int]]`
- `extract_tool(self, content: str) -> Union[str, list['FunctionCall']]`
- `fix_jinja_template(self, tokenizer: 'PreTrainedTokenizer') -> None`
- `fix_special_tokens(self, tokenizer: 'PreTrainedTokenizer') -> None`
- `get_ollama_modelfile(self, tokenizer: 'PreTrainedTokenizer') -> str`
- `get_stop_token_ids(self, tokenizer: 'PreTrainedTokenizer') -> list[int]`
- `get_thought_word_ids(self, tokenizer: 'PreTrainedTokenizer') -> list[int]`
- `remove_thought(self, content: str) -> str`

---

## Class: `TokenizerModule`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `loader`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TypedDict`

### å±æ€§ (Attributes)
- `processor: Optional['ProcessorMixin']`
- `tokenizer: 'PreTrainedTokenizer'`

---

## Class: `ToolFormatter`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `formatter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Formatter`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `apply(self, **kwargs) -> SLOTS`
- `extract(self, content: str) -> Union[str, list['FunctionCall']]`

---

## Class: `ToolUtils`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tool_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ABC`

### æ–¹æ³• (Methods)
- `function_formatter(functions: list['FunctionCall']) -> str`
- `tool_extractor(content: str) -> Union[str, list['FunctionCall']]`
- `tool_formatter(tools: list[dict[str, Any]]) -> str`

---

## Class: `TrainingArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `training_args`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `RayArguments`, `Seq2SeqTrainingArguments`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `URL`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `protocol`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `detail: Literal['auto', 'low', 'high']`
- `url: str`

---

## Class: `UltraChat`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `ultra_chat`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `datasets.GeneratorBasedBuilder`

### å±æ€§ (Attributes)
- `VERSION`

### æ–¹æ³• (Methods)
- `_generate_examples(self, filepaths: list[str])`
- `_info(self)`
- `_split_generators(self, dl_manager: datasets.DownloadManager)`

---

## Class: `UnslothGradientCheckpointing`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `checkpointing`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.autograd.Function`

### æ–¹æ³• (Methods)
- `backward(ctx: 'torch.autograd.Function', grad_output: 'torch.Tensor') -> 'torch.Tensor'`
- `forward(ctx: 'torch.autograd.Function', forward_function: 'torch.Module', hidden_states: 'torch.Tensor', *args) -> 'torch.Tensor'`

---

## Class: `UnsupervisedDatasetProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `unsupervised`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DatasetProcessor`

### æ–¹æ³• (Methods)
- `_encode_data_example(self, prompt: list[dict[str, str]], response: list[dict[str, str]], system: Optional[str], tools: Optional[str], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput']) -> tuple[list[int], list[int]]`
- `preprocess_dataset(self, examples: dict[str, list[Any]]) -> dict[str, list[Any]]`
- `print_data_example(self, example: dict[str, list[int]]) -> None`

---

## Class: `VideoLlavaPlugin`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_plugin`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePlugin`

### æ–¹æ³• (Methods)
- `process_messages(self, messages: list[dict[str, str]], images: list['ImageInput'], videos: list['VideoInput'], audios: list['AudioInput'], processor: Optional['MMProcessor']) -> list[dict[str, str]]`

---

## Class: `VllmArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_args`

### å±æ€§ (Attributes)
- `vllm_config: Optional[Union[dict, str]]`
- `vllm_enforce_eager: bool`
- `vllm_gpu_util: float`
- `vllm_max_lora_rank: int`
- `vllm_maxlen: int`

### æ–¹æ³• (Methods)
- `__post_init__(self)`

---

## Class: `VllmEngine`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vllm_engine`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseEngine`

### å±æ€§ (Attributes)
- `can_generate`
- `generating_args`
- `model`
- `model_args`
- `name`
- `processor`
- `template`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, model_args: 'ModelArguments', data_args: 'DataArguments', finetuning_args: 'FinetuningArguments', generating_args: 'GeneratingArguments') -> None`

---

## Class: `WebChatModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `chatter`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ChatModel`

### å±æ€§ (Attributes)
- `demo_mode`
- `engine: Optional[BaseEngine]`
- `manager`

### æ–¹æ³• (Methods)
- `__init__(self, manager: 'Manager', demo_mode: bool, lazy_init: bool) -> None`
- `append(chatbot: list[dict[str, str]], messages: list[dict[str, str]], role: str, query: str, escape_html: bool) -> tuple[list[dict[str, str]], list[dict[str, str]], str]`
- `load_model(self, data) -> Generator[str, None, None]`
- `loaded(self) -> bool`
- `stream(self, chatbot: list[dict[str, str]], messages: list[dict[str, str]], lang: str, system: str, tools: str, image: Optional[Any], video: Optional[Any], audio: Optional[Any], max_new_tokens: int, top_p: float, temperature: float, skip_special_tokens: bool, escape_html: bool, enable_thinking: bool) -> Generator[tuple[list[dict[str, str]], list[dict[str, str]]], None, None]`
- `unload_model(self, data) -> Generator[str, None, None]`

---

## Class: `_Logger`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `logging`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `logging.Logger`

### æ–¹æ³• (Methods)
- `info_rank0(self, *args, **kwargs) -> None`
- `warning_rank0(self, *args, **kwargs) -> None`
- `warning_rank0_once(self, *args, **kwargs) -> None`

---


[ä¿¡æ¯] UML å›¾è¡¨ 'llama_factory_uml.png' ä¹Ÿå·²é€šè¿‡ WebSocket ç›´æ¥å‘é€ã€‚
2025-05-15 15:49:39.321 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 3 as completed in plan plan_1747295325
2025-05-15 15:49:39.323 | INFO     | agents.base:run:129 - Executing step 5/20
2025-05-15 15:49:57.867 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: æˆ‘å·²ç»å®Œæˆäº†æ‰€æœ‰æ­¥éª¤ï¼Œç°åœ¨å¯ä»¥ç»“æŸä»»åŠ¡äº†ã€‚
2025-05-15 15:49:57.867 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:49:57.867 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['final_response']
2025-05-15 15:49:57.870 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"content_to_deliver": "æˆ‘æ‰¾åˆ°äº†ä¸€ä¸ªåä¸º \'LLaMA-Factory\' çš„LoRAå¤§æ¨¡å‹é¡¹ç›®ï¼Œå¹¶ç”Ÿæˆäº†å®ƒçš„UMLç±»å›¾ã€‚ä»¥ä¸‹æ˜¯é¡¹ç›®çš„ç®€è¦ä»‹ç»å’ŒUMLå›¾ï¼š\n\n### é¡¹ç›®ç®€ä»‹ï¼š\nLLaMA-Factory æ˜¯ä¸€ä¸ªç”¨äºå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé›†æˆäº†å¤šç§å…ˆè¿›çš„é«˜æ•ˆè®­ç»ƒæ–¹æ³•ã€‚å®ƒå…è®¸ç”¨æˆ·é€šè¿‡å†…ç½®çš„Web UIçµæ´»å®šåˆ¶100å¤šä¸ªLLMsçš„å¾®è°ƒè¿‡ç¨‹ï¼Œè€Œæ— éœ€ç¼–å†™ä»£ç ã€‚\n\n### UML ç±»å›¾ï¼š\n![](D:\\\\deep_learning\\\\codes\\\\workspace\\\\LLaMA-Factory\\\\llama_factory_uml.png)\n\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„åˆ†ææˆ–æœ‰å…³æ­¤é¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼"}']
2025-05-15 15:49:57.870 | ERROR    | agents.tool_call:execute_tool:174 - âš ï¸ å·¥å…· 'final_response' æ‰§è¡Œå‡ºç°é”™è¯¯: Invalid control character at: line 1 column 89 (char 88)
2025-05-15 15:49:57.870 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'final_response' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º: é”™è¯¯: âš ï¸ å·¥å…· 'final_response' æ‰§è¡Œå‡ºç°é”™è¯¯: Invalid control character at: line 1 column 89 (char 88)
2025-05-15 15:49:57.871 | INFO     | agents.base:run:129 - Executing step 6/20
2025-05-15 15:50:14.109 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: æˆ‘å·²ç»å®Œæˆäº†æ‰€æœ‰æ­¥éª¤ï¼Œå¹¶ä¸”å‡†å¤‡ç»“æŸä»»åŠ¡ã€‚ä¹‹å‰å°è¯•å‘é€æœ€ç»ˆå›å¤æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¿™æ¬¡æˆ‘å°†ç¡®ä¿ä¿¡æ¯æ­£ç¡®æ— è¯¯ã€‚
2025-05-15 15:50:14.110 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:50:14.110 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['final_response']
2025-05-15 15:50:14.110 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"content_to_deliver":"æˆ‘æ‰¾åˆ°äº†ä¸€ä¸ªåä¸º \'LLaMA-Factory\' çš„LoRAå¤§æ¨¡å‹é¡¹ç›®ï¼Œå¹¶ç”Ÿæˆäº†å®ƒçš„UMLç±»å›¾ã€‚ä»¥ä¸‹æ˜¯é¡¹ç›®çš„ç®€è¦ä»‹ç»å’ŒUMLå›¾ï¼š\\n\\n### é¡¹ç›®ç®€ä»‹ï¼š\\nLLaMA-Factory æ˜¯ä¸€ä¸ªç”¨äºå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé›†æˆäº†å¤šç§å…ˆè¿›çš„é«˜æ•ˆè®­ç»ƒæ–¹æ³•ã€‚å®ƒå…è®¸ç”¨æˆ·é€šè¿‡å†…ç½®çš„Web UIçµæ´»å®šåˆ¶100å¤šä¸ªLLMsçš„å¾®è°ƒè¿‡ç¨‹ï¼Œè€Œæ— éœ€ç¼–å†™ä»£ç ã€‚\\n\\n### UML ç±»å›¾ï¼š\\n![](D:\\\\deep_learning\\\\codes\\\\workspace\\\\LLaMA-Factory\\\\llama_factory_uml.png)\\n\\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„åˆ†ææˆ–æœ‰å…³æ­¤é¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼"}']
2025-05-15 15:50:14.111 | INFO     | tools.summarize:execute:35 - ğŸ ä»£ç†çš„æœ€ç»ˆå›åº”: æˆ‘æ‰¾åˆ°äº†ä¸€ä¸ªåä¸º 'LLaMA-Factory' çš„LoRAå¤§æ¨¡å‹é¡¹ç›®ï¼Œå¹¶ç”Ÿæˆäº†å®ƒçš„UMLç±»å›¾ã€‚ä»¥ä¸‹æ˜¯é¡¹ç›®çš„ç®€è¦ä»‹ç»å’ŒUMLå›¾ï¼š

### é¡¹ç›®ç®€ä»‹ï¼š
LLaMA-Factory æ˜¯ä¸€ä¸ªç”¨äºå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé›†æˆäº†å¤šç§å…ˆè¿›çš„é«˜æ•ˆè®­ç»ƒæ–¹æ³•ã€‚å®ƒå…è®¸ç”¨æˆ·é€šè¿‡å†…ç½®çš„Web UIçµæ´»å®šåˆ¶100å¤šä¸ªLLMsçš„å¾®è°ƒè¿‡ç¨‹ï¼Œè€Œæ— éœ€ç¼–å†™ä»£ç ã€‚

### UML ç±»å›¾ï¼š
![](D:\deep_learning\codes\workspace\LLaMA-Factory\llama_factory_uml.png)

å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„åˆ†ææˆ–æœ‰å…³æ­¤é¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
2025-05-15 15:50:14.111 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'final_response' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:final_response`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
ä»£ç†å·²å¾—å‡ºä»¥ä¸‹æœ€ç»ˆå›åº”: æˆ‘æ‰¾åˆ°äº†ä¸€ä¸ªåä¸º 'LLaMA-Factory' çš„LoRAå¤§æ¨¡å‹é¡¹ç›®ï¼Œå¹¶ç”Ÿæˆäº†å®ƒçš„UMLç±»å›¾ã€‚ä»¥ä¸‹æ˜¯é¡¹ç›®çš„ç®€è¦ä»‹ç»å’ŒUMLå›¾ï¼š

### é¡¹ç›®ç®€ä»‹ï¼š
LLaMA-Factory æ˜¯ä¸€ä¸ªç”¨äºå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé›†æˆäº†å¤šç§å…ˆè¿›çš„é«˜æ•ˆè®­ç»ƒæ–¹æ³•ã€‚å®ƒå…è®¸ç”¨æˆ·é€šè¿‡å†…ç½®çš„Web UIçµæ´»å®šåˆ¶100å¤šä¸ªLLMsçš„å¾®è°ƒè¿‡ç¨‹ï¼Œè€Œæ— éœ€ç¼–å†™ä»£ç ã€‚

### UML ç±»å›¾ï¼š
![](D:\deep_learning\codes\workspace\LLaMA-Factory\llama_factory_uml.png)

å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„åˆ†ææˆ–æœ‰å…³æ­¤é¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
2025-05-15 15:50:14.111 | INFO     | agents.base:run:129 - Executing step 7/20
2025-05-15 15:50:16.280 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: æ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼Œç°åœ¨å¯ä»¥ç»ˆæ­¢ä»»åŠ¡äº†ã€‚
2025-05-15 15:50:16.281 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:50:16.281 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['terminate']
2025-05-15 15:50:16.281 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"status": "success"}']
2025-05-15 15:50:16.282 | INFO     | agents.tool_call:_handle_special_tool:183 - ğŸ Special tool 'terminate' has completed the task!
2025-05-15 15:50:16.282 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'terminate' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:terminate`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
The interaction has been completed with status: success
2025-05-15 15:50:59.054 | INFO     | main:websocket_endpoint:56 - Received message from 127.0.0.1:54336: ç»™æˆ‘æ‰¾ä¸€ä¸ªminimindçš„é¡¹ç›®ï¼Œåˆ†æuml
2025-05-15 15:50:59.055 | INFO     | agents.umlagent:create_initial_plan:214 - Creating initial plan with ID: plan_1747295459
2025-05-15 15:51:04.350 | INFO     | agents.umlagent:create_initial_plan:243 -  ç»“æœä¸º:  `å·¥å…·:planning`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
Plan created successfully with ID: plan_1747295459

Plan: å¯»æ‰¾å¹¶åˆ†æminimindé¡¹ç›®UML (ID: plan_1747295459)
===============================================

Progress: 0/4 steps completed (0.0%)
Status: 0 completed, 0 in progress, 0 blocked, 4 not started

Steps:
0. [ ] ä½¿ç”¨ç™¾åº¦æœç´¢å·¥å…·æœç´¢minimindç›¸å…³é¡¹ç›®
1. [ ] é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„minimindé¡¹ç›®è¿›è¡Œå…‹éš†
2. [ ] ç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLç±»å›¾
3. [ ] åˆ†æå¹¶æ€»ç»“UMLç±»å›¾ç»“æœ

2025-05-15 15:51:04.350 | INFO     | agents.base:run:119 - websocket initialized finish, state:<starlette.datastructures.State object at 0x0000018E2CB27FE0>
2025-05-15 15:51:04.350 | INFO     | agents.base:run:129 - Executing step 8/20
2025-05-15 15:51:13.126 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: è®¡åˆ’å·²åˆ›å»ºï¼Œæ¥ä¸‹æ¥æˆ‘å°†æ‰§è¡Œç¬¬ä¸€ä¸ªæ­¥éª¤ï¼šä½¿ç”¨ç™¾åº¦æœç´¢å·¥å…·æœç´¢minimindç›¸å…³é¡¹ç›®ã€‚
2025-05-15 15:51:13.126 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:51:13.126 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['baidu_search']
2025-05-15 15:51:13.126 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"query": "minimind é¡¹ç›® github"}']
2025-05-15 15:51:14.321 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'baidu_search' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:baidu_search`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
[{'title': 'minimind é¡¹ç›® github\n\xa0-\xa0ç²¾é€‰ç¬”è®°', 'abstract': 'minimind é¡¹ç›® github\n\xa0-\xa0ç²¾é€‰ç¬”è®°\n\n\n\n\n\n\n\n\n\né›¶åŸºç¡€ç©è½¬aiè¿™ä¸ªå¼€æºé¡¹ç›®è®©æ™®é€šç”µè„‘ä¹Ÿèƒ½è·‘è¯­è¨€æ¨¡å‹å¤ªé˜³é¸Ÿ\n\n\n\n\n\n\næ¯æ—¥çƒ­é—¨ GitHub Trending å¼€æºé¡¹ç›®æ¨èã€‚ 1ã€twmb/franz-go æœ‰è¶…è¿‡ 1.9k Star,ä½¿ç”¨ Go å¼€å‘,Franz-goæ˜¯ä¸€ä¸ªç”¨Goå®Œå…¨ç¼–å†™çš„Apache Kafkaå®¢æˆ·ç«¯åº“,æ”¯æŒä»Kafka 0.8.0è‡³3.8+çš„å…¨éƒ¨ç‰¹æ€§,åŒ…æ‹¬äº‹åŠ¡ã€æ­£åˆ™è¡¨è¾¾å¼ä¸»é¢˜æ¶ˆè´¹ã€é«˜çº§ç®¡ç†ç­‰åŠŸèƒ½ã€‚ 2ã€jingyaogong/minimind æœ‰è¶…è¿‡ 4.1k Star,ä½¿ç”¨ Python å¼€å‘,MiniMindé¡¹ç›®å¼€åˆ›æ€§åœ°å®ç°äº†åœ¨3å°æ—¶å†…ä»é›¶è®­ç»ƒ', 'url': 'http://www.baidu.com/link?url=MfJvggOvgPUBBSEf5Twk4wHLxaNQNO29tKtgpsBb7A7LieRWzECXJ1f2N1kogdlHICvcFMo_S3fzCfBHu2rtO7vuHrt7cIQttR9miaEz7hmnYPYg4mY7LGD8COM37nHoQ65GTiuJH_4m9uF9utYA7K', 'rank': 1}, {'title': 'GitHub - perfree/minimind: ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€2å°æ—¶å®Œå…¨ä»0...', 'abstract': 'GitHub - perfree/minimind: ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€2å°æ—¶å®Œå…¨ä»0...2025å¹´2æœˆ9æ—¥  æ­¤å¼€æºé¡¹ç›®æ—¨åœ¨å®Œå…¨ä»0å¼€å§‹,ä»…ç”¨3å—é’±æˆæœ¬ + 2å°æ—¶!å³å¯è®­ç»ƒå‡ºä»…ä¸º25.8Mçš„è¶…å°è¯­è¨€æ¨¡å‹MiniMindã€‚ MiniMindç³»åˆ—æå…¶è½»é‡,æœ€å°ç‰ˆæœ¬ä½“ç§¯æ˜¯ GPT-3 çš„17000,åŠ›æ±‚åš...GitHub\ue62b', 'url': 'http://www.baidu.com/link?url=jj0CGT0fvkGGXA-99XwwfsEfKSF9yoiFG7QWkBT2ttziYdHaPXaQxMW9rmp-FbLE', 'rank': 2}, {'title': 'å¤§å®¶è¿˜åœ¨æœgithubå®˜ç½‘Githubä¸­æ–‡ç‰ˆgithubæ˜Ÿæœ€å¤šçš„é¡¹ç›®githubä¼˜ç§€javaå¼€æºé¡¹ç›®githubçƒ­é—¨å¼€æºé¡¹ç›®githubå¥½ç©çš„é¡¹ç›®githubä¼˜ç§€å¼€æºé¡¹ç›®githubçƒ­é—¨é¡¹ç›®', 'abstract': 'å¤§å®¶è¿˜åœ¨æœgithubå®˜ç½‘Githubä¸­æ–‡ç‰ˆgithubæ˜Ÿæœ€å¤šçš„é¡¹ç›®githubä¼˜ç§€javaå¼€æºé¡¹ç›®githubçƒ­é—¨å¼€æºé¡¹ç›®githubå¥½ç©çš„é¡¹ç›®githubä¼˜ç§€å¼€æºé¡¹ç›®githubçƒ­é—¨é¡¹ç›®', 'url': '/s?wd=github%E5%AE%98%E7%BD%91&usm=2&ie=utf-8&rsv_pq=8859f909009c4073&oq=minimind%20%E9%A1%B9%E7%9B%AE%20github&rsv_t=c1273pOHhPWHoxoM%2BQiwjCPCuEGooAhBZLidBpy%2F6i8NT%2Bv1xbTxToaNMIg&rsf=101636803&rsv_dl=0_prs_28608_1', 'rank': 3}, {'title': '2025-02-18 Github çƒ­ç‚¹é¡¹ç›® minimind:3å°æ—¶è®­ç»ƒä¸ªäººGPUè½»...', 'abstract': '2025-02-18 Github çƒ­ç‚¹é¡¹ç›® minimind:3å°æ—¶è®­ç»ƒä¸ªäººGPUè½»...\n\n\n\n\n\n\n\n\n2025å¹´2æœˆ18æ—¥  GitHub - jingyaogong/minimind: ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€2å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPT!ğŸŒ Train a 26M-parameter GPT from scratch in just 2h! MiniMind æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®,æ—¨åœ¨ä»...\n\n\n\n\nCSDNåšå®¢\ue62b\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=CuEz-0nCSRlaWRzdlthJICOPEZP5GSgn3iyOy5sRvLI898VbdlAs7U6VHjj7S77kGzpf1fKo217t5NtDQ6jJU-XTGRiMK-0zCuW9krn90hG', 'rank': 4}, {'title': 'AIå­¦ä¹ è®°å½• - ä¾æ® minimind é¡¹ç›®å…¥é—¨_minimind github-CS...', 'abstract': 'AIå­¦ä¹ è®°å½• - ä¾æ® minimind é¡¹ç›®å…¥é—¨_minimind github-CS...\n\n\n\n\n\n\n\n\n2024å¹´12æœˆ19æ—¥  æƒ³å­¦ä¹ AI,è¿˜æ˜¯éœ€è¦ä»å¤´åˆ°å°¾è·‘ä¸€è¾¹æµç¨‹,æœ€è¿‘çœ‹åˆ°è¿™ä¸ªé¡¹ç›® minimind, æˆ‘ä¹Ÿè®°å½•ä¸‹å­¦ä¹ åˆ°çš„ä¸œè¥¿,éœ€è¦ç»“åˆé¡¹ç›®çš„readmeçœ‹ã€‚ 1ã€githubé“¾æ¥ https://github.com/jingyaogong/minim...\n\n\n\n\nCSDNåšå®¢\ue62b\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=l-TYlLTfwd_wKXURXWd0cIP25gX79uIZVBHZ8nGHHCScyrC6RH3R_lJyQ9qwlv3NXI2BR_2jBYfE5E5Jmc7Uq03FbxQAqGE0YylOjuSVCSi', 'rank': 5}, {'title': 'minimind/model/LMConfig.py at master Â· perfree/minimi...', 'abstract': 'minimind/model/LMConfig.py at master Â· perfree/minimi...2025å¹´2æœˆ9æ—¥  from transformers import PretrainedConfig from typing import List class LMConfig(PretrainedConfig): model_type = "minimind" def __init__( self, dim: ...GitHub\ue62b', 'url': 'http://www.baidu.com/link?url=n635mss6Itgq9vI8bBZB2Xc-NKpAfKUDbwPo-PfmvgjSNadcpU_G5p8zQds7cB3mTcl6e_gSlIybdaYiCip4SdT8ukaQgUXe_Uba79VP2Ua', 'rank': 6}, {'title': 'æ™®é€šäººä»0å¼€å§‹è®­ç»ƒLLMå¤§è¯­è¨€æ¨¡å‹ - é£å§‹äºé’èæœ« - åšå®¢å›­', 'abstract': 'æ™®é€šäººä»0å¼€å§‹è®­ç»ƒLLMå¤§è¯­è¨€æ¨¡å‹ - é£å§‹äºé’èæœ« - åšå®¢å›­\n\n\n\n\n\n\n\n\n2025å¹´2æœˆ10æ—¥  æ™®é€šäººä»0å¼€å§‹è®­ç»ƒLLMå¤§è¯­è¨€æ¨¡å‹ é¦–å…ˆå£°æ˜ã€‚æœ¬é¡¹ç›®åŸºäºå¼€æºé¡¹ç›®:MiniMind,åŸºäºä¸ªäººçš„ç†è§£å’Œè¸©å‘ã€‚åšäº†ä¸ªäººçš„ç†è§£å’Œæ³¨é‡Šã€‚å®Œæˆä»å°ç™½å¼€å§‹,ä»0è®­ç»ƒä¸€ä¸ªLLMå¤§è¯­è¨€æ¨¡å‹ã€‚é¡¹ç›®æºåœ°...åšå®¢å›­\ue62b\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=mRH7aCgjfi3oLSuxmVoiShF-zqrUoz1-k49Mi0a30ZLv709g5OAcxLaextheMJUrDrVxrme6Y6QatiRh4x98LA7d5HDA4NHN8AC--AoX42C', 'rank': 7}, {'title': '6ä¸ª GitHub ä¸Šç‹‚é£™çš„ AI æ•™ç¨‹,ç‰›å•Šã€‚LLM-Universe æœ¬æ–‡ä¼š...', 'abstract': '6ä¸ª GitHub ä¸Šç‹‚é£™çš„ AI æ•™ç¨‹,ç‰›å•Šã€‚LLM-Universe æœ¬æ–‡ä¼š...\n\n\n\n\n\n\n\n\n2025å¹´2æœˆ28æ—¥  06ã€MiniMind è¿™ä¸ªå¼€æºé¡¹ç›®,å¯ä»¥è®©ä¸ªäººå®Œå…¨ä» 0 è®­ç»ƒä¸€ä¸ªä»…æœ‰ 26M çš„æå°å‚æ•°å¤§è¯­è¨€æ¨¡å‹!æœ€ä½ä»…éœ€ 2G æ˜¾å¡å³å¯è®­ç»ƒå’Œæ¨ç†,æœ€å¿«ä»…éœ€2-3å°æ—¶ã€‚ ç›®å‰è¿™ä¸ªå¼€æºé¡¹ç›® MiniMind å·²ç»...\n\n\n\n\næ˜é‡‘å¼€å‘è€…ç¤¾åŒº\ue62b\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=SzyxcOFm207Sk3MJzYZVetSqPZkJUI5QHoZDCuH40PDL3w2oaboEVjDdukm6LHjKYx6czNnsr_FyFowjOMO-Ya', 'rank': 8}, {'title': 'GitHub ä¸Šè¾ƒç«çš„ä¸€ä¸ª AI é¡¹ç›®:MiniMind ... æ¥è‡ªMakeiss -...', 'abstract': 'GitHub ä¸Šè¾ƒç«çš„ä¸€ä¸ª AI é¡¹ç›®:MiniMind ... æ¥è‡ªMakeiss -...2025å¹´3æœˆ4æ—¥  GitHub ä¸Šè¾ƒç«çš„ä¸€ä¸ª AI é¡¹ç›®:MiniMindã€‚æ­¤å¼€æºé¡¹ç›®æ—¨åœ¨å®Œå…¨ä» 0 å¼€å§‹,ä»…ç”¨ 3 å—é’±æˆæœ¬ + 2å°æ—¶,å³å¯è®­ç»ƒå‡ºä»…ä¸º 25.8M çš„è¶…å°è¯­è¨€æ¨¡å‹MiniMindã€‚GitHub:Oç½‘é¡µé“¾...å¾®åš\ue62b', 'url': 'http://www.baidu.com/link?url=V5NXU-22fC_d58IFCB5Cuz4I7A8UM8rrl9ccjcsYZX4phhsyZcJ3v5gvRlHq3Vy-', 'rank': 9}, {'title': 'MiniMindå¾®å‹è¯­è¨€æ¨¡å‹,è®©ä½ è½»æ¾å¼€å¯AIå¯¹è¯! - å“”å“©å“”å“©', 'abstract': 'MiniMindå¾®å‹è¯­è¨€æ¨¡å‹,è®©ä½ è½»æ¾å¼€å¯AIå¯¹è¯! - å“”å“©å“”å“©\n\n\n\n\n\n\n\n\n2024å¹´12æœˆ18æ—¥  git clone https://github.com/jingyaogong/minimind.git è¯·æ³¨æ„,å¦‚æœ git clone https://github.com/01-ai/Yi-Coder.git è¿™ä¸ªé“¾æ¥ä¸å­˜åœ¨æˆ–è€…æ— æ•ˆ,git clone å‘½ä»¤å°†ä¸ä¼šæˆåŠŸ...å“”å“©å“”å“©\ue62b\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=nwojUqfUMfI_4r-aFlSgkvRmz2Z8CYZhAeYpXiQJwmVRqZVR7_72A8c0ZElSO2OzSw-x0_GTPwfcvaV0DFe3Fq', 'rank': 10}]
2025-05-15 15:51:14.323 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 0 as completed in plan plan_1747295459
2025-05-15 15:51:14.323 | INFO     | agents.base:run:129 - Executing step 9/20
2025-05-15 15:51:28.586 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: Using tools response: æˆ‘å·²ç»æ‰¾åˆ°äº†å…³äºminimindçš„ç›¸å…³é¡¹ç›®ï¼Œæ¥ä¸‹æ¥æˆ‘å°†æ‰§è¡Œæ­¥éª¤äºŒï¼šé€‰æ‹©ä¸€ä¸ªåˆé€‚çš„minimindé¡¹ç›®è¿›è¡Œå…‹éš†ã€‚æ ¹æ®æœç´¢ç»“æœï¼Œæˆ‘é€‰æ‹©äº† 'perfree/minimind' è¿™ä¸ªé¡¹ç›®ã€‚ç°åœ¨æˆ‘å°†å…‹éš†è¿™ä¸ªGitHubä»“åº“åˆ°æœ¬åœ°ã€‚
2025-05-15 15:51:28.588 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:51:28.588 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['github_repo_cloner_ssh']
2025-05-15 15:51:28.589 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_name": "perfree/minimind"}']
2025-05-15 15:53:25.846 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'github_repo_cloner_ssh' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:github_repo_cloner_ssh`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
D:\deep_learning\codes\workspace\minimind
2025-05-15 15:53:25.846 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 1 as completed in plan plan_1747295459
2025-05-15 15:53:25.847 | INFO     | agents.base:run:129 - Executing step 10/20
2025-05-15 15:53:41.145 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: Using tools response: æˆ‘å·²ç»æˆåŠŸå…‹éš†äº† 'perfree/minimind' ä»“åº“åˆ°æœ¬åœ°ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†ç”Ÿæˆè¯¥é¡¹ç›®çš„UMLç±»å›¾ã€‚
2025-05-15 15:53:41.145 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:53:41.145 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['code_to_uml_generator_multilang']
2025-05-15 15:53:41.145 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_path": "D:\\\\deep_learning\\\\codes\\\\workspace\\\\minimind", "output_png_path": "D:\\\\deep_learning\\\\codes\\\\workspace\\\\minimind\\\\minimind_uml.png", "target_languages": ["python"]}']
2025-05-15 15:53:41.905 | INFO     | tools.uml:execute:696 - å‡†å¤‡é€šè¿‡ WebSocket å‘é€ UML å›¾ç‰‡ 'minimind_uml.png'ã€‚
2025-05-15 15:53:41.905 | INFO     | tools.uml:execute:711 - UML å›¾ç‰‡ 'minimind_uml.png' å·²é€šè¿‡ WebSocket å‘é€ (42799 å­—èŠ‚)ã€‚
2025-05-15 15:53:41.905 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'code_to_uml_generator_multilang' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:code_to_uml_generator_multilang`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
UML å›¾è¡¨å’Œæ–‡æœ¬æè¿°å·²æˆåŠŸç”Ÿæˆã€‚
PNG å›¾åƒä¿å­˜è·¯å¾„: 'D:\deep_learning\codes\workspace\minimind\minimind_uml.png'

---
UML å›¾è¡¨æ–‡æœ¬æè¿°å†…å®¹:
---
# UML å›¾è¡¨æ–‡æœ¬æè¿°

## Class: `Attention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attn_dropout`
- `dropout`
- `flash`
- `head_dim`
- `n_kv_heads`
- `n_local_heads`
- `n_local_kv_heads`
- `n_rep`
- `resid_dropout`
- `wk`
- `wo`
- `wq`
- `wv`

### æ–¹æ³• (Methods)
- `__init__(self, args: LMConfig)`
- `forward(self, x: torch.Tensor, pos_cis: torch.Tensor, past_key_value: Optional[Tuple[torch.Tensor, torch.Tensor]], use_cache)`

---

## Class: `ChatRequest`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `serve_openai_api`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseModel`

### å±æ€§ (Attributes)
- `max_tokens: int`
- `messages: list`
- `model: str`
- `stream: bool`
- `temperature: float`
- `top_p: int`

---

## Class: `DPODataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `dataset`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Dataset`

### å±æ€§ (Attributes)
- `bos_id`
- `eos_id`
- `max_length`
- `padding`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__getitem__(self, index)`
- `__init__(self, file_path, tokenizer, max_length)`
- `__len__(self)`
- `_generate_loss_mask(self, input_ids)`

---

## Class: `FeedForward`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `dropout`
- `w1`
- `w2`
- `w3`

### æ–¹æ³• (Methods)
- `__init__(self, config: LMConfig)`
- `forward(self, x)`

---

## Class: `LMConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `LMConfig`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PretrainedConfig`

### å±æ€§ (Attributes)
- `aux_loss_alpha`
- `dim`
- `dropout`
- `flash_attn`
- `hidden_dim`
- `max_seq_len`
- `model_type`
- `multiple_of`
- `n_heads`
- `n_kv_heads`
- `n_layers`
- `n_routed_experts`
- `n_shared_experts`
- `norm_eps`
- `norm_topk_prob`
- `num_experts_per_tok`
- `rope_theta`
- `scoring_func`
- `seq_aux`
- `use_moe`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, dim: int, n_layers: int, n_heads: int, n_kv_heads: int, vocab_size: int, hidden_dim: int, multiple_of: int, norm_eps: float, max_seq_len: int, rope_theta: int, dropout: float, flash_attn: bool, use_moe: bool, num_experts_per_tok: int, n_routed_experts: int, n_shared_experts: bool, scoring_func: str, aux_loss_alpha: float, seq_aux: bool, norm_topk_prob: bool, **kwargs)`

---

## Class: `LoRA`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_lora`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `A`
- `B`
- `rank`

### æ–¹æ³• (Methods)
- `__init__(self, in_features, out_features, rank)`
- `forward(self, x)`

---

## Class: `MOEFeedForward`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `experts`
- `gate`

### æ–¹æ³• (Methods)
- `__init__(self, config: LMConfig)`
- `forward(self, x)`
- `moe_infer(self, x, flat_expert_indices, flat_expert_weights)`

---

## Class: `MiniMindBlock`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attention`
- `attention_norm`
- `dim`
- `feed_forward`
- `ffn_norm`
- `head_dim`
- `layer_id`
- `n_heads`

### æ–¹æ³• (Methods)
- `__init__(self, layer_id: int, config: LMConfig)`
- `forward(self, x, pos_cis, past_key_value, use_cache)`

---

## Class: `MiniMindLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModel`

### å±æ€§ (Attributes)
- `OUT`
- `config_class`
- `dropout`
- `layers`
- `norm`
- `output`
- `params`
- `tok_embeddings`

### æ–¹æ³• (Methods)
- `__init__(self, params: LMConfig)`
- `_stream(self, input_ids, eos_token_id, max_new_tokens, temperature, top_p, rp, use_cache, **args)`
- `forward(self, input_ids: Optional[torch.Tensor], past_key_values: Optional[List[Tuple[torch.Tensor, torch.Tensor]]], use_cache: bool, **args)`
- `generate(self, input_ids, eos_token_id, max_new_tokens, temperature, top_p, stream, rp, use_cache, pad_token_id, **args)`

---

## Class: `MoEGate`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `alpha`
- `config`
- `gating_dim`
- `n_routed_experts`
- `norm_topk_prob`
- `scoring_func`
- `seq_aux`
- `top_k`
- `weight`

### æ–¹æ³• (Methods)
- `__init__(self, config: LMConfig)`
- `forward(self, hidden_states)`
- `reset_parameters(self) -> None`

---

## Class: `PretrainDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `dataset`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Dataset`

### å±æ€§ (Attributes)
- `max_length`
- `samples`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__getitem__(self, index)`
- `__init__(self, data_path, tokenizer, max_length)`
- `__len__(self)`
- `load_data(self, path)`

---

## Class: `RMSNorm`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.nn.Module`

### å±æ€§ (Attributes)
- `eps`
- `weight`

### æ–¹æ³• (Methods)
- `__init__(self, dim: int, eps: float)`
- `forward(self, x)`

---

## Class: `SFTDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `dataset`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Dataset`

### å±æ€§ (Attributes)
- `bos_id`
- `eos_id`
- `max_length`
- `samples`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__getitem__(self, index)`
- `__init__(self, jsonl_path, tokenizer, max_length)`
- `__len__(self)`
- `_create_chat_prompt(self, conversations)`
- `_generate_loss_mask(self, input_ids)`
- `load_data(self, path)`

---


[ä¿¡æ¯] UML å›¾è¡¨ 'minimind_uml.png' ä¹Ÿå·²é€šè¿‡ WebSocket ç›´æ¥å‘é€ã€‚
2025-05-15 15:53:41.908 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 2 as completed in plan plan_1747295459
2025-05-15 15:53:41.913 | INFO     | agents.base:run:129 - Executing step 11/20
2025-05-15 15:54:17.443 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: Using tools response: æˆ‘å·²ç»ç”Ÿæˆäº† 'perfree/minimind' é¡¹ç›®çš„UMLç±»å›¾ï¼Œæ¥ä¸‹æ¥æˆ‘å°†åˆ†æå¹¶æ€»ç»“è¿™ä¸ªUMLç±»å›¾çš„ç»“æœã€‚
2025-05-15 15:54:17.443 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:54:17.443 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['final_response']
2025-05-15 15:54:17.443 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"content_to_deliver":"åœ¨åˆ†æminimindé¡¹ç›®æ—¶ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†å…¶UMLç±»å›¾ï¼Œå¹¶å‘ç°äº†ä¸€äº›å…³é”®çš„ç±»å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦çš„ç±»åŠå…¶åŠŸèƒ½æ¦‚è¿°ï¼š\\n\\n### ä¸»è¦ç±»åŠåŠŸèƒ½ï¼š\\n1. **Attention**:\\n   - å®ç°æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚\\n   - åŒ…å«å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œç”¨äºå¤„ç†è¾“å…¥å¼ é‡ã€‚\\n\\n2. **ChatRequest**:\\n   - å®šä¹‰äº†èŠå¤©è¯·æ±‚çš„ç»“æ„ï¼ŒåŒ…æ‹¬æœ€å¤§tokenæ•°ã€æ¶ˆæ¯åˆ—è¡¨ã€æ¨¡å‹åç§°ç­‰ã€‚\\n\\n3. **DPODataset** å’Œ **SFTDataset**:\\n   - åˆ†åˆ«ç”¨äºæ•°æ®é›†çš„ä¸åŒç”¨é€”ï¼ˆå¦‚ç›´æ¥åå¥½ä¼˜åŒ–å’Œç›‘ç£å¾®è°ƒï¼‰ï¼ŒåŒ…å«æ•°æ®åŠ è½½å’Œå¤„ç†çš„æ–¹æ³•ã€‚\\n\\n4. **FeedForward** å’Œ **MOEFeedForward**:\\n   - å‰è€…å®ç°æ ‡å‡†çš„å‰é¦ˆç½‘ç»œï¼Œåè€…å¼•å…¥äº†ä¸“å®¶æ··åˆï¼ˆMoEï¼‰æœºåˆ¶ä»¥æé«˜æ•ˆç‡ã€‚\\n\\n5. **LMConfig**:\\n   - é…ç½®è¯­è¨€æ¨¡å‹çš„å…³é”®å‚æ•°ï¼Œä¾‹å¦‚ç»´åº¦ã€å±‚æ•°ã€å¤´éƒ¨æ•°é‡ç­‰ã€‚\\n\\n6. **MiniMindBlock**:\\n   - è¡¨ç¤ºæ¨¡å‹ä¸­çš„ä¸€ä¸ªå—ï¼Œæ•´åˆäº†æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆå±‚ã€‚\\n\\n7. **MiniMindLM**:\\n   - æ ¸å¿ƒçš„è¯­è¨€æ¨¡å‹ç±»ï¼Œè´Ÿè´£æ•´ä½“çš„å‰å‘ä¼ æ’­å’Œç”Ÿæˆè¿‡ç¨‹ã€‚\\n\\n8. **RMSNorm**:\\n   - å®ç°äº†å½’ä¸€åŒ–æ“ä½œï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚\\n\\n9. **LoRA**:\\n   - å®ç°ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æŠ€æœ¯ï¼Œç”¨äºé«˜æ•ˆå¾®è°ƒå¤§å‹æ¨¡å‹ã€‚\\n\\n### UML ç±»å›¾ï¼š\\n![](D:\\\\deep_learning\\\\codes\\\\workspace\\\\minimind\\\\minimind_uml.png)\\n\\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„åˆ†ææˆ–æœ‰å…³æ­¤é¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼"}']
2025-05-15 15:54:17.443 | INFO     | tools.summarize:execute:35 - ğŸ ä»£ç†çš„æœ€ç»ˆå›åº”: åœ¨åˆ†æminimindé¡¹ç›®æ—¶ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†å…¶UMLç±»å›¾ï¼Œå¹¶å‘ç°äº†ä¸€äº›å…³é”®çš„ç±»å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦çš„ç±»åŠå…¶åŠŸèƒ½æ¦‚è¿°ï¼š

### ä¸»è¦ç±»åŠåŠŸèƒ½ï¼š
1. **Attention**:
   - å®ç°æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚
   - åŒ…å«å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œç”¨äºå¤„ç†è¾“å…¥å¼ é‡ã€‚

2. **ChatRequest**:
   - å®šä¹‰äº†èŠå¤©è¯·æ±‚çš„ç»“æ„ï¼ŒåŒ…æ‹¬æœ€å¤§tokenæ•°ã€æ¶ˆæ¯åˆ—è¡¨ã€æ¨¡å‹åç§°ç­‰ã€‚

3. **DPODataset** å’Œ **SFTDataset**:
   - åˆ†åˆ«ç”¨äºæ•°æ®é›†çš„ä¸åŒç”¨é€”ï¼ˆå¦‚ç›´æ¥åå¥½ä¼˜åŒ–å’Œç›‘ç£å¾®è°ƒï¼‰ï¼ŒåŒ…å«æ•°æ®åŠ è½½å’Œå¤„ç†çš„æ–¹æ³•ã€‚

4. **FeedForward** å’Œ **MOEFeedForward**:
   - å‰è€…å®ç°æ ‡å‡†çš„å‰é¦ˆç½‘ç»œï¼Œåè€…å¼•å…¥äº†ä¸“å®¶æ··åˆï¼ˆMoEï¼‰æœºåˆ¶ä»¥æé«˜æ•ˆç‡ã€‚

5. **LMConfig**:
   - é…ç½®è¯­è¨€æ¨¡å‹çš„å…³é”®å‚æ•°ï¼Œä¾‹å¦‚ç»´åº¦ã€å±‚æ•°ã€å¤´éƒ¨æ•°é‡ç­‰ã€‚

6. **MiniMindBlock**:
   - è¡¨ç¤ºæ¨¡å‹ä¸­çš„ä¸€ä¸ªå—ï¼Œæ•´åˆäº†æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆå±‚ã€‚

7. **MiniMindLM**:
   - æ ¸å¿ƒçš„è¯­è¨€æ¨¡å‹ç±»ï¼Œè´Ÿè´£æ•´ä½“çš„å‰å‘ä¼ æ’­å’Œç”Ÿæˆè¿‡ç¨‹ã€‚

8. **RMSNorm**:
   - å®ç°äº†å½’ä¸€åŒ–æ“ä½œï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚

9. **LoRA**:
   - å®ç°ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æŠ€æœ¯ï¼Œç”¨äºé«˜æ•ˆå¾®è°ƒå¤§å‹æ¨¡å‹ã€‚

### UML ç±»å›¾ï¼š
![](D:\deep_learning\codes\workspace\minimind\minimind_uml.png)

å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„åˆ†ææˆ–æœ‰å…³æ­¤é¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
2025-05-15 15:54:17.443 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'final_response' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:final_response`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
ä»£ç†å·²å¾—å‡ºä»¥ä¸‹æœ€ç»ˆå›åº”: åœ¨åˆ†æminimindé¡¹ç›®æ—¶ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†å…¶UMLç±»å›¾ï¼Œå¹¶å‘ç°äº†ä¸€äº›å…³é”®çš„ç±»å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦çš„ç±»åŠå…¶åŠŸèƒ½æ¦‚è¿°ï¼š

### ä¸»è¦ç±»åŠåŠŸèƒ½ï¼š
1. **Attention**:
   - å®ç°æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚
   - åŒ…å«å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œç”¨äºå¤„ç†è¾“å…¥å¼ é‡ã€‚

2. **ChatRequest**:
   - å®šä¹‰äº†èŠå¤©è¯·æ±‚çš„ç»“æ„ï¼ŒåŒ…æ‹¬æœ€å¤§tokenæ•°ã€æ¶ˆæ¯åˆ—è¡¨ã€æ¨¡å‹åç§°ç­‰ã€‚

3. **DPODataset** å’Œ **SFTDataset**:
   - åˆ†åˆ«ç”¨äºæ•°æ®é›†çš„ä¸åŒç”¨é€”ï¼ˆå¦‚ç›´æ¥åå¥½ä¼˜åŒ–å’Œç›‘ç£å¾®è°ƒï¼‰ï¼ŒåŒ…å«æ•°æ®åŠ è½½å’Œå¤„ç†çš„æ–¹æ³•ã€‚

4. **FeedForward** å’Œ **MOEFeedForward**:
   - å‰è€…å®ç°æ ‡å‡†çš„å‰é¦ˆç½‘ç»œï¼Œåè€…å¼•å…¥äº†ä¸“å®¶æ··åˆï¼ˆMoEï¼‰æœºåˆ¶ä»¥æé«˜æ•ˆç‡ã€‚

5. **LMConfig**:
   - é…ç½®è¯­è¨€æ¨¡å‹çš„å…³é”®å‚æ•°ï¼Œä¾‹å¦‚ç»´åº¦ã€å±‚æ•°ã€å¤´éƒ¨æ•°é‡ç­‰ã€‚

6. **MiniMindBlock**:
   - è¡¨ç¤ºæ¨¡å‹ä¸­çš„ä¸€ä¸ªå—ï¼Œæ•´åˆäº†æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆå±‚ã€‚

7. **MiniMindLM**:
   - æ ¸å¿ƒçš„è¯­è¨€æ¨¡å‹ç±»ï¼Œè´Ÿè´£æ•´ä½“çš„å‰å‘ä¼ æ’­å’Œç”Ÿæˆè¿‡ç¨‹ã€‚

8. **RMSNorm**:
   - å®ç°äº†å½’ä¸€åŒ–æ“ä½œï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚

9. **LoRA**:
   - å®ç°ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æŠ€æœ¯ï¼Œç”¨äºé«˜æ•ˆå¾®è°ƒå¤§å‹æ¨¡å‹ã€‚

### UML ç±»å›¾ï¼š
![](D:\deep_learning\codes\workspace\minimind\minimind_uml.png)

å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„åˆ†ææˆ–æœ‰å…³æ­¤é¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
2025-05-15 15:54:17.445 | INFO     | agents.umlagent:update_plan_status:159 - Marked step 3 as completed in plan plan_1747295459
2025-05-15 15:54:17.445 | INFO     | agents.base:run:129 - Executing step 12/20
2025-05-15 15:54:21.995 | INFO     | agents.tool_call:think:56 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: æ‰€æœ‰æ­¥éª¤éƒ½å·²å®Œæˆï¼Œç°åœ¨å¯ä»¥ç»ˆæ­¢ä»»åŠ¡äº†ã€‚
2025-05-15 15:54:21.995 | INFO     | agents.tool_call:think:58 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-05-15 15:54:21.995 | INFO     | agents.tool_call:think:63 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['terminate']
2025-05-15 15:54:21.995 | INFO     | agents.tool_call:think:78 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"status": "success"}']
2025-05-15 15:54:21.995 | INFO     | agents.tool_call:_handle_special_tool:183 - ğŸ Special tool 'terminate' has completed the task!
2025-05-15 15:54:21.996 | INFO     | agents.tool_call:act:131 - ğŸ¯ å·¥å…· 'terminate' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:terminate`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
The interaction has been completed with status: success
2025-05-15 15:55:25.226 | INFO     | main:websocket_endpoint:60 - WebSocket connection disconnected from 127.0.0.1:54336
2025-05-15 15:55:25.228 | INFO     | main:websocket_endpoint:75 - Cleaned up resources for 127.0.0.1:54336
