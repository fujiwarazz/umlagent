2025-06-08 17:21:39.541 | INFO     | main:websocket_endpoint:30 - WebSocket connection accepted from 127.0.0.1:54437
2025-06-08 17:21:39.543 | INFO     | tools.swe_tools.file_operator:__init__:80 - FileOperatorTool initialized with workspace_root: D:\deep_learning\codes\umlagent\app\workspace\tmp_codes
2025-06-08 17:21:49.510 | INFO     | main:websocket_endpoint:61 - Received message from 127.0.0.1:54437: æˆ‘æƒ³å­¦ä¹ llavaï¼Œå¸®æˆ‘æ‰¾ä¸ªé¡¹ç›®ï¼Œå¹¶ä¸”åˆ†æUML
2025-06-08 17:21:49.510 | INFO     | agents.umlagent:create_initial_plan:208 - Creating initial plan with ID: plan_1749374509
2025-06-08 17:21:55.657 | INFO     | agents.umlagent:create_initial_plan:237 -  ç»“æœä¸º:  `å·¥å…·:planning`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
Plan created successfully with ID: plan_1749374509

Plan: å­¦ä¹ llavaå¹¶åˆ†æç›¸å…³é¡¹ç›®UML (ID: plan_1749374509)
==============================================

Progress: 0/3 steps completed (0.0%)
Status: 0 completed, 0 in progress, 0 blocked, 3 not started

Steps:
0. [ ] æœç´¢ä¸llavaç›¸å…³çš„å¼€æºé¡¹ç›®
1. [ ] é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„é¡¹ç›®è¿›è¡Œå…‹éš†
2. [ ] ç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLç±»å›¾

2025-06-08 17:21:55.658 | INFO     | agents.base:run:123 - websocket initialized finish, state:<starlette.datastructures.State object at 0x0000027D0D29FBF0>
2025-06-08 17:21:55.658 | INFO     | agents.base:run:133 - Executing step 1/20
2025-06-08 17:21:58.593 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: è®¡åˆ’å·²åˆ›å»ºï¼Œç°åœ¨éœ€è¦æ‰§è¡Œç¬¬ä¸€æ­¥ï¼šæœç´¢ä¸llavaç›¸å…³çš„å¼€æºé¡¹ç›®ã€‚æ¥ä¸‹æ¥å°†ä½¿ç”¨ç™¾åº¦æœç´¢å·¥å…·æ¥æŸ¥æ‰¾ç›¸å…³é¡¹ç›®ã€‚
2025-06-08 17:21:58.593 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:21:58.594 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['baidu_search']
2025-06-08 17:21:58.594 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"query": "llava å¼€æºé¡¹ç›®"}']
2025-06-08 17:21:59.609 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'baidu_search' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:baidu_search`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
[{'title': 'ViP-LLaVA å¼€æºé¡¹ç›®ä½¿ç”¨æ•™ç¨‹-CSDNåšå®¢', 'abstract': 'ViP-LLaVA å¼€æºé¡¹ç›®ä½¿ç”¨æ•™ç¨‹-CSDNåšå®¢\n\n2024å¹´9æœˆ14æ—¥é¦–å…ˆ,å…‹éš†é¡¹ç›®ä»“åº“å¹¶è¿›å…¥é¡¹ç›®ç›®å½•: gitclonehttps://github.com/WisconsinAIVision/ViP-LLaVA.git cdViP-LLaVA AIå†™ä»£ç bash åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ: conda create -n vip-llava python=3.10 -y conda activate vip-llava AIå†™ä»£ç bash å®‰è£…å¿…è¦çš„åŒ…: pi\n\n\nCSDNåšå®¢\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=WT9ji_OoLxfs6qU1ZKCtKg6cUPUGmqHT1ZIRuQT7Yfcr7Z3QokSz2jFGF2tcZiXi2-kzpWCOQYGGRo6isDYrBW3rfApJ1vblijfhMrqAP7K', 'rank': 1}, {'title': 'æ¢ç´¢æœªæ¥æ™ºèƒ½åŠ©æ‰‹:LLaVA-NeXT å¼€æºé¡¹ç›®æ­ç§˜-CSDNåšå®¢', 'abstract': 'æ¢ç´¢æœªæ¥æ™ºèƒ½åŠ©æ‰‹:LLaVA-NeXT å¼€æºé¡¹ç›®æ­ç§˜-CSDNåšå®¢\n\n2024å¹´6æœˆ21æ—¥åœ¨äººå·¥æ™ºèƒ½çš„å‰æ²¿,æˆ‘ä»¬è¿æ¥äº†LLaVA-NeXTâ€”â€”ä¸€ä¸ªå¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹æ¡†æ¶,å®ƒå°†è§†è§‰ç†è§£ä¸è¯­è¨€å¤„ç†èä¸ºä¸€ä½“,ä¸ºAIåŠ©æ‰‹è®¾å®šäº†æ–°çš„æ ‡å‡†ã€‚è¿™ä¸ªé¡¹ç›®ä¸ä»…æä¾›äº†åˆ›æ–°çš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆ,è€Œä¸”é€šè¿‡å¼€æºçš„å½¢å¼,æ¨åŠ¨äº†æ•´ä¸ªç¤¾åŒºçš„è¿›æ­¥ã€‚ é¡¹ç›®ä»‹ç» LLaVA-NeXTæ˜¯åŸºäºå¤§è§„æ¨¡æ•°æ®è®­ç»ƒçš„å¤šæ¨¡æ€æ¨¡å‹,èƒ½å¤Ÿæ‰§è¡Œå›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€ç†è§£å’Œå¤æ‚çš„äº¤äº’ä»»...\n\n\nCSDNåšå®¢\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=WT9ji_OoLxfs6qU1ZKCtKg6cUPUGmqHT1ZIRuQT7Yfcr7Z3QokSz2jFGF2tcZiXi8PH1-jAwoxCSTLlI7BipkgRo-tzLITkRzEt9v2D_zqu', 'rank': 2}, {'title': 'LLaVAå¤šæ¨¡æ€å¼€æºå¤§æ¨¡å‹æºç åˆ†æ - çŸ¥ä¹', 'abstract': 'LLaVAå¤šæ¨¡æ€å¼€æºå¤§æ¨¡å‹æºç åˆ†æ - çŸ¥ä¹\n\n\n\n\n\n\n\n\n\n2024å¹´7æœˆ13æ—¥åœ¨transformersä»“åº“ä¸­å¯ä»¥çœ‹åˆ°llavaçš„æºç ,é¦–å…ˆæ˜¯LlavaForConditionalGenerationç±»,ç»§æ‰¿è‡ªPreTrainedModel,è¿™ä¸ªç±»æ˜¯æ‰€æœ‰æ¨¡å‹çš„åŸºç±»,åŒ…å«äº†ä¸€äº›é€šç”¨çš„æ–¹æ³•,æ¯”å¦‚ä¿å­˜æ¨¡å‹ã€åŠ è½½æ¨¡å‹ã€åˆå§‹åŒ–æƒé‡ç­‰ã€‚ ç»§æ‰¿å…³ç³»ä¸º:LlavaForConditionalGeneration-> LlavaPreTrainedModel-> PreTrainedModel LlavaConfig LlavaConfig ä¸­ä¸»è¦æ˜¯å®šä¹‰ä¸€äº›å‚...\n\n\nçŸ¥ä¹\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n', 'url': 'http://www.baidu.com/link?url=OCPITaeyxaUZx3wBEt0kC1OkUdQ10gqJA763Wei7QyUTmZCXec1aJ5LkUnSarNVU', 'rank': 3}, {'title': 'å¤§å®¶è¿˜åœ¨æœarduinoå¼€æºé¡¹ç›®é¡¹ç›®å¼€æºjavaä¼˜ç§€å¼€æºé¡¹ç›®androidå¼€æºé¡¹ç›®phpå¼€æºé¡¹ç›®ç›®å‰ç«çˆ†çš„Layer3é¡¹ç›®ipaç¬¬ä¸‰æ–¹è½¯ä»¶æºflizaè½¯ä»¶æºllvm javaopenlavallvmæºç åˆ†æluaå¼€æºé¡¹ç›®', 'abstract': 'å¤§å®¶è¿˜åœ¨æœarduinoå¼€æºé¡¹ç›®é¡¹ç›®å¼€æºjavaä¼˜ç§€å¼€æºé¡¹ç›®androidå¼€æºé¡¹ç›®phpå¼€æºé¡¹ç›®ç›®å‰ç«çˆ†çš„Layer3é¡¹ç›®ipaç¬¬ä¸‰æ–¹è½¯ä»¶æºflizaè½¯ä»¶æºllvm javaopenlavallvmæºç åˆ†æluaå¼€æºé¡¹ç›®', 'url': '/s?wd=arduino%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE&usm=1&ie=utf-8&rsv_pq=8ec2ab1200022f08&oq=llava%20%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE&rsv_t=fe7d5vkGgN0P%2F0goyt4AcGBdDmn0HYZUd%2BDuqe2uLDF12Zz23kSwAiLW%2Bdo&rsf=101633403&rsv_dl=0_prs_28608_1', 'rank': 4}, {'title': 'ã€ä»£ç ã€‘LLaVA ä»£ç å­¦ä¹ ä¸è°ƒè¯• - KeanShi - åšå®¢å›­', 'abstract': 'ã€ä»£ç ã€‘LLaVA ä»£ç å­¦ä¹ ä¸è°ƒè¯• - KeanShi - åšå®¢å›­\n\n\n\n\n\n\n\n\n\n2024å¹´12æœˆ20æ—¥ä»£ç åœ°å€:https://github.com/haotian-liu/LLaVA æ„Ÿè°¢ b ç«™ @è‰¯ç¦è·¯ç¨‹åºå‘˜ çš„æ•™ç¨‹ LLaVA æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹,æ—¨åœ¨æ ¹æ®è§†è§‰è¾“å…¥(å›¾åƒ)å’Œæ–‡æœ¬æŒ‡ä»¤ç†è§£å’Œç”Ÿæˆå†…å®¹ã€‚å·²ç»æˆä¸ºç›®å‰æœ€åŸºæœ¬ã€å½±å“åŠ›æœ€å¹¿çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¹‹ä¸€;æ°å¥½æœ€è¿‘æ­£åœ¨å­¦ä¹  LLaVA\n\n\nåšå®¢å›­', 'url': 'http://www.baidu.com/link?url=iTcGkIm828WoHKhdzmHHzyDckrh4HPlCHDyO-wIsVorb1OPg1p5TshBLR1DjNIL19XhXvRqBKVq593YVduo00K', 'rank': 5}, {'title': 'LLaVA-NeXT: å¼€æºçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹é¡¹ç›®,... æ¥è‡ªçˆ±å¯å¯-çˆ±ç”Ÿæ´»...', 'abstract': "LLaVA-NeXT: å¼€æºçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹é¡¹ç›®,... æ¥è‡ªçˆ±å¯å¯-çˆ±ç”Ÿæ´»...\n\n\n\n\n\n\n\n\n\n2024å¹´5æœˆ10æ—¥ã€LLaVA-NeXT: å¼€æºçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹é¡¹ç›®,ä¸“æ³¨äºæå‡è¯­è¨€å’Œè§†è§‰ä»»åŠ¡çš„å¤„ç†èƒ½åŠ›ã€‘'LLaVA-NeXT: Open Large Multimodal Models' GitHub: github.com/LLaVA-VL/LLaVA-NeXT #å¼€æº# #æœºå™¨å­¦ä¹ # #äººå·¥æ™ºèƒ½# \u200b\u200b\u200b\u200b  Ã»æ”¶è—  10  è¯„è®º  Ã±10  è¯„è®º o p åŒæ—¶è½¬å‘åˆ°æˆ‘çš„å¾®åš  æŒ‰çƒ­åº¦ æŒ‰æ—¶é—´  æ­£åœ¨...\n\n\nå¾®åš", 'url': 'http://www.baidu.com/link?url=OCPITaeyxaUZx3wBEt0kCFnOpj06WQYQQY7Tg5S2xU78hIv454HnisUFnpW3nB29', 'rank': 6}, {'title': 'LLaVA:GPT-4V(ision) çš„å¼€æºæ›¿ä»£å“-51CTO.COM', 'abstract': 'LLaVA:GPT-4V(ision) çš„å¼€æºæ›¿ä»£å“-51CTO.COM\n\n\n\n\n\n\n\n\n\n2024å¹´2æœˆ6æ—¥æœ¬æ–‡å°†å‘æ‚¨å±•ç¤ºä¸€æ¬¾ä¼˜ç§€çš„GPT-4Vçš„å¼€æºæ›¿ä»£å“â€”â€”LLaVA,å¹¶åˆ†åˆ«å±•ç¤ºä»¥Webã€æœ¬åœ°å’ŒGoogle Colabä¸‰ç§æ–¹å¼è¿è¡ŒLLaVAã€‚ LLaVA(å¤§å‹è¯­è¨€å’Œè§†è§‰åŠ©ç†)(é“¾æ¥::https://llava-vl.github.io/)æ˜¯ä¸€ä¸ªå¾ˆæœ‰å‰é€”çš„å¼€æºç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹,å®ƒå¤åˆ¶äº†OpenAI GPT-4åœ¨å›¾åƒè½¬æ¢æ–¹é¢çš„ä¸€äº›åŠŸèƒ½ã€‚ç”¨æˆ·å¯ä»¥å°†å›¾åƒæ·»åŠ åˆ°LLaVAèŠå¤©å¯¹è¯ä¸­...\n\n\n51CTO\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=DI5IIdoKvX8wYANtg0AiLXh7XVhnJfdkfnC1s__-bhLsf3efwbQqav1-x-HnZLiILNqbRfkYNNvDZDrQ5VUwNK', 'rank': 7}, {'title': 'æ¯å‘¨GitHub æ¢ç´¢|å¼€æºå·¥å…·é›†åˆé€Ÿé€’:ä»å¤šæ¨¡æ€æ¨¡å‹åˆ° Web æ¸²æŸ“å¼•æ“', 'abstract': 'æ¯å‘¨GitHub æ¢ç´¢|å¼€æºå·¥å…·é›†åˆé€Ÿé€’:ä»å¤šæ¨¡æ€æ¨¡å‹åˆ° Web æ¸²æŸ“å¼•æ“\n\n\n\n\n\n\n\n\n\n2024å¹´8æœˆ17æ—¥1.LLaVA-NeXTï¼šå¼€æ”¾çš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ ï¸ä»“åº“åç§°ï¼šLLaVA-VL/LLaVA-NeXTæˆªæ­¢å‘ç¨¿æ˜Ÿæ•°: 1863 (è¿‘ä¸€å‘¨æ–°å¢:373)ä»“åº“è¯­è¨€: Pythonä»“åº“å¼€æºåè®®ï¼šApache License 2.0 å¼•è¨€ æœ¬æ–‡æ·±å…¥å‰–æ GitHub ä»“åº“ LLaVA-NeXTï¼Œé‡ç‚¹ä»‹ç»å…¶ä½œç”¨ã€æŠ€æœ¯è§£æä»¥åŠåœ¨å¤šæ¨¡å¼æœºå™¨å­¦ä¹ é¢†åŸŸçš„æœ€æ–°è¿›å±•ã€‚é¡¹ç›®ä½œç”¨ LLaVA-NeXT å»ºç«‹åœ¨ LLaVA ...\n\n\nè¯šå“¥çœ‹å¼€æº\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=OCPITaeyxaUZx3wBEt0kC4i9tO-7WiceZTkBMduSUba3DUs6ATXUgccLUdK7v3w7n2ar8Qjqwtvz32Y6AmJ5xgVDSp4IsG9LRm5ek3wQO07', 'rank': 8}, {'title': 'AIçƒ­é—¨å¼€æºé¡¹ç›®æ’è¡Œ - çŸ¥ä¹', 'abstract': 'AIçƒ­é—¨å¼€æºé¡¹ç›®æ’è¡Œ - çŸ¥ä¹\n\n2024å¹´1æœˆ8æ—¥ç®€ä»‹:é¡¹ç›®æä¾›äº†MiniGPT-4å’ŒMiniGPT-v2çš„å¼€æºä»£ç ,è¿™äº›æ˜¯ç¼©å°ç‰ˆçš„GPT-4æ¨¡å‹,æ—¨åœ¨æä¾›ç±»ä¼¼åŠŸèƒ½ä½†èµ„æºè¦æ±‚æ›´ä½çš„è§£å†³æ–¹æ¡ˆã€‚è¿™ä½¿å¾—åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ç ”ç©¶å’Œå¼€å‘å¤§å‹è¯­è¨€æ¨¡å‹å˜å¾—å¯èƒ½ã€‚ åœ°å€:http://github.com/Vision-CAIR/MiniGPT-4 6ã€LLaVA ç®€ä»‹:LLaVAé¡¹ç›®æ—¨åœ¨æ„å»ºå…·æœ‰GPT-4Vçº§åˆ«èƒ½åŠ›çš„å¤§å‹è¯­è¨€å’Œè§†è§‰åŠ©æ‰‹ã€‚è¯¥é¡¹...\n\n\nçŸ¥ä¹\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=OCPITaeyxaUZx3wBEt0kC1OkUdQ10gqJA763Wei7QyTHQq-7LoobbsITMaEcyE_s', 'rank': 9}, {'title': 'LLaVAé¡¹ç›®å®æˆ˜:å¦‚ä½•è¿è¡ŒDemo-ç™¾åº¦å¼€å‘è€…ä¸­å¿ƒ', 'abstract': 'LLaVAé¡¹ç›®å®æˆ˜:å¦‚ä½•è¿è¡ŒDemo-ç™¾åº¦å¼€å‘è€…ä¸­å¿ƒ\n\n2024å¹´3æœˆ28æ—¥åœ¨è¿è¡ŒLLaVAé¡¹ç›®çš„Demoä¹‹å‰,æˆ‘ä»¬éœ€è¦å…ˆæ­å»ºä¸€ä¸ªé€‚åˆé¡¹ç›®çš„è¿è¡Œç¯å¢ƒã€‚è¿™ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢: å®‰è£…Git:Gitæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ,ç”¨äºè¿½è¸ªä»£ç çš„æ”¹åŠ¨ã€‚åœ¨å®‰è£…Gitå,æˆ‘ä»¬å¯ä»¥é€šè¿‡å…‹éš†(clone)æ“ä½œè·å–LLaVAé¡¹ç›®çš„æºä»£ç ã€‚ å®‰è£…Python:LLaVAé¡¹ç›®ä½¿ç”¨Pythonä½œä¸ºå¼€å‘è¯­è¨€,å› æ­¤éœ€è¦å®‰è£…Pythonç¯å¢ƒã€‚å»ºè®®ä½¿ç”¨Python 3.x...\n\n\nç™¾åº¦å¼€å‘è€…ä¸­å¿ƒ\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=2NmXprlnmxRqisMZK76-vujh0C2zio0vLBRHS2LCFeoAmj1jvw7o8WN81gLcwPideXED_dOT8eWncU4brIwfoq', 'rank': 10}]
2025-06-08 17:21:59.611 | INFO     | agents.umlagent:update_plan_status:153 - Marked step 0 as completed in plan plan_1749374509
2025-06-08 17:21:59.612 | INFO     | agents.base:run:133 - Executing step 2/20
2025-06-08 17:22:05.739 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: é€šè¿‡æœç´¢ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†å¤šä¸ªä¸llavaç›¸å…³çš„å¼€æºé¡¹ç›®ã€‚æ¥ä¸‹æ¥å°†é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„é¡¹ç›®è¿›è¡Œå…‹éš†ã€‚æˆ‘å°†ä½¿ç”¨github_repo_cloner_sshå·¥å…·æ¥å…‹éš†ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„é¡¹ç›®ï¼šWisconsinAIVision/ViP-LLaVAã€‚
2025-06-08 17:22:05.740 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:22:05.741 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['github_repo_cloner_ssh']
2025-06-08 17:22:05.741 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_name": "WisconsinAIVision/ViP-LLaVA"}']
2025-06-08 17:22:34.155 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'github_repo_cloner_ssh' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:github_repo_cloner_ssh`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA
2025-06-08 17:22:34.156 | INFO     | agents.umlagent:update_plan_status:153 - Marked step 1 as completed in plan plan_1749374509
2025-06-08 17:22:34.156 | INFO     | agents.base:run:133 - Executing step 3/20
2025-06-08 17:22:41.009 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: é¡¹ç›®å·²ç»æˆåŠŸå…‹éš†ï¼Œç°åœ¨å°†æ‰§è¡Œæœ€åä¸€æ­¥ï¼šç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLç±»å›¾ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿æ‰€æœ‰PythonåŒ…ä¸­éƒ½åŒ…å«__init__.pyæ–‡ä»¶ã€‚æˆ‘å°†ä½¿ç”¨ensure_init_pyå·¥å…·æ¥å®Œæˆè¿™ä¸€æ­¥éª¤ã€‚
2025-06-08 17:22:41.010 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:22:41.010 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['ensure_init_py']
2025-06-08 17:22:41.010 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"root_dir_path": "D:\\\\deep_learning\\\\codes\\\\umlagent\\\\app\\\\workspace\\\\tmp_codes\\\\ViP-LLaVA"}']
2025-06-08 17:22:41.022 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'ensure_init_py' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:ensure_init_py`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
æˆåŠŸåœ¨ä»¥ä¸‹ 9 ä¸ªç›®å½•ä¸­åˆ›å»ºäº† __init__.py æ–‡ä»¶:
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\llava\eval\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\llava\model\language_model\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\llava\model\multimodal_encoder\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\llava\model\multimodal_projector\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\llava\train\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\scripts\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\scripts\eval\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\scripts\v1_5\eval\__init__.py
2025-06-08 17:22:41.023 | INFO     | agents.umlagent:update_plan_status:153 - Marked step 2 as completed in plan plan_1749374509
2025-06-08 17:22:41.023 | INFO     | agents.base:run:133 - Executing step 4/20
2025-06-08 17:22:50.468 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: å·²ç»æˆåŠŸåˆ›å»ºäº†æ‰€æœ‰å¿…è¦çš„__init__.pyæ–‡ä»¶ï¼Œç°åœ¨å¯ä»¥ç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLç±»å›¾ã€‚æˆ‘å°†ä½¿ç”¨code_to_uml_generator_multilangå·¥å…·æ¥å®Œæˆè¿™ä¸€æ­¥éª¤ã€‚
2025-06-08 17:22:50.469 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:22:50.469 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['code_to_uml_generator_multilang']
2025-06-08 17:22:50.469 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_path": "D:\\\\deep_learning\\\\codes\\\\umlagent\\\\app\\\\workspace\\\\tmp_codes\\\\ViP-LLaVA", "output_png_path": "D:\\\\deep_learning\\\\codes\\\\umlagent\\\\app\\\\workspace\\\\tmp_codes\\\\ViP-LLaVA\\\\uml_diagram.png"}']
2025-06-08 17:22:52.098 | INFO     | tools.uml:execute:696 - å‡†å¤‡é€šè¿‡ WebSocket å‘é€ UML å›¾ç‰‡ 'uml_diagram.png'ã€‚
2025-06-08 17:22:52.108 | INFO     | tools.uml:execute:711 - UML å›¾ç‰‡ 'uml_diagram.png' å·²é€šè¿‡ WebSocket å‘é€ (392039 å­—èŠ‚)ã€‚
2025-06-08 17:22:52.108 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'code_to_uml_generator_multilang' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:code_to_uml_generator_multilang`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
UML å›¾è¡¨å’Œæ–‡æœ¬æè¿°å·²æˆåŠŸç”Ÿæˆã€‚
PNG å›¾åƒä¿å­˜è·¯å¾„: 'D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\uml_diagram.png'

---
UML å›¾è¡¨æ–‡æœ¬æè¿°å†…å®¹:
---
# UML å›¾è¡¨æ–‡æœ¬æè¿°

## Class: `CLIPVisionTower`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `clip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `is_loaded`
- `select_feature`
- `select_layer`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `config(self)`
- `device(self)`
- `dtype(self)`
- `dummy_feature(self)`
- `feature_select(self, image_forward_outs)`
- `forward(self, images)`
- `hidden_size(self)`
- `load_model(self)`
- `num_patches(self)`

---

## Class: `CLIPVisionTowerMultilayer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `clip_4layer_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `is_loaded`
- `select_feature`
- `select_layer`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `config(self)`
- `device(self)`
- `dtype(self)`
- `dummy_feature(self)`
- `feature_select(self, image_forward_outs)`
- `forward(self, images)`
- `hidden_size(self)`
- `load_model(self)`
- `num_patches(self)`

---

## Class: `Controller`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `controller`

### å±æ€§ (Attributes)
- `dispatch_method`
- `heart_beat_thread`
- `worker_info`

### æ–¹æ³• (Methods)
- `__init__(self, dispatch_method: str)`
- `get_worker_address(self, model_name: str)`
- `get_worker_status(self, worker_name: str)`
- `list_models(self)`
- `receive_heart_beat(self, worker_name: str, queue_length: int)`
- `refresh_all_workers(self)`
- `register_worker(self, worker_name: str, check_heart_beat: bool, worker_status: dict)`
- `remove_stable_workers_by_expiration(self)`
- `remove_worker(self, worker_name: str)`
- `worker_api_generate_stream(self, params)`
- `worker_api_get_status(self)`

---

## Class: `Conversation`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `conversation`

### å±æ€§ (Attributes)
- `messages: List[List[str]]`
- `offset: int`
- `roles: List[str]`
- `sep2: str`
- `sep: str`
- `sep_style: SeparatorStyle`
- `skip_next: bool`
- `system: str`
- `version: str`

### æ–¹æ³• (Methods)
- `append_message(self, role, message)`
- `copy(self)`
- `dict(self)`
- `get_images(self, return_pil)`
- `get_prompt(self)`
- `process_image(self, image, image_process_mode, return_pil, image_format, max_len, min_len)`
- `to_gradio_chatbot(self)`

---

## Class: `CustomDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_vqa_loader`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Dataset`, `Dataset`

### å±æ€§ (Attributes)
- `data_args`
- `image_aspect_ratio`
- `image_folder`
- `image_processor`
- `model_config`
- `questions`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__getitem__(self, index)`
- `__init__(self, questions, image_folder, tokenizer, image_processor, model_config)`
- `__init__(self, questions, image_folder, tokenizer, image_processor, model_config, args, image_aspect_ratio)`
- `__len__(self)`

---

## Class: `DataArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### å±æ€§ (Attributes)
- `data_path: str`
- `image_aspect_ratio: str`
- `image_folder: Optional[str]`
- `is_multimodal: bool`
- `lazy_preprocess: bool`
- `train_vip_prmpt_style: str`

---

## Class: `DataCollatorForSupervisedDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `tokenizer: transformers.PreTrainedTokenizer`

### æ–¹æ³• (Methods)
- `__call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]`

---

## Class: `DispatchMethod`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `controller`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Enum`

### å±æ€§ (Attributes)
- `LOTTERY`
- `SHORTEST_QUEUE`

### æ–¹æ³• (Methods)
- `from_str(cls, name)`

---

## Class: `EvalAIAnswerProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `m4c_evaluator`

### å±æ€§ (Attributes)
- `ARTICLES`
- `COMMA_STRIP`
- `CONTRACTIONS`
- `NUMBER_MAP`
- `PERIOD_STRIP`
- `PUNCTUATIONS`

### æ–¹æ³• (Methods)
- `__call__(self, item)`
- `__init__(self, *args, **kwargs)`
- `process_digit_article(self, in_text)`
- `process_punctuation(self, in_text)`
- `word_tokenize(self, word)`

---

## Class: `IdentityMap`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `builder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `config(self)`
- `forward(self, x, *args, **kwargs)`

---

## Class: `KeywordsStoppingCriteria`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `StoppingCriteria`, `StoppingCriteria`

### å±æ€§ (Attributes)
- `input_ids`
- `keyword_ids`
- `keywords`
- `max_keyword_len`
- `start_len`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__call__(self, output_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool`
- `__init__(self, keywords, tokenizer, input_ids)`
- `call_for_batch(self, output_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool`

---

## Class: `LLaVATrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### æ–¹æ³• (Methods)
- `_get_train_sampler(self) -> Optional[torch.utils.data.Sampler]`
- `_save(self, output_dir: Optional[str], state_dict)`
- `_save_checkpoint(self, model, trial, metrics)`
- `create_optimizer(self)`

---

## Class: `LazySupervisedDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Dataset`

### å±æ€§ (Attributes)
- `data_args`
- `list_data_dict`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__getitem__(self, i) -> Dict[str, torch.Tensor]`
- `__init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer, data_args: DataArguments)`
- `__len__(self)`
- `lengths(self)`
- `modality_lengths(self)`

---

## Class: `LengthGroupedSampler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Sampler`

### å±æ€§ (Attributes)
- `batch_size`
- `generator`
- `group_by_modality`
- `lengths`
- `world_size`

### æ–¹æ³• (Methods)
- `__init__(self, batch_size: int, world_size: int, lengths: Optional[List[int]], generator, group_by_modality: bool)`
- `__iter__(self)`
- `__len__(self)`

---

## Class: `LlavaConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaConfig`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaLlamaForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`
- `pretraining_tp`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool]) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaLlamaModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `LlamaModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: LlamaConfig)`

---

## Class: `LlavaMetaForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_arch`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ABC`

### æ–¹æ³• (Methods)
- `encode_images(self, images)`
- `get_model(self)`
- `get_vision_tower(self)`
- `initialize_vision_tokenizer(self, model_args, tokenizer)`
- `prepare_inputs_labels_for_multimodal(self, input_ids, position_ids, attention_mask, past_key_values, labels, images, image_sizes)`

---

## Class: `LlavaMetaModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_arch`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `get_vision_tower(self)`
- `initialize_vision_modules(self, model_args, fsdp)`

---

## Class: `LlavaMptConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mpt`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MptConfig`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaMptForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mpt`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MptForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `supports_gradient_checkpointing`
- `transformer`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `_set_gradient_checkpointing(self, module, value)`
- `forward(self, input_ids: Optional[torch.LongTensor], past_key_values: Optional[Tuple[Tuple[torch.Tensor, torch.Tensor], ...]], attention_mask: Optional[torch.Tensor], inputs_embeds: Optional[torch.Tensor], labels: Optional[torch.Tensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool], images)`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaMptModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mpt`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `MptModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: MptConfig)`
- `embed_tokens(self, x)`

---

## Class: `LlavaPhi3Config`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3Config`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaPhi3ForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3ForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool]) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaPhi3Model`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `Phi3Model`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: Phi3Config)`

---

## Class: `ModelArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### å±æ€§ (Attributes)
- `freeze_backbone: bool`
- `mm_patch_merge_type: Optional[str]`
- `mm_projector_type: Optional[str]`
- `mm_use_im_patch_token: bool`
- `mm_use_im_start_end: bool`
- `mm_vision_select_feature: Optional[str]`
- `mm_vision_select_layer: Optional[int]`
- `model_name_or_path: Optional[str]`
- `pretrain_mm_mlp_adapter: Optional[str]`
- `tune_mm_mlp_adapter: bool`
- `version: Optional[str]`
- `vision_tower: Optional[str]`

---

## Class: `ModelWorker`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_worker`

### å±æ€§ (Attributes)
- `controller_addr`
- `device`
- `is_multimodal`
- `worker_addr`
- `worker_id`

### æ–¹æ³• (Methods)
- `__init__(self, controller_addr, worker_addr, worker_id, no_register, model_path, model_base, model_name, load_8bit, load_4bit, device)`
- `generate_stream(self, params)`
- `generate_stream_gate(self, params)`
- `get_queue_length(self)`
- `get_status(self)`
- `register_to_controller(self)`
- `send_heart_beat(self)`

---

## Class: `Phi3Attention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attention_dropout`
- `config`
- `head_dim`
- `hidden_size`
- `is_causal`
- `layer_idx`
- `max_position_embeddings`
- `num_heads`
- `num_key_value_groups`
- `num_key_value_heads`
- `o_proj`
- `original_max_position_embeddings`
- `qkv_proj`
- `rope_scaling`
- `rope_theta`

### æ–¹æ³• (Methods)
- `__init__(self, config: Phi3Config, layer_idx: Optional[int])`
- `_init_rope(self)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Cache], output_attentions: bool, use_cache: bool) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `Phi3Config`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `configuration_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PretrainedConfig`

### å±æ€§ (Attributes)
- `attention_dropout`
- `embd_pdrop`
- `hidden_act`
- `hidden_size`
- `initializer_range`
- `intermediate_size`
- `keys_to_ignore_at_inference`
- `max_position_embeddings`
- `model_type`
- `num_attention_heads`
- `num_hidden_layers`
- `num_key_value_heads`
- `original_max_position_embeddings`
- `resid_pdrop`
- `rms_norm_eps`
- `rope_scaling`
- `rope_theta`
- `sliding_window`
- `use_cache`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, vocab_size, hidden_size, intermediate_size, num_hidden_layers, num_attention_heads, num_key_value_heads, resid_pdrop, embd_pdrop, attention_dropout, hidden_act, max_position_embeddings, original_max_position_embeddings, initializer_range, rms_norm_eps, use_cache, tie_word_embeddings, rope_theta, rope_scaling, bos_token_id, eos_token_id, pad_token_id, sliding_window, **kwargs)`
- `_rope_scaling_validation(self)`

---

## Class: `Phi3DecoderLayer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `input_layernorm`
- `mlp`
- `post_attention_layernorm`
- `resid_attn_dropout`
- `resid_mlp_dropout`
- `self_attn`

### æ–¹æ³• (Methods)
- `__init__(self, config: Phi3Config, layer_idx: int)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Tuple[torch.Tensor]], output_attentions: Optional[bool], use_cache: Optional[bool], **kwargs) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]`

---

## Class: `Phi3FlashAttention2`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3Attention`

### å±æ€§ (Attributes)
- `_flash_attn_uses_top_left_mask`

### æ–¹æ³• (Methods)
- `__init__(self, *args, **kwargs)`
- `_flash_attention_forward(self, query_states, key_states, value_states, attention_mask, query_length, dropout, softmax_scale, use_sliding_windows)`
- `_upad_input(self, query_layer, key_layer, value_layer, attention_mask, query_length)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.LongTensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Cache], output_attentions: bool, use_cache: bool, **kwargs) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `Phi3ForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3PreTrainedModel`

### å±æ€§ (Attributes)
- `_tied_weights_keys`
- `lm_head`
- `model`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `_reorder_cache(past_key_values, beam_idx)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, CausalLMOutputWithPast]`
- `get_decoder(self)`
- `get_input_embeddings(self)`
- `get_output_embeddings(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, attention_mask, inputs_embeds, **kwargs)`
- `set_decoder(self, decoder)`
- `set_input_embeddings(self, value)`
- `set_output_embeddings(self, new_embeddings)`

---

## Class: `Phi3ForSequenceClassification`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3PreTrainedModel`

### å±æ€§ (Attributes)
- `model`
- `num_labels`
- `score`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, SequenceClassifierOutputWithPast]`
- `get_input_embeddings(self)`
- `set_input_embeddings(self, value)`

---

## Class: `Phi3ForTokenClassification`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3PreTrainedModel`

### å±æ€§ (Attributes)
- `classifier`
- `dropout`
- `model`
- `num_labels`

### æ–¹æ³• (Methods)
- `__init__(self, config: Phi3Config)`
- `forward(self, input_ids: Optional[torch.LongTensor], past_key_values: Optional[Tuple[Tuple[torch.Tensor, torch.Tensor], ...]], attention_mask: Optional[torch.Tensor], inputs_embeds: Optional[torch.Tensor], labels: Optional[torch.Tensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool], **deprecated_arguments) -> Union[Tuple[torch.Tensor], TokenClassifierOutput]`

---

## Class: `Phi3MLP`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `activation_fn`
- `config`
- `down_proj`
- `gate_up_proj`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states: torch.FloatTensor) -> torch.FloatTensor`

---

## Class: `Phi3Model`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3PreTrainedModel`

### å±æ€§ (Attributes)
- `_attn_implementation`
- `embed_dropout`
- `embed_tokens`
- `gradient_checkpointing`
- `layers`
- `norm`
- `padding_idx`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, config: Phi3Config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, BaseModelOutputWithPast]`
- `get_input_embeddings(self)`
- `set_input_embeddings(self, value)`

---

## Class: `Phi3PreTrainedModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModel`

### å±æ€§ (Attributes)
- `_no_split_modules`
- `_skip_keys_device_placement`
- `_supports_cache_class`
- `_supports_flash_attn_2`
- `_supports_sdpa`
- `_version`
- `base_model_prefix`
- `config_class`
- `supports_gradient_checkpointing`

### æ–¹æ³• (Methods)
- `_init_weights(self, module)`

---

## Class: `Phi3RMSNorm`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `variance_epsilon`
- `weight`

### æ–¹æ³• (Methods)
- `__init__(self, hidden_size, eps)`
- `forward(self, hidden_states)`

---

## Class: `Phi3RotaryEmbedding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `base`
- `dim`
- `max_position_embeddings`

### æ–¹æ³• (Methods)
- `__init__(self, dim, max_position_embeddings, base, device)`
- `forward(self, x, position_ids, seq_len)`

---

## Class: `Phi3SdpaAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3Attention`

### æ–¹æ³• (Methods)
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Cache], output_attentions: bool, use_cache: bool) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `Phi3SuScaledRotaryEmbedding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3RotaryEmbedding`

### å±æ€§ (Attributes)
- `long_factor`
- `original_max_position_embeddings`
- `short_factor`

### æ–¹æ³• (Methods)
- `__init__(self, dim, short_factor, long_factor, original_max_position_embeddings, max_position_embeddings, base, device)`
- `_calc_scaling_factor(self, scale)`
- `forward(self, x, position_ids, seq_len)`

---

## Class: `Phi3YarnScaledRotaryEmbedding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_phi3`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Phi3RotaryEmbedding`

### å±æ€§ (Attributes)
- `long_factor`
- `original_max_position_embeddings`
- `short_factor`

### æ–¹æ³• (Methods)
- `__init__(self, dim, short_factor, long_factor, original_max_position_embeddings, max_position_embeddings, base, device)`
- `_calc_scaling_factor(self, scale)`
- `forward(self, x, position_ids, seq_len)`

---

## Class: `Predictor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `predict`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePredictor`

### æ–¹æ³• (Methods)
- `predict(self, image: Path, prompt: str, top_p: float, temperature: float, max_tokens: int) -> ConcatenateIterator[str]`
- `setup(self) -> None`

---

## Class: `STVQAANLSEvaluator`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `m4c_evaluator`

### å±æ€§ (Attributes)
- `get_edit_distance`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `eval_pred_list(self, pred_list)`
- `get_anls(self, s1, s2)`

---

## Class: `STVQAAccuracyEvaluator`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `m4c_evaluator`

### å±æ€§ (Attributes)
- `answer_processor`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `eval_pred_list(self, pred_list)`

---

## Class: `SeparatorStyle`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `conversation`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Enum`

### å±æ€§ (Attributes)
- `LLAMA_2`
- `LLAMA_3`
- `MPT`
- `PLAIN`
- `Phi_3`
- `SINGLE`
- `TWO`

---

## Class: `SimpleFeatureSingleModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `builder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `clip_layernorm`
- `final_linear`

### æ–¹æ³• (Methods)
- `__init__(self, num_clip_layers_by_feature_dim, final_linear)`
- `forward(self, clip_features)`

---

## Class: `SimpleResBlock`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `builder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `pre_norm`
- `proj`

### æ–¹æ³• (Methods)
- `__init__(self, channels)`
- `forward(self, x)`

---

## Class: `StreamToLogger`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `linebuf`
- `log_level`
- `logger`
- `terminal`

### æ–¹æ³• (Methods)
- `__getattr__(self, attr)`
- `__init__(self, logger, log_level)`
- `flush(self)`
- `write(self, buf)`

---

## Class: `TextCapsBleu4Evaluator`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `m4c_evaluator`

### å±æ€§ (Attributes)
- `scorer`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `eval_pred_list(self, pred_list)`

---

## Class: `TextVQAAccuracyEvaluator`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `m4c_evaluator`

### å±æ€§ (Attributes)
- `answer_processor`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `_compute_answer_scores(self, raw_answers)`
- `eval_pred_list(self, pred_list)`

---

## Class: `TrainingArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `transformers.TrainingArguments`

### å±æ€§ (Attributes)
- `bits: int`
- `cache_dir: Optional[str]`
- `double_quant: bool`
- `freeze_mm_mlp_adapter: bool`
- `group_by_modality_length: bool`
- `lora_alpha: int`
- `lora_bias: str`
- `lora_dropout: float`
- `lora_enable: bool`
- `lora_r: int`
- `lora_weight_path: str`
- `mm_projector_lr: Optional[float]`
- `model_max_length: int`
- `mpt_attn_impl: Optional[str]`
- `optim: str`
- `quant_type: str`
- `remove_unused_columns: bool`

---

## Class: `WorkerInfo`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `controller`

### å±æ€§ (Attributes)
- `check_heart_beat: bool`
- `last_heart_beat: str`
- `model_names: List[str]`
- `queue_length: int`
- `speed: int`

---


[ä¿¡æ¯] UML å›¾è¡¨ 'uml_diagram.png' ä¹Ÿå·²é€šè¿‡ WebSocket ç›´æ¥å‘é€ã€‚
2025-06-08 17:22:52.123 | INFO     | agents.base:run:133 - Executing step 5/20
2025-06-08 17:23:00.478 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: å·²æˆåŠŸç”ŸæˆViP-LLaVAé¡¹ç›®çš„UMLç±»å›¾ã€‚ç°åœ¨å¯ä»¥ç»“æŸä»»åŠ¡äº†ã€‚

![](D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\ViP-LLaVA\uml_diagram.png)
2025-06-08 17:23:00.479 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:23:00.479 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['terminate']
2025-06-08 17:23:00.479 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"status": "success"}']
2025-06-08 17:23:00.480 | INFO     | agents.tool_call:_handle_special_tool:210 - ğŸ Special tool 'terminate' has completed the task!
2025-06-08 17:23:00.480 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'terminate' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:terminate`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
The interaction has been completed with status: success
2025-06-08 17:23:39.956 | INFO     | main:websocket_endpoint:61 - Received message from 127.0.0.1:54437: æˆ‘æƒ³å­¦ä¹ llavaï¼Œå¸®æˆ‘æ‰¾ä¸ªé¡¹ç›®ï¼Œå¹¶ä¸”åˆ†æUMLï¼ŒåŒæ—¶æ€»ç»“ä¸€ä¸‹
2025-06-08 17:23:39.956 | INFO     | agents.umlagent:create_initial_plan:208 - Creating initial plan with ID: plan_1749374619
2025-06-08 17:24:01.964 | INFO     | agents.umlagent:create_initial_plan:237 -  ç»“æœä¸º:  `å·¥å…·:planning`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
Plan created successfully with ID: plan_1749374619

Plan: å­¦ä¹ llavaç›¸å…³é¡¹ç›®å¹¶åˆ†æå…¶UML (ID: plan_1749374619)
===============================================

Progress: 0/4 steps completed (0.0%)
Status: 0 completed, 0 in progress, 0 blocked, 4 not started

Steps:
0. [ ] æœç´¢ä¸llavaç›¸å…³çš„é¡¹ç›®
1. [ ] é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„é¡¹ç›®è¿›è¡Œå…‹éš†
2. [ ] ç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLå›¾
3. [ ] æ€»ç»“é¡¹ç›®å¹¶æä¾›åˆ†æ

2025-06-08 17:24:01.965 | INFO     | agents.base:run:123 - websocket initialized finish, state:<starlette.datastructures.State object at 0x0000027D0D29FBF0>
2025-06-08 17:24:01.965 | INFO     | agents.base:run:133 - Executing step 6/20
2025-06-08 17:24:09.007 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: è®¡åˆ’å·²åˆ›å»ºï¼Œç°åœ¨éœ€è¦æ‰§è¡Œç¬¬ä¸€æ­¥ï¼šæœç´¢ä¸llavaç›¸å…³çš„é¡¹ç›®ã€‚æ¥ä¸‹æ¥å°†ä½¿ç”¨ç™¾åº¦æœç´¢å·¥å…·æ¥æŸ¥æ‰¾ç›¸å…³é¡¹ç›®ã€‚
2025-06-08 17:24:09.008 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:24:09.008 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['baidu_search']
2025-06-08 17:24:09.008 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"query": "llava å¼€æºé¡¹ç›®"}']
2025-06-08 17:24:10.430 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'baidu_search' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:baidu_search`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
[{'title': 'LLaVA:å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ·±åº¦è§£æ_llavaè¯¦è§£-CSDNåšå®¢', 'abstract': 'LLaVA:å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ·±åº¦è§£æ_llavaè¯¦è§£-CSDNåšå®¢\n\n2025å¹´5æœˆ10æ—¥LLaVA:å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ·±åº¦è§£æ ä¸€ã€åŸºæœ¬ä»‹ç» 1.1 é¡¹ç›®èƒŒæ™¯ä¸å®šä½ LLaVA(Large Language andVisionAssistant)æ˜¯ç”±Haotian Liuç­‰äººå¼€å‘çš„å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹,æ—¨åœ¨å®ç°GPT-4çº§åˆ«çš„è§†è§‰-è¯­è¨€äº¤äº’èƒ½åŠ›ã€‚è¯¥é¡¹ç›®é€šè¿‡è§†è§‰æŒ‡ä»¤å¾®è°ƒæŠ€æœ¯,å°†é¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨ä¸è¯­è¨€æ¨¡å‹æ·±åº¦èåˆ,åœ¨å¤šä¸ªå¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°SOTAæ°´å¹³\n\n\nCSDNåšå®¢\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=45N1tM8BL16DNTUCBRveHW8CatGM3WWb3AbEZzLxJNvQYJlv_q8Yl26BoTPcl5PEs0_5cDe9CEQTLRN4HsDjNJ9Ec2ocej1dTucdfr41phi', 'rank': 1}, {'title': 'LLaVA å¼€æºé¡¹ç›®æŒ‡å—-CSDNåšå®¢', 'abstract': 'LLaVA å¼€æºé¡¹ç›®æŒ‡å—-CSDNåšå®¢\n\n2024å¹´8æœˆ8æ—¥åœ¨LLaVAé¡¹ç›®ä¸­,å¯åŠ¨æ–‡ä»¶å¯èƒ½ä¼šåŒ…å«ä»¥ä¸‹åŠŸèƒ½: æ¨¡å‹è®­ç»ƒ:é€šè¿‡è°ƒç”¨src/trainä¸‹çš„è„šæœ¬æ¥å¼€å§‹æ¨¡å‹çš„ç«¯åˆ°ç«¯è®­ç»ƒã€‚ æ¨ç†æœåŠ¡:å¯ä»¥æ˜¯ç‹¬ç«‹çš„CLIæ¥å£æœåŠ¡,å¦‚python src/inference/cli/main.py,æˆ–è€…ä¸€ä¸ªç½‘é¡µæœåŠ¡å™¨,ä¾‹å¦‚ä½¿ç”¨Gradioåº“æä¾›çš„äº¤äº’å¼ç•Œé¢ã€‚ æ ¹æ®é¡¹ç›®éœ€æ±‚,å¯åŠ¨æ–‡ä»¶å¯èƒ½ä¼šæ¥å—å‘½ä»¤è¡Œå‚æ•°æ¥å®šåˆ¶è¿è¡Œæ¨¡å¼,ä¾‹å¦‚æ¨¡å‹è·¯å¾„ã€é…...\n\n\nCSDNåšå®¢\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=_GDDrDUq7d5PvBSUE_SU0uXppY2f5WFhipBR7Uqcc1ZkkCUgaP-nQsjjKkEpuUe0XPzTvxYIvT1HcvDdA51rY3DlFvtPKaOw1wnO__kNVpu', 'rank': 2}, {'title': 'å¤§å®¶è¿˜åœ¨æœarduinoå¼€æºé¡¹ç›®é¡¹ç›®å¼€æºjavaä¼˜ç§€å¼€æºé¡¹ç›®androidå¼€æºé¡¹ç›®phpå¼€æºé¡¹ç›®luaå¼€æºé¡¹ç›®llvmæºç åˆ†æipaç¬¬ä¸‰æ–¹è½¯ä»¶æºç›®å‰ç«çˆ†çš„Layer3é¡¹ç›®flizaè½¯ä»¶æº', 'abstract': 'å¤§å®¶è¿˜åœ¨æœarduinoå¼€æºé¡¹ç›®é¡¹ç›®å¼€æºjavaä¼˜ç§€å¼€æºé¡¹ç›®androidå¼€æºé¡¹ç›®phpå¼€æºé¡¹ç›®luaå¼€æºé¡¹ç›®llvmæºç åˆ†æipaç¬¬ä¸‰æ–¹è½¯ä»¶æºç›®å‰ç«çˆ†çš„Layer3é¡¹ç›®flizaè½¯ä»¶æº', 'url': '/s?wd=arduino%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE&usm=1&ie=utf-8&rsv_pq=facd9da201df2715&oq=llava%20%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE&rsv_t=a370l6lLs9vtho4n5pSkSJ3iJWx5c3thTvYP%2BF6B%2BkAhvmFX%2BUqY8A2eIuo&rsf=101633403&rsv_dl=0_prs_28608_1', 'rank': 3}, {'title': '...All You Need!é¦–ä¸ªå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹é€šç”¨è¯„æµ‹å™¨LLaVA-Critic - çŸ¥...', 'abstract': '...All You Need!é¦–ä¸ªå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹é€šç”¨è¯„æµ‹å™¨LLaVA-Critic - çŸ¥...\n\n\n\n\n\n\n\n\n\n2024å¹´10æœˆ14æ—¥é¡¹ç›®ä¸»é¡µ:llava-vl.github.io/blog æ•°æ®ä¸æ¨¡å‹å¼€æº:huggingface.co/collecti é¦–å…ˆ,è¯¥å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªæ¶µç›–äº†å¤šæ ·åŒ–è¯„æµ‹åœºæ™¯å’Œè¯„åˆ†æ ‡å‡†çš„è¯„æµ‹æŒ‡ä»¤éµå¾ªæ•°æ®é›†(critic instruction-following dataset);ä¹‹å,åœ¨è¿™ä¸€æ•°æ®é›†ä¸Šè®­ç»ƒ LLaVA-Critic,ä½¿ä¹‹å­¦ä¼šå¯¹æ¨¡å‹å›å¤ç»™å‡ºåˆç†è¯„åˆ†(judgement)å’Œæ‰“åˆ†ä¾æ®(reason);æ›´è¿›ä¸€æ­¥,åœ¨å¤šæ¨¡æ€...\n\n\nçŸ¥ä¹\n\n\n\n\n\n\n\n\n\ue680', 'url': 'http://www.baidu.com/link?url=45N1tM8BL16DNTUCBRveHXeC1feDkRyhnqsuVuerbsUGbrvRJ4HDgC5L7cMr7qUPzIiHntlijTK6ZCocTrZpB_', 'rank': 4}, {'title': 'åœ¨çº¿æ•™ç¨‹ | æ‰“è´¥ GPT-4V?è¶…å¼ºå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹ LLaVA-OneVis', 'abstract': 'åœ¨çº¿æ•™ç¨‹ | æ‰“è´¥ GPT-4V?è¶…å¼ºå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹ LLaVA-OneVis\n\n\n\n\n\n\n\n\n\n2024å¹´10æœˆ16æ—¥è¿‘æœŸ,æ¥è‡ªå­—èŠ‚è·³åŠ¨ã€å—æ´‹ç†å·¥å¤§å­¦ã€é¦™æ¸¯ä¸­æ–‡å¤§å­¦å’Œé¦™æ¸¯ç§‘æŠ€å¤§å­¦çš„ç ”ç©¶äººå‘˜å…±åŒå¼€æºäº† LLaVA-OneVision å¤šæ¨¡æ€å¤§æ¨¡å‹,è¯¥æ¨¡å‹åœ¨å•å›¾åƒã€å¤šå›¾åƒå’Œè§†é¢‘ä»»åŠ¡ä¸­å‡å±•ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ä¸“ä¸ºå¤šæ¨¡æ€å¤§å‹æ¨¡å‹è®¾è®¡çš„è¯„ä¼°æ¡†æ¶ LMMs-Eval ä¸­æ˜¾ç¤º,LLaVA-OneVision-72B åœ¨å¤§å¤šæ•°åŸºå‡†ä¸Šä¼˜äº GPT-4V å’Œ GPT-4o,å¦‚ä¸‹å›¾æ‰€ç¤º: LLaVA...\n\n\nå“”å“©å“”å“©\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=45N1tM8BL16DNTUCBRveHW8CatGM3WWb3AbEZzLxJNukTd4V0G9Q8TbVXcVtnF3m8QZWIg-HdrTUtHGamgId1_', 'rank': 5}, {'title': 'LLaVAå¤šæ¨¡æ€å¼€æºå¤§æ¨¡å‹æºç åˆ†æ - çŸ¥ä¹', 'abstract': 'LLaVAå¤šæ¨¡æ€å¼€æºå¤§æ¨¡å‹æºç åˆ†æ - çŸ¥ä¹\n\n\n\n\n\n\n\n\n\n2024å¹´7æœˆ13æ—¥LLaVA-Model åœ¨transformersä»“åº“ä¸­å¯ä»¥çœ‹åˆ°llavaçš„æºç ,é¦–å…ˆæ˜¯LlavaForConditionalGenerationç±»,ç»§æ‰¿è‡ªPreTrainedModel,è¿™ä¸ªç±»æ˜¯æ‰€æœ‰æ¨¡å‹çš„åŸºç±»,åŒ…å«äº†ä¸€äº›é€šç”¨çš„æ–¹æ³•,æ¯”å¦‚ä¿å­˜æ¨¡å‹ã€åŠ è½½æ¨¡å‹ã€åˆå§‹åŒ–æƒé‡ç­‰ã€‚ ç»§æ‰¿å…³ç³»ä¸º:LlavaForConditionalGeneration-> LlavaPreTrainedModel-> PreTrainedModel ...\n\n\nçŸ¥ä¹\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=_EbN_JeVIesm7ycSZ8rJa0PTsw5ljj1qYZCWUCic37Y8ZL0LcFEGwu8VgE4CnpRo', 'rank': 6}, {'title': 'LLaVAé¡¹ç›®å®æˆ˜:å¦‚ä½•è¿è¡ŒDemo-ç™¾åº¦å¼€å‘è€…ä¸­å¿ƒ', 'abstract': 'LLaVAé¡¹ç›®å®æˆ˜:å¦‚ä½•è¿è¡ŒDemo-ç™¾åº¦å¼€å‘è€…ä¸­å¿ƒ\n\n2024å¹´3æœˆ28æ—¥LLaVAé¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„å¼€æºé¡¹ç›®,æ—¨åœ¨å®ç°é«˜æ•ˆçš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„ç¥ç»ç½‘ç»œæ¨¡å‹,LLaVAèƒ½å¤Ÿåœ¨å¤šç§åœºæ™¯ä¸‹å®ç°é«˜æ•ˆçš„æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘ç­‰åŠŸèƒ½ã€‚ äºŒã€ç¯å¢ƒæ­å»º åœ¨è¿è¡ŒLLaVAé¡¹ç›®çš„Demoä¹‹å‰,æˆ‘ä»¬éœ€è¦å…ˆæ­å»ºä¸€ä¸ªé€‚åˆé¡¹ç›®çš„è¿è¡Œç¯å¢ƒã€‚è¿™ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢: å®‰è£…Git:Gitæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ç‰ˆ...\n\n\nç™¾åº¦å¼€å‘è€…ä¸­å¿ƒ\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=StabwoaNrJrGB9oflOtZo9sjs45fGlhk-ZY1c4fyo5Q0cOG1igUTIWkYJCU9fQh9U70czajl-73iWVBmVbDFVK', 'rank': 7}, {'title': 'æ¨¡å—åŒ–é‡æ„LLaVA,æ›¿æ¢åªéœ€æ·»åŠ 1-2ä¸ªæ–‡ä»¶,TinyLLaVA Factoryæ¥äº†', 'abstract': 'æ¨¡å—åŒ–é‡æ„LLaVA,æ›¿æ¢åªéœ€æ·»åŠ 1-2ä¸ªæ–‡ä»¶,TinyLLaVA Factoryæ¥äº†\n\n\n\n\n\n\n\n\n\n2024å¹´5æœˆ27æ—¥æ¥ä¸‹æ¥ï¼Œåˆ’é‡ç‚¹ï¼TinyLLaVA Factory Github é¡¹ç›®è¿˜æ‰‹æŠŠæ‰‹æ•™ä½ å®šåˆ¶è‡ªå·±çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚åªéœ€ç®€å•åœ°æ·»åŠ  1-2 ä¸ªæ–‡ä»¶ï¼Œå°±å¯ä»¥è½»æ¾æ›¿æ¢ LLM ç»„ä»¶ã€è§†è§‰ç¼–ç å™¨ç»„ä»¶ã€è¿æ¥å™¨ç»„ä»¶ã€‚æ‹¿æ›¿æ¢ LLM æ¨¡å‹ä¸¾ä¾‹ã€‚æ®ä½¿ç”¨è¿‡ LLaVA ä»£ç åº“çš„åŒå­¦ååº”ï¼ŒLLaVA ä»£ç æƒ³æ›¿æ¢é Llama ç³»åˆ—çš„è¯­è¨€æ¨¡å‹å®¹æ˜“å‡ºé”™ã€‚è€Œ TinyLLaVA Factory å¯ä»¥...\n\n\næœºå™¨ä¹‹å¿ƒPro\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=_EbN_JeVIesm7ycSZ8rJaBwHHV8vARWo40T1Oi1odiaoZekQY8n1kNnclFqCH1eBCy-ZHcpBawNIFtOMjo6-kCKG9tAfGFjRlM4JxZZpB2q', 'rank': 8}, {'title': 'ä¸»æµå…­å¤§å¼€æºé¡¹ç›®,é«˜æ•ˆæå‡ä»£ç å®¡è®¡ã€æ•°æ®ç®¡ç†å’Œå›¾åƒç”Ÿæˆ', 'abstract': 'ä¸»æµå…­å¤§å¼€æºé¡¹ç›®,é«˜æ•ˆæå‡ä»£ç å®¡è®¡ã€æ•°æ®ç®¡ç†å’Œå›¾åƒç”Ÿæˆ \n\n\n\n\n\n\n\n\n\n2024å¹´8æœˆ16æ—¥æœ¬æ–‡ç²¾é€‰å…­å¤§ GitHub å¼€æºé¡¹ç›®,æ¶µç›–å¤§å‹è¯­è¨€æ¨¡å‹ã€ä»£ç å®¡è®¡ã€æ— ä»£ç æ•°æ®åº“ã€å›¾åƒç”Ÿæˆä¼˜åŒ–ã€é”™è¯¯è·Ÿè¸ªå’Œé«˜æ–¯ç‚¹é˜µå…‰æ …åŒ–,æ—¨åœ¨å¸®åŠ©å¼€å‘è€…æå‡å·¥ä½œæ•ˆç‡å’Œé¡¹ç›®è´¨é‡ã€‚ ç›®å½• 1. CKEditor 5 2. LLaVA-NeXT:å¤§å‹å¤šæ¨¡å¼æ¨¡å‹ 3. Multiplier:ä»£ç å®¡è®¡æ•ˆç‡å€å¢ 4. Teable:ä¸‹ä¸€ä»£åŸºäº Postgres çš„ Airtable æ— ä»£ç æ›¿ä»£å“ ...\n\n\nä¸ªäººå›¾ä¹¦é¦†\n\n\n\n\n\n\n\n\n\ue680\næ’­æŠ¥\n\n\n\ue67d\næš‚åœ', 'url': 'http://www.baidu.com/link?url=p4tz5S3lFp8si5AmtciS_aGxkwwwzXCW4rvn0nEvcjSTzTRXy5vqpqJlkTn5LrYDdhYQVO6JJa9R-EJfBoQPAa', 'rank': 9}, {'title': 'LLaVA-NeXT: å¼€æºçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹é¡¹ç›®,... æ¥è‡ªçˆ±å¯å¯-çˆ±ç”Ÿæ´»...', 'abstract': "LLaVA-NeXT: å¼€æºçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹é¡¹ç›®,... æ¥è‡ªçˆ±å¯å¯-çˆ±ç”Ÿæ´»...\n\n\n\n\n\n\n\n\n\n2024å¹´5æœˆ10æ—¥ã€LLaVA-NeXT: å¼€æºçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹é¡¹ç›®,ä¸“æ³¨äºæå‡è¯­è¨€å’Œè§†è§‰ä»»åŠ¡çš„å¤„ç†èƒ½åŠ›ã€‘'LLaVA-NeXT: Open Large Multimodal Models' GitHub: github.com/LLaVA-VL/LLaVA-NeXT #å¼€æº# #æœºå™¨å­¦ä¹ # #äººå·¥æ™ºèƒ½# \u200b\u200b\u200b\u200b  Ã»æ”¶è—  10  è¯„è®º  Ã±10  è¯„è®º o p åŒæ—¶è½¬å‘åˆ°æˆ‘çš„å¾®åš  æŒ‰çƒ­åº¦ æŒ‰æ—¶é—´  æ­£åœ¨...\n\n\nå¾®åš", 'url': 'http://www.baidu.com/link?url=_EbN_JeVIesm7ycSZ8rJaDc-r-ooYNH0eZaC7ORXxmpzrco8UkZPdj5EFB-AyBWC', 'rank': 10}]
2025-06-08 17:24:10.432 | INFO     | agents.umlagent:update_plan_status:153 - Marked step 0 as completed in plan plan_1749374619
2025-06-08 17:24:10.432 | INFO     | agents.base:run:133 - Executing step 7/20
2025-06-08 17:24:18.060 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: é€šè¿‡æœç´¢ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†å¤šä¸ªä¸llavaç›¸å…³çš„å¼€æºé¡¹ç›®ã€‚æ¥ä¸‹æ¥å°†é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„é¡¹ç›®è¿›è¡Œå…‹éš†ã€‚æˆ‘å°†ä½¿ç”¨github_repo_cloner_sshå·¥å…·æ¥å…‹éš†ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„é¡¹ç›®ï¼šLLaVA-VL/LLaVA-NeXTã€‚
2025-06-08 17:24:18.061 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:24:18.061 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['github_repo_cloner_ssh']
2025-06-08 17:24:18.061 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_name": "LLaVA-VL/LLaVA-NeXT"}']
2025-06-08 17:24:22.752 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'github_repo_cloner_ssh' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:github_repo_cloner_ssh`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT
2025-06-08 17:24:22.753 | INFO     | agents.umlagent:update_plan_status:153 - Marked step 1 as completed in plan plan_1749374619
2025-06-08 17:24:22.753 | INFO     | agents.base:run:133 - Executing step 8/20
2025-06-08 17:24:34.375 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: Using tools response: é¡¹ç›®å·²ç»æˆåŠŸå…‹éš†ï¼Œç°åœ¨å°†æ‰§è¡Œä¸‹ä¸€æ­¥ï¼šç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLå›¾ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿æ‰€æœ‰PythonåŒ…ä¸­éƒ½åŒ…å«__init__.pyæ–‡ä»¶ã€‚æˆ‘å°†ä½¿ç”¨ensure_init_pyå·¥å…·æ¥å®Œæˆè¿™ä¸€æ­¥éª¤ã€‚
2025-06-08 17:24:34.376 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:24:34.376 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['ensure_init_py']
2025-06-08 17:24:34.377 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"root_dir_path": "D:\\\\deep_learning\\\\codes\\\\umlagent\\\\app\\\\workspace\\\\tmp_codes\\\\LLaVA-NeXT"}']
2025-06-08 17:24:34.390 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'ensure_init_py' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:ensure_init_py`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
æˆåŠŸåœ¨ä»¥ä¸‹ 14 ä¸ªç›®å½•ä¸­åˆ›å»ºäº† __init__.py æ–‡ä»¶:
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\eval\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\model\language_model\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\model\multimodal_encoder\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\model\multimodal_encoder\dev_eva_clip\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\model\multimodal_encoder\eva_clip\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\model\multimodal_encoder\mlcd\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\model\multimodal_projector\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\model\multimodal_resampler\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\llava\train\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\playground\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\playground\demo\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\scripts\__init__.py
- D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\scripts\archived\__init__.py
2025-06-08 17:24:34.391 | INFO     | agents.umlagent:update_plan_status:153 - Marked step 2 as completed in plan plan_1749374619
2025-06-08 17:24:34.391 | INFO     | agents.base:run:133 - Executing step 9/20
2025-06-08 17:24:44.054 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: Using tools response: å·²ç»æˆåŠŸåˆ›å»ºäº†æ‰€æœ‰å¿…è¦çš„__init__.pyæ–‡ä»¶ï¼Œç°åœ¨å¯ä»¥ç”Ÿæˆæ‰€é€‰é¡¹ç›®çš„UMLå›¾ã€‚æˆ‘å°†ä½¿ç”¨code_to_uml_generator_multilangå·¥å…·æ¥å®Œæˆè¿™ä¸€æ­¥éª¤ã€‚
2025-06-08 17:24:44.055 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:24:44.055 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['code_to_uml_generator_multilang']
2025-06-08 17:24:44.055 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"repo_path": "D:\\\\deep_learning\\\\codes\\\\umlagent\\\\app\\\\workspace\\\\tmp_codes\\\\LLaVA-NeXT", "output_png_path": "D:\\\\deep_learning\\\\codes\\\\umlagent\\\\app\\\\workspace\\\\tmp_codes\\\\LLaVA-NeXT\\\\uml_diagram.png"}']
2025-06-08 17:24:45.808 | INFO     | tools.uml:execute:696 - å‡†å¤‡é€šè¿‡ WebSocket å‘é€ UML å›¾ç‰‡ 'uml_diagram.png'ã€‚
2025-06-08 17:24:45.825 | INFO     | tools.uml:execute:711 - UML å›¾ç‰‡ 'uml_diagram.png' å·²é€šè¿‡ WebSocket å‘é€ (615051 å­—èŠ‚)ã€‚
2025-06-08 17:24:45.826 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'code_to_uml_generator_multilang' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:code_to_uml_generator_multilang`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
UML å›¾è¡¨å’Œæ–‡æœ¬æè¿°å·²æˆåŠŸç”Ÿæˆã€‚
PNG å›¾åƒä¿å­˜è·¯å¾„: 'D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\uml_diagram.png'

---
UML å›¾è¡¨æ–‡æœ¬æè¿°å†…å®¹:
---
# UML å›¾è¡¨æ–‡æœ¬æè¿°

## Class: `AdaptiveKLController`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### å±æ€§ (Attributes)
- `horizon`
- `target`
- `value`

### æ–¹æ³• (Methods)
- `__init__(self, init_kl_coef, target, horizon)`
- `update(self, current, n_steps)`

---

## Class: `AllGather`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.autograd.Function`

### æ–¹æ³• (Methods)
- `backward(ctx, grad_output)`
- `forward(ctx, tensor, rank, world_size)`

---

## Class: `Attention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `attn_drop`
- `head_dim`
- `in_proj_weight`
- `inner_attn_ln`
- `logit_scale_max`
- `num_heads`
- `out_drop`
- `out_proj`
- `proj`
- `proj_drop`
- `rope`
- `scale`
- `scale_heads`
- `scaled_cosine`
- `subln`
- `xattn`
- `xattn_drop`

### æ–¹æ³• (Methods)
- `__init__(self, dim, num_heads, qkv_bias, qk_scale, attn_drop, proj_drop, window_size, attn_head_dim, xattn, rope, subln, norm_layer)`
- `__init__(self, dim, num_heads, qkv_bias, scaled_cosine, scale_heads, logit_scale_max, attn_drop, proj_drop, xattn, rope)`
- `forward(self, x, attn_mask: Optional[torch.Tensor])`
- `forward(self, x, rel_pos_bias, attn_mask)`

---

## Class: `AttentionPool2d`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modified_resnet`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `c_proj`
- `k_proj`
- `num_heads`
- `positional_embedding`
- `q_proj`
- `v_proj`

### æ–¹æ³• (Methods)
- `__init__(self, spacial_dim: int, embed_dim: int, num_heads: int, output_dim: int)`
- `forward(self, x)`

---

## Class: `AutoModelForCausalLMWithValueHead`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_value_head`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModelWrapper`

### å±æ€§ (Attributes)
- `lm_head_namings`
- `supported_args`
- `transformers_parent_class`
- `v_head`

### æ–¹æ³• (Methods)
- `__init__(self, pretrained_model, **kwargs)`
- `_init_weights(self, **kwargs)`
- `forward(self, input_ids, past_key_values, attention_mask, **kwargs)`
- `generate(self, *args, **kwargs)`
- `post_init(self, state_dict)`
- `push_to_hub(self, *args, **kwargs)`
- `state_dict(self, *args, **kwargs)`

---

## Class: `AutoModelForSeq2SeqLMWithValueHead`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_value_head`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModelWrapper`

### å±æ€§ (Attributes)
- `is_encoder_decoder`
- `lm_head_namings`
- `supported_args`
- `transformers_parent_class`
- `v_head`

### æ–¹æ³• (Methods)
- `__init__(self, pretrained_model, **kwargs)`
- `_has_lm_head(self)`
- `_init_weights(self, **kwargs)`
- `forward(self, input_ids, past_key_values, attention_mask, **kwargs)`
- `generate(self, *args, **kwargs)`
- `post_init(self, state_dict)`
- `push_to_hub(self, *args, **kwargs)`
- `state_dict(self, *args, **kwargs)`

---

## Class: `BaseModelOutput`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_model`

---

## Class: `BaseProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_clip_processors`

### å±æ€§ (Attributes)
- `transform`

### æ–¹æ³• (Methods)
- `__call__(self, item)`
- `__init__(self)`

---

## Class: `BaseTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `base`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PyTorchModelHubMixin`

### å±æ€§ (Attributes)
- `config`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `_save_pretrained(self, save_directory)`
- `compute_rewards(self, *args)`
- `loss(self, *args)`
- `step(self, *args)`

---

## Class: `BertAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `output`
- `pruned_heads`
- `self`

### æ–¹æ³• (Methods)
- `__init__(self, config, is_cross_attention)`
- `forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)`
- `prune_heads(self, heads)`

---

## Class: `BertEmbeddings`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `LayerNorm`
- `config`
- `dropout`
- `position_embedding_type`
- `position_embeddings`
- `word_embeddings`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids, position_ids, query_embeds, past_key_values_length)`

---

## Class: `BertEncoder`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `layer`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, query_length)`

---

## Class: `BertForMaskedLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BertPreTrainedModel`

### å±æ€§ (Attributes)
- `_keys_to_ignore_on_load_missing`
- `_keys_to_ignore_on_load_unexpected`
- `bert`
- `cls`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids, attention_mask, position_ids, head_mask, query_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict, return_logits, is_decoder)`
- `get_output_embeddings(self)`
- `set_output_embeddings(self, new_embeddings)`

---

## Class: `BertIntermediate`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `dense`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states)`

---

## Class: `BertLMHeadModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BertPreTrainedModel`

### å±æ€§ (Attributes)
- `_keys_to_ignore_on_load_missing`
- `_keys_to_ignore_on_load_unexpected`
- `bert`
- `cls`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `_reorder_cache(self, past, beam_idx)`
- `forward(self, input_ids, attention_mask, position_ids, head_mask, query_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, return_logits, is_decoder, reduction)`
- `get_output_embeddings(self)`
- `prepare_inputs_for_generation(self, input_ids, query_embeds, past, attention_mask, **model_kwargs)`
- `set_output_embeddings(self, new_embeddings)`

---

## Class: `BertLMPredictionHead`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `bias`
- `decoder`
- `transform`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states)`

---

## Class: `BertLayer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attention`
- `chunk_size_feed_forward`
- `config`
- `intermediate`
- `intermediate_query`
- `layer_num`
- `output`
- `output_query`
- `seq_len_dim`

### æ–¹æ³• (Methods)
- `__init__(self, config, layer_num)`
- `feed_forward_chunk(self, attention_output)`
- `feed_forward_chunk_query(self, attention_output)`
- `forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, query_length)`

---

## Class: `BertModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BertPreTrainedModel`

### å±æ€§ (Attributes)
- `config`
- `embeddings`
- `encoder`
- `pooler`

### æ–¹æ³• (Methods)
- `__init__(self, config, add_pooling_layer)`
- `_prune_heads(self, heads_to_prune)`
- `forward(self, input_ids, attention_mask, position_ids, head_mask, query_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, is_decoder)`
- `get_extended_attention_mask(self, attention_mask: Tensor, input_shape: Tuple[int], device: device, is_decoder: bool, has_query: bool) -> Tensor`
- `get_input_embeddings(self)`
- `set_input_embeddings(self, value)`

---

## Class: `BertOnlyMLMHead`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `predictions`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, sequence_output)`

---

## Class: `BertOutput`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `LayerNorm`
- `dense`
- `dropout`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states, input_tensor)`

---

## Class: `BertPooler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `activation`
- `dense`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states)`

---

## Class: `BertPreTrainedModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModel`

### å±æ€§ (Attributes)
- `_keys_to_ignore_on_load_missing`
- `base_model_prefix`
- `config_class`

### æ–¹æ³• (Methods)
- `_init_weights(self, module)`

---

## Class: `BertPredictionHeadTransform`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `LayerNorm`
- `dense`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states)`

---

## Class: `BertSelfAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `all_head_size`
- `attention_head_size`
- `config`
- `dropout`
- `num_attention_heads`
- `position_embedding_type`
- `query`
- `save_attention`

### æ–¹æ³• (Methods)
- `__init__(self, config, is_cross_attention)`
- `forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)`
- `get_attention_map(self)`
- `get_attn_gradients(self)`
- `save_attention_map(self, attention_map)`
- `save_attn_gradients(self, attn_gradients)`
- `transpose_for_scores(self, x)`

---

## Class: `BertSelfOutput`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `LayerNorm`
- `dense`
- `dropout`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states, input_tensor)`

---

## Class: `BestOfNSampler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `best_of_n_sampler`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `gen_config`
- `length_sampler`
- `model`
- `n_candidates`
- `queries_to_scores`
- `sample_size`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, model: PreTrainedModelWrapper, tokenizer: Union[PreTrainedTokenizer, PreTrainedTokenizerFast], queries_to_scores: Callable[[List[str]], List[float]], length_sampler: Any, sample_size: int, seed: Optional[int], n_candidates: int, generation_config: Optional[GenerationConfig]) -> None`
- `generate(self, tokenized_query: Union[List[int], torch.Tensor, List[torch.Tensor], List[List[int]]], skip_special_tokens: bool, device: Optional[Union[str, torch.device]], **generation_kwargs) -> List[List[str]]`

---

## Class: `Block`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `attn`
- `drop_path`
- `norm1`
- `norm2`
- `postnorm`

### æ–¹æ³• (Methods)
- `__init__(self, dim, num_heads, mlp_ratio, qkv_bias, qk_scale, drop, attn_drop, drop_path, init_values, act_layer, norm_layer, window_size, attn_head_dim, xattn, rope, postnorm, subln, naiveswiglu)`
- `forward(self, x, rel_pos_bias, attn_mask)`

---

## Class: `Bottleneck`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modified_resnet`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `act1`
- `act2`
- `act3`
- `avgpool`
- `bn1`
- `bn2`
- `bn3`
- `conv1`
- `conv2`
- `conv3`
- `downsample`
- `expansion`
- `stride`

### æ–¹æ³• (Methods)
- `__init__(self, inplanes, planes, stride)`
- `forward(self, x: torch.Tensor)`

---

## Class: `CLIP`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `ln_final`
- `logit_scale`
- `positional_embedding`
- `text_projection`
- `token_embedding`
- `transformer`
- `visual`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, embed_dim: int, vision_cfg: CLIPVisionCfg, text_cfg: CLIPTextCfg, quick_gelu: bool, cast_dtype: Optional[torch.dtype])`
- `encode_image(self, image, normalize: bool)`
- `encode_text(self, text, normalize: bool)`
- `forward(self, image, text)`
- `lock_image_tower(self, unlocked_groups, freeze_bn_stats)`
- `no_weight_decay(self)`
- `set_grad_checkpointing(self, enable)`

---

## Class: `CLIPTextCfg`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### å±æ€§ (Attributes)
- `attn_mask: bool`
- `context_length: int`
- `fusedLN: bool`
- `heads: int`
- `hf_model_name: str`
- `hf_model_pretrained: bool`
- `hf_tokenizer_name: str`
- `layers: int`
- `ls_init_value: Optional[float]`
- `masked_language_modeling: bool`
- `pooler_type: str`
- `proj: str`
- `vocab_size: int`
- `width: int`
- `xattn: bool`

---

## Class: `CLIPVisionCfg`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### å±æ€§ (Attributes)
- `drop_path_rate: Optional[float]`
- `eva_model_name: str`
- `fusedLN: bool`
- `global_average_pool: bool`
- `head_width: int`
- `image_size: Union[Tuple[int, int], int]`
- `intp_freq: bool`
- `layers: Union[Tuple[int, int, int, int], int]`
- `ls_init_value: Optional[float]`
- `mlp_ratio: float`
- `naiveswiglu: bool`
- `patch_dropout: float`
- `patch_size: int`
- `postnorm: bool`
- `pt_hw_seq_len: int`
- `qkv_bias: bool`
- `rope: bool`
- `subln: bool`
- `timm_model_name: str`
- `timm_model_pretrained: bool`
- `timm_pool: str`
- `timm_proj: str`
- `timm_proj_bias: bool`
- `use_rms_norm: bool`
- `width: int`
- `xattn: bool`

---

## Class: `CLIPVisionTower`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `clip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `is_loaded`
- `select_feature`
- `select_layer`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `config(self)`
- `device(self)`
- `dtype(self)`
- `dummy_feature(self)`
- `feature_select(self, image_forward_outs)`
- `forward(self, images)`
- `hidden_size(self)`
- `image_size(self)`
- `load_model(self, device_map)`
- `num_patches(self)`
- `num_patches_per_side(self)`

---

## Class: `CLIPVisionTowerS2`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `clip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `CLIPVisionTower`

### å±æ€§ (Attributes)
- `s2_image_size`
- `s2_scales`
- `s2_split_size`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `forward(self, images)`
- `forward_feature(self, images)`
- `hidden_size(self)`
- `load_model(self, device_map)`

---

## Class: `ChatMlSpecialTokens`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### å±æ€§ (Attributes)
- `bos_token: str`
- `eos_token: str`
- `pad_token: str`

### æ–¹æ³• (Methods)
- `assistant(self)`
- `chat_template(self)`
- `system(self)`
- `user(self)`

---

## Class: `ClipLoss`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `loss`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `cache_labels`
- `gather_with_grad`
- `label_smoothing_cross_entropy`
- `labels`
- `local_loss`
- `prev_num_logits`
- `rank`
- `use_horovod`
- `world_size`

### æ–¹æ³• (Methods)
- `__init__(self, local_loss, gather_with_grad, cache_labels, rank, world_size, use_horovod, smoothing)`
- `forward(self, image_features, text_features, logit_scale)`

---

## Class: `ClsPooler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `cls_token_position`
- `use_pooler_output`

### æ–¹æ³• (Methods)
- `__init__(self, use_pooler_output)`
- `forward(self, x: BaseModelOutput, attention_mask: TensorType)`

---

## Class: `ConstantLengthDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `IterableDataset`

### å±æ€§ (Attributes)
- `add_special_tokens`
- `append_concat_token`
- `concat_token_id`
- `current_size`
- `dataset`
- `infinite`
- `max_buffer_size`
- `seq_length`
- `shuffle`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, tokenizer, dataset, dataset_text_field, formatting_func, infinite, seq_length, num_of_sequences, chars_per_token, eos_token_id, shuffle, append_concat_token, add_special_tokens)`
- `__iter__(self)`
- `__len__(self)`

---

## Class: `Controller`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `controller`

### å±æ€§ (Attributes)
- `dispatch_method`
- `heart_beat_thread`
- `worker_info`

### æ–¹æ³• (Methods)
- `__init__(self, dispatch_method: str)`
- `get_worker_address(self, model_name: str)`
- `get_worker_status(self, worker_name: str)`
- `list_models(self)`
- `receive_heart_beat(self, worker_name: str, queue_length: int)`
- `refresh_all_workers(self)`
- `register_worker(self, worker_name: str, check_heart_beat: bool, worker_status: dict)`
- `remove_stable_workers_by_expiration(self)`
- `remove_worker(self, worker_name: str)`
- `worker_api_generate_stream(self, params)`
- `worker_api_get_status(self)`

---

## Class: `Conversation`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `conversation`

### å±æ€§ (Attributes)
- `messages: List[List[str]]`
- `offset: int`
- `roles: List[str]`
- `sep2: str`
- `sep: str`
- `sep_style: SeparatorStyle`
- `skip_next: bool`
- `stop_str: Union[str, List[str]]`
- `stop_token_ids: List[int]`
- `system: str`
- `tokenizer: Any`
- `tokenizer_id: str`
- `version: str`

### æ–¹æ³• (Methods)
- `append_message(self, role, message)`
- `copy(self)`
- `dict(self)`
- `get_images(self, return_pil, return_path)`
- `get_prompt(self)`
- `is_image_file(self, filename)`
- `is_video_file(self, filename)`
- `process_image(self, image, image_process_mode, return_pil, image_format)`
- `to_gradio_chatbot(self)`

---

## Class: `CustomAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attn_drop`
- `head_dim`
- `in_proj_weight`
- `logit_scale_max`
- `num_heads`
- `out_drop`
- `out_proj`
- `scale`
- `scale_heads`
- `scaled_cosine`
- `xattn`
- `xattn_drop`

### æ–¹æ³• (Methods)
- `__init__(self, dim, num_heads, qkv_bias, scaled_cosine, scale_heads, logit_scale_max, attn_drop, proj_drop, xattn)`
- `forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, attn_mask: Optional[torch.Tensor])`

---

## Class: `CustomCLIP`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `logit_scale`
- `text`
- `visual`

### æ–¹æ³• (Methods)
- `__init__(self, embed_dim: int, vision_cfg: CLIPVisionCfg, text_cfg: CLIPTextCfg, quick_gelu: bool, cast_dtype: Optional[torch.dtype], itm_task: bool)`
- `encode_image(self, image, normalize: bool)`
- `encode_text(self, text, normalize: bool)`
- `forward(self, image, text)`
- `lock_image_tower(self, unlocked_groups, freeze_bn_stats)`
- `lock_text_tower(self, unlocked_layers: int, freeze_layer_norm: bool)`
- `no_weight_decay(self)`
- `set_grad_checkpointing(self, enable)`

---

## Class: `CustomResidualAttentionBlock`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attn`
- `ln_1`
- `ln_1_k`
- `ln_1_v`
- `ln_2`
- `ln_attn`
- `ls_1`
- `ls_2`
- `mlp`

### æ–¹æ³• (Methods)
- `__init__(self, d_model: int, n_head: int, mlp_ratio: float, ls_init_value: float, act_layer: Callable, norm_layer: Callable, scale_cosine_attn: bool, scale_heads: bool, scale_attn: bool, scale_fc: bool, cross_attn: bool, xattn: bool)`
- `forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, attn_mask: Optional[torch.Tensor])`

---

## Class: `CustomTransformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `grad_checkpointing`
- `layers`
- `resblocks`
- `width`
- `xattn`

### æ–¹æ³• (Methods)
- `__init__(self, width: int, layers: int, heads: int, mlp_ratio: float, ls_init_value: float, act_layer: Callable, norm_layer: Callable, scale_cosine_attn: bool, scale_heads: bool, scale_attn: bool, scale_fc: bool, cross_attn: bool, xattn: bool)`
- `forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, attn_mask: Optional[torch.Tensor])`
- `get_cast_dtype(self) -> torch.dtype`

---

## Class: `DDPOConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `ddpo_config`

### å±æ€§ (Attributes)
- `accelerator_kwargs: dict`
- `allow_tf32: bool`
- `async_reward_computation: bool`
- `exp_name: str`
- `log_with: Optional[Literal['wandb', 'tensorboard']]`
- `logdir: str`
- `max_workers: int`
- `mixed_precision: str`
- `negative_prompts: Optional[str]`
- `num_checkpoint_limit: int`
- `num_epochs: int`
- `per_prompt_stat_tracking: bool`
- `per_prompt_stat_tracking_buffer_size: int`
- `per_prompt_stat_tracking_min_count: int`
- `project_kwargs: dict`
- `resume_from: Optional[str]`
- `run_name: Optional[str]`
- `sample_batch_size: int`
- `sample_eta: float`
- `sample_guidance_scale: float`
- `sample_num_batches_per_epoch: int`
- `sample_num_steps: int`
- `save_freq: int`
- `seed: int`
- `tracker_kwargs: dict`
- `tracker_project_name: str`
- `train_adam_beta1: float`
- `train_adam_beta2: float`
- `train_adam_epsilon: float`
- `train_adam_weight_decay: float`
- `train_adv_clip_max: float`
- `train_batch_size: int`
- `train_cfg: bool`
- `train_clip_range: float`
- `train_gradient_accumulation_steps: int`
- `train_learning_rate: float`
- `train_max_grad_norm: float`
- `train_num_inner_epochs: int`
- `train_timestep_fraction: float`
- `train_use_8bit_adam: bool`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `to_dict(self)`

---

## Class: `DDPOPipelineOutput`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_sd_base`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `images: torch.Tensor`
- `latents: torch.Tensor`
- `log_probs: torch.Tensor`

---

## Class: `DDPOSchedulerOutput`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_sd_base`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `latents: torch.Tensor`
- `log_probs: torch.Tensor`

---

## Class: `DDPOStableDiffusionPipeline`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_sd_base`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### æ–¹æ³• (Methods)
- `__call__(self, *args, **kwargs) -> DDPOPipelineOutput`
- `autocast(self)`
- `get_trainable_layers(self, *args, **kwargs)`
- `load_checkpoint(self, *args, **kwargs)`
- `save_checkpoint(self, *args, **kwargs)`
- `save_pretrained(self, *args, **kwargs)`
- `scheduler(self)`
- `scheduler_step(self, *args, **kwargs) -> DDPOSchedulerOutput`
- `set_progress_bar_config(self, *args, **kwargs)`
- `text_encoder(self)`
- `tokenizer(self)`
- `unet(self)`
- `vae(self)`

---

## Class: `DDPOTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `ddpo_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseTrainer`

### å±æ€§ (Attributes)
- `_tag_names`
- `accelerator`
- `autocast`
- `config`
- `image_samples_callback`
- `neg_prompt_embed`
- `num_train_timesteps`
- `optimizer`
- `prompt_fn`
- `reward_fn`
- `sd_pipeline`

### æ–¹æ³• (Methods)
- `__init__(self, config: DDPOConfig, reward_function: Callable[[torch.Tensor, Tuple[str], Tuple[Any]], torch.Tensor], prompt_function: Callable[[], Tuple[str, Any]], sd_pipeline: DDPOStableDiffusionPipeline, image_samples_hook: Optional[Callable[[Any, Any, Any], Any]])`
- `_config_check(self) -> Tuple[bool, str]`
- `_generate_samples(self, iterations, batch_size)`
- `_load_model_hook(self, models, input_dir)`
- `_save_model_hook(self, models, weights, output_dir)`
- `_save_pretrained(self, save_directory)`
- `_setup_optimizer(self, trainable_layers_parameters)`
- `_train_batched_samples(self, inner_epoch, epoch, global_step, batched_samples)`
- `calculate_loss(self, latents, timesteps, next_latents, log_probs, advantages, embeds)`
- `compute_rewards(self, prompt_image_pairs, is_async)`
- `create_model_card(self, path: str, model_name: Optional[str]) -> None`
- `loss(self, advantages: torch.Tensor, clip_range: float, ratio: torch.Tensor)`
- `step(self, epoch: int, global_step: int)`
- `train(self, epochs: Optional[int])`

---

## Class: `DPODataCollator`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train_dpo`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DPODataCollatorWithPadding`

### æ–¹æ³• (Methods)
- `__call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]`
- `collate(self, batch)`
- `tokenize_batch_element(self, prompt: str, chosen: str, rejected: str, has_image: bool) -> Dict`

---

## Class: `DPODataCollatorWithPadding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### å±æ€§ (Attributes)
- `is_encoder_decoder: Optional[bool]`
- `label_pad_token_id: int`
- `pad_token_id: int`
- `tokenizer: PreTrainedTokenizerBase`

### æ–¹æ³• (Methods)
- `__call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]`

---

## Class: `DPODataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train_dpo`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Dataset`

### å±æ€§ (Attributes)
- `data_args`
- `list_data_dict`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__getitem__(self, i) -> Dict[str, torch.Tensor]`
- `__init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer, data_args: DataArguments)`
- `__len__(self)`
- `_get_item(self, i) -> Dict[str, torch.Tensor]`
- `lengths(self)`
- `modality_lengths(self)`
- `process_image(self, image_file)`

---

## Class: `DPOTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `dpo_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### å±æ€§ (Attributes)
- `_peft_has_been_casted_to_bf16`
- `_precomputed_eval_ref_log_probs`
- `_precomputed_train_ref_log_probs`
- `_stored_metrics`
- `_tag_names`
- `beta`
- `dataset_num_proc`
- `dpo_alpha`
- `gamma`
- `generate_during_eval`
- `is_peft_model`
- `label_pad_token_id`
- `label_smoothing`
- `loss_type`
- `max_length`
- `max_prompt_length`
- `max_target_length`
- `model_adapter_name`
- `padding_value`
- `precompute_ref_log_probs`
- `ref_adapter_name`
- `reference_free`
- `tokenizer`
- `truncation_mode`

### æ–¹æ³• (Methods)
- `__init__(self, model: Optional[Union[PreTrainedModel, nn.Module, str]], ref_model: Optional[Union[PreTrainedModel, nn.Module, str]], dpo_alpha: float, beta: float, gamma: float, label_smoothing: float, loss_type: Literal['sigmoid', 'hinge', 'ipo', 'kto_pair'], args: Optional[TrainingArguments], data_collator: Optional[DataCollator], label_pad_token_id: int, padding_value: Optional[int], truncation_mode: str, train_dataset: Optional[Dataset], eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]], tokenizer: Optional[PreTrainedTokenizerBase], model_init: Optional[Callable[[], PreTrainedModel]], callbacks: Optional[List[TrainerCallback]], optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR], preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]], max_length: Optional[int], max_prompt_length: Optional[int], max_target_length: Optional[int], peft_config: Optional[Dict], is_encoder_decoder: Optional[bool], disable_dropout: bool, generate_during_eval: bool, compute_metrics: Optional[Callable[[EvalLoopOutput], Dict]], precompute_ref_log_probs: bool, dataset_num_proc: Optional[int], model_init_kwargs: Optional[Dict], ref_model_init_kwargs: Optional[Dict], model_adapter_name: Optional[str], ref_adapter_name: Optional[str], reference_free: bool)`
- `_prepare_deepspeed(self, model: PreTrainedModelWrapper)`
- `build_tokenized_answer(self, prompt, answer)`
- `compute_loss(self, model: Union[PreTrainedModel, nn.Module], inputs: Dict[str, Union[torch.Tensor, Any]], return_outputs) -> Union[torch.Tensor, Tuple[torch.Tensor, Dict[str, torch.Tensor]]]`
- `compute_reference_log_probs(self, padded_batch: Dict) -> Dict`
- `concatenated_forward(self, model: nn.Module, batch: Dict[str, Union[List, torch.LongTensor]]) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]`
- `concatenated_inputs(batch: Dict[str, Union[List, torch.LongTensor]], is_encoder_decoder: bool, label_pad_token_id: int, padding_value: int, device: Optional[torch.device]) -> Dict[str, torch.LongTensor]`
- `dpo_loss(self, policy_chosen_logps: torch.FloatTensor, policy_rejected_logps: torch.FloatTensor, reference_chosen_logps: torch.FloatTensor, reference_rejected_logps: torch.FloatTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]`
- `evaluation_loop(self, dataloader: DataLoader, description: str, prediction_loss_only: Optional[bool], ignore_keys: Optional[List[str]], metric_key_prefix: str) -> EvalLoopOutput`
- `get_batch_logps(logits: torch.FloatTensor, labels: torch.LongTensor, average_log_prob: bool, label_pad_token_id: int, is_encoder_decoder: bool) -> torch.FloatTensor`
- `get_batch_loss_metrics(self, model, batch: Dict[str, Union[List, torch.LongTensor]], train_eval: Literal['train', 'eval'])`
- `get_batch_samples(self, model, batch: Dict[str, torch.LongTensor]) -> Tuple[str, str]`
- `get_eval_dataloader(self, eval_dataset: Optional[Dataset]) -> DataLoader`
- `get_sft_loss(self, logits, labels)`
- `get_train_dataloader(self) -> DataLoader`
- `log(self, logs: Dict[str, float]) -> None`
- `null_ref_context(self)`
- `prediction_step(self, model: Union[PreTrainedModel, nn.Module], inputs: Dict[str, Union[torch.Tensor, Any]], prediction_loss_only: bool, ignore_keys: Optional[List[str]])`
- `push_to_hub(self, commit_message: Optional[str], blocking: bool, **kwargs) -> str`
- `store_metrics(self, metrics: Dict[str, float], train_eval: Literal['train', 'eval']) -> None`
- `tokenize_row(self, feature, model: Optional[Union[PreTrainedModel, nn.Module]]) -> Dict`

---

## Class: `DataArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### å±æ€§ (Attributes)
- `add_time_instruction: Optional[bool]`
- `data_path: str`
- `early_mix_text: bool`
- `force_sample: Optional[bool]`
- `frames_upbound: Optional[int]`
- `image_aspect_ratio: str`
- `image_crop_resolution: Optional[int]`
- `image_crop_resolution: int`
- `image_folder: Optional[str]`
- `image_grid_pinpoints: Optional[str]`
- `image_split_resolution: Optional[int]`
- `image_split_resolution: int`
- `input_prompt: Optional[str]`
- `is_multimodal: bool`
- `lazy_preprocess: bool`
- `num_sample: Optional[int]`
- `refine_prompt: Optional[bool]`
- `video_folder: Optional[str]`
- `video_fps: Optional[int]`

---

## Class: `DataCollatorForCompletionOnlyLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DataCollatorForLanguageModeling`

### å±æ€§ (Attributes)
- `ignore_index`
- `instruction_template`
- `response_template`

### æ–¹æ³• (Methods)
- `__init__(self, response_template: Union[str, List[int]], instruction_template: Union[str, List[int]], *args, **kwargs)`
- `torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]`

---

## Class: `DataCollatorForSupervisedDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `tokenizer: transformers.PreTrainedTokenizer`

### æ–¹æ³• (Methods)
- `__call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]`
- `pad_sequence(self, input_ids, batch_first, padding_value)`

---

## Class: `DataProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `data_checker`

### å±æ€§ (Attributes)
- `data`
- `file_path`
- `image_root`
- `video_root`

### æ–¹æ³• (Methods)
- `__init__(self, file_path, image_root, video_root)`
- `check_image_and_structure(self, item)`
- `check_image_existence(self, data)`
- `check_item_structure(self, item)`
- `count_items(self)`
- `filter_data(self)`
- `load_data(self)`
- `load_json_data(self, json_path)`
- `process_images(self)`
- `stat_and_filter_data(self, threshold)`
- `stat_data(self)`

---

## Class: `DefaultDDPOStableDiffusionPipeline`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_sd_base`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DDPOStableDiffusionPipeline`

### å±æ€§ (Attributes)
- `pretrained_model`
- `pretrained_revision`
- `sd_pipeline`
- `use_lora`

### æ–¹æ³• (Methods)
- `__call__(self, *args, **kwargs) -> DDPOPipelineOutput`
- `__init__(self, pretrained_model_name: str)`
- `autocast(self)`
- `get_trainable_layers(self)`
- `load_checkpoint(self, models, input_dir)`
- `save_checkpoint(self, models, weights, output_dir)`
- `save_pretrained(self, output_dir)`
- `scheduler(self)`
- `scheduler_step(self, *args, **kwargs) -> DDPOSchedulerOutput`
- `set_progress_bar_config(self, *args, **kwargs)`
- `text_encoder(self)`
- `tokenizer(self)`
- `unet(self)`
- `vae(self)`

---

## Class: `DispatchMethod`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `controller`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Enum`

### å±æ€§ (Attributes)
- `LOTTERY`
- `SHORTEST_QUEUE`

### æ–¹æ³• (Methods)
- `from_str(cls, name)`

---

## Class: `DropPath`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `drop_prob`

### æ–¹æ³• (Methods)
- `__init__(self, drop_prob)`
- `extra_repr(self) -> str`
- `forward(self, x)`

---

## Class: `EVAEncoderWrapper`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `model`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower_pretrained, config)`
- `device(self)`
- `dtype(self)`
- `forward(self, image, **kwargs)`

---

## Class: `EVAVisionTransformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `blocks`
- `cls_token`
- `embed_dim`
- `fc_norm`
- `grad_checkpointing`
- `head`
- `image_size`
- `naiveswiglu`
- `norm`
- `num_classes`
- `num_features`
- `patch_dropout`
- `patch_embed`
- `pos_drop`
- `use_rel_pos_bias`

### æ–¹æ³• (Methods)
- `__init__(self, img_size, patch_size, in_chans, num_classes, embed_dim, depth, num_heads, mlp_ratio, qkv_bias, qk_scale, drop_rate, attn_drop_rate, drop_path_rate, norm_layer, init_values, patch_dropout, use_abs_pos_emb, use_rel_pos_bias, use_shared_rel_pos_bias, rope, use_mean_pooling, init_scale, grad_checkpointing, xattn, postnorm, pt_hw_seq_len, intp_freq, naiveswiglu, subln)`
- `_init_weights(self, m)`
- `fix_init_weight(self)`
- `forward(self, x, return_all_features)`
- `forward_features(self, x, return_all_features)`
- `get_cast_dtype(self) -> torch.dtype`
- `get_classifier(self)`
- `get_num_layers(self)`
- `lock(self, unlocked_groups, freeze_bn_stats)`
- `no_weight_decay(self)`
- `reset_classifier(self, num_classes, global_pool)`
- `set_grad_checkpointing(self, enable)`

---

## Class: `EvaClipImageBaseProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_clip_processors`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseProcessor`

### å±æ€§ (Attributes)
- `mean`
- `normalize`
- `std`

### æ–¹æ³• (Methods)
- `__init__(self, mean, std)`
- `image_mean(self)`

---

## Class: `EvaClipImageTrainProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_clip_processors`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `EvaClipImageBaseProcessor`

### å±æ€§ (Attributes)
- `image_size`
- `transform`

### æ–¹æ³• (Methods)
- `__call__(self, item)`
- `__init__(self, image_size, mean, std, min_scale, max_scale)`
- `crop_size(self)`
- `preprocess(self, images, return_tensors)`
- `size(self)`

---

## Class: `EvaClipVisionTower`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_clip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `is_loaded`
- `vision_tower_name`
- `vision_tower_pretrained`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `device(self)`
- `dtype(self)`
- `forward(self, images)`
- `hidden_size(self)`
- `image_size(self)`
- `load_model(self, device_map)`
- `num_patches(self)`
- `num_patches_per_side(self)`

---

## Class: `EvaViTWrapper`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `args`
- `is_loaded`
- `model_config`
- `pretrained`
- `select_feature`
- `select_layer`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `config(self)`
- `dummy_feature(self)`
- `feature_select(self, image_features)`
- `forward(self, images)`
- `hidden_size(self)`
- `image_size(self)`
- `load_model(self)`
- `num_patches(self)`
- `num_patches_per_side(self)`
- `train(self, mode)`

---

## Class: `Eval`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `evaluate_interleave`

### å±æ€§ (Attributes)
- `commaStrip`
- `periodStrip`
- `punct`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `evaluate_multi_choice_image(self, preditions)`
- `evaluate_multichoice(self, preditions)`
- `evaluate_rouge(self, preds)`
- `judge_multi_choice(self, sample)`
- `process(self, answer)`
- `processPunctuation(self, inText)`
- `process_sample(self, sample)`

---

## Class: `FixedKLController`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### å±æ€§ (Attributes)
- `value`

### æ–¹æ³• (Methods)
- `__init__(self, kl_coef)`
- `update(self, current, n_steps)`

---

## Class: `HFTextEncoder`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `output_dim`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, model_name_or_path: str, output_dim: int, tokenizer_name: str, config: PretrainedConfig, pooler_type: str, proj: str, pretrained: bool, masked_language_modeling: bool)`
- `forward(self, x: TensorType) -> TensorType`
- `forward_mlm(self, input_ids, image_embeds, mlm_probability)`
- `get_num_layers(self)`
- `init_parameters(self)`
- `lock(self, unlocked_layers: int, freeze_layer_norm: bool)`
- `mask(self, input_ids, vocab_size, device, targets, masked_indices, probability_matrix)`
- `set_grad_checkpointing(self, enable)`

---

## Class: `HFTokenizer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tokenizer`

### å±æ€§ (Attributes)
- `tokenizer`

### æ–¹æ³• (Methods)
- `__call__(self, texts: Union[str, List[str]], context_length: int) -> torch.Tensor`
- `__init__(self, tokenizer_name: str)`

---

## Class: `HFVisionTower`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_vision`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `is_loaded`
- `select_feature`
- `select_layer`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `dummy_feature(self)`
- `feature_select(self, image_forward_outs)`
- `forward(self, images)`
- `hidden_size(self)`
- `image_size(self)`
- `load_model(self)`
- `num_patches(self)`
- `num_patches_per_side(self)`

---

## Class: `IdentityMap`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `builder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `torch.nn.Module`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `config(self)`
- `forward(self, x, *args, **kwargs)`

---

## Class: `ImageBindWrapper`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `imagebind`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `is_loaded`
- `select_feature`
- `select_layer`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, select_layer, select_feature, delay_load)`
- `device(self)`
- `dtype(self)`
- `dummy_feature(self)`
- `forward(self, x)`
- `hidden_size(self)`
- `load_model(self)`
- `train(self, mode)`

---

## Class: `IterativeSFTTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `iterative_sft_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### å±æ€§ (Attributes)
- `is_encoder_decoder`
- `is_peft_model`
- `max_length`
- `optimize_device_cache`
- `tokenizer`
- `truncation_mode`

### æ–¹æ³• (Methods)
- `__init__(self, model: PreTrainedModel, args: TrainingArguments, tokenizer: PreTrainedTokenizerBase, optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR], data_collator: Optional[DataCollator], eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]], max_length: Optional[int], truncation_mode: Optional[str], preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]], compute_metrics: Optional[Callable[[EvalLoopOutput], Dict]], optimize_device_cache: Optional[bool])`
- `_maybe_log_save_evaluate(self)`
- `_step_safety_checker(input_ids: List[torch.LongTensor], attention_mask: List[torch.LongTensor], labels: List[torch.LongTensor], texts: List[str], texts_labels: List[str])`
- `prepare_model_inputs(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: torch.Tensor)`
- `step(self, input_ids: Optional[List[torch.LongTensor]], attention_mask: Optional[List[torch.LongTensor]], labels: Optional[List[torch.LongTensor]], texts: Optional[List[str]], texts_labels: Optional[List[str]])`

---

## Class: `KeywordsStoppingCriteria`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mm_utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `StoppingCriteria`

### å±æ€§ (Attributes)
- `keyword_ids`
- `keywords`
- `start_len`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__call__(self, output_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool`
- `__init__(self, keywords, tokenizer, input_ids)`

---

## Class: `LLaVADPOTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `DPOTrainer`

### æ–¹æ³• (Methods)
- `_get_train_sampler(self) -> Optional[torch.utils.data.Sampler]`
- `_save(self, output_dir: Optional[str], state_dict)`
- `_save_checkpoint(self, model, trial, metrics)`

---

## Class: `LLaVAEvalTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_trainer_eval`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LLaVATrainer`

### æ–¹æ³• (Methods)
- `evaluate(self, evaluate_args)`

---

## Class: `LLaVATrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### æ–¹æ³• (Methods)
- `_get_train_sampler(self) -> Optional[torch.utils.data.Sampler]`
- `_save(self, output_dir: Optional[str], state_dict)`
- `_save_checkpoint(self, model, trial, metrics)`
- `create_accelerator_and_postprocess(self)`
- `create_optimizer(self)`
- `get_train_dataloader(self) -> DataLoader`

---

## Class: `LayerNorm`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.LayerNorm`, `nn.LayerNorm`

### æ–¹æ³• (Methods)
- `forward(self, x: torch.Tensor)`

---

## Class: `LayerNormFp32`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.LayerNorm`

### æ–¹æ³• (Methods)
- `__init__(self, *args, **kwargs)`
- `forward(self, x: torch.Tensor)`

---

## Class: `LayerScale`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `gamma`
- `inplace`

### æ–¹æ³• (Methods)
- `__init__(self, dim, init_values, inplace)`
- `forward(self, x)`

---

## Class: `LazySupervisedDataset`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Dataset`

### å±æ€§ (Attributes)
- `data_args`
- `list_data_dict`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__getitem__(self, i) -> Dict[str, torch.Tensor]`
- `__init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer, data_args: DataArguments)`
- `__len__(self)`
- `_get_item(self, i) -> Dict[str, torch.Tensor]`
- `lengths(self)`
- `modality_lengths(self)`
- `process_image(self, image_file, overwrite_image_aspect_ratio)`

---

## Class: `LengthGroupedSampler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Sampler`

### å±æ€§ (Attributes)
- `batch_size`
- `generator`
- `group_by_modality`
- `group_by_modality_auto`
- `lengths`
- `variable_length`
- `world_size`

### æ–¹æ³• (Methods)
- `__init__(self, batch_size: int, world_size: int, lengths: Optional[List[int]], generator, variable_length: bool, group_by_modality: bool, group_by_modality_auto: bool)`
- `__iter__(self)`
- `__len__(self)`

---

## Class: `LengthSampler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `core`

### å±æ€§ (Attributes)
- `values`

### æ–¹æ³• (Methods)
- `__call__(self) -> int`
- `__init__(self, min_value: int, max_value: int)`

---

## Class: `LlamaAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attention_dropout`
- `config`
- `head_dim`
- `hidden_size`
- `is_causal`
- `k_proj`
- `layer_idx`
- `max_position_embeddings`
- `num_heads`
- `num_key_value_groups`
- `num_key_value_heads`
- `o_proj`
- `q_proj`
- `rope_theta`
- `v_proj`

### æ–¹æ³• (Methods)
- `__init__(self, config: LlamaConfig, layer_idx: Optional[int])`
- `_init_rope(self)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Cache], output_attentions: bool, use_cache: bool, cache_position: Optional[torch.LongTensor], **kwargs) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `LlamaDecoderLayer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `hidden_size`
- `input_layernorm`
- `mlp`
- `post_attention_layernorm`
- `self_attn`

### æ–¹æ³• (Methods)
- `__init__(self, config: LlamaConfig, layer_idx: int)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Tuple[torch.Tensor]], output_attentions: Optional[bool], use_cache: Optional[bool], cache_position: Optional[torch.LongTensor], **kwargs) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]`

---

## Class: `LlamaDynamicNTKScalingRotaryEmbedding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaRotaryEmbedding`

### æ–¹æ³• (Methods)
- `forward(self, x, position_ids, seq_len)`

---

## Class: `LlamaFlashAttention2`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaAttention`

### å±æ€§ (Attributes)
- `_flash_attn_uses_top_left_mask`

### æ–¹æ³• (Methods)
- `__init__(self, *args, **kwargs)`
- `_flash_attention_forward(self, query_states, key_states, value_states, attention_mask, query_length, dropout, softmax_scale)`
- `_upad_input(self, query_layer, key_layer, value_layer, attention_mask, query_length)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.LongTensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Cache], output_attentions: bool, use_cache: bool, cache_position: Optional[torch.LongTensor], **kwargs) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `LlamaForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaPreTrainedModel`

### å±æ€§ (Attributes)
- `_tied_weights_keys`
- `lm_head`
- `model`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `_reorder_cache(past_key_values, beam_idx)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool], cache_position: Optional[torch.LongTensor]) -> Union[Tuple, CausalLMOutputWithPast]`
- `get_decoder(self)`
- `get_input_embeddings(self)`
- `get_output_embeddings(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, attention_mask, inputs_embeds, **kwargs)`
- `set_decoder(self, decoder)`
- `set_input_embeddings(self, value)`
- `set_output_embeddings(self, new_embeddings)`

---

## Class: `LlamaForQuestionAnswering`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaPreTrainedModel`

### å±æ€§ (Attributes)
- `base_model_prefix`
- `qa_outputs`
- `transformer`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: Optional[torch.LongTensor], attention_mask: Optional[torch.FloatTensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], start_positions: Optional[torch.LongTensor], end_positions: Optional[torch.LongTensor], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, QuestionAnsweringModelOutput]`
- `get_input_embeddings(self)`
- `set_input_embeddings(self, value)`

---

## Class: `LlamaForSequenceClassification`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaPreTrainedModel`

### å±æ€§ (Attributes)
- `model`
- `num_labels`
- `score`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, SequenceClassifierOutputWithPast]`
- `get_input_embeddings(self)`
- `set_input_embeddings(self, value)`

---

## Class: `LlamaLinearScalingRotaryEmbedding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaRotaryEmbedding`

### æ–¹æ³• (Methods)
- `forward(self, x, position_ids, seq_len)`

---

## Class: `LlamaMLP`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `act_fn`
- `config`
- `down_proj`
- `gate_proj`
- `hidden_size`
- `intermediate_size`
- `up_proj`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, x)`

---

## Class: `LlamaModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaPreTrainedModel`

### å±æ€§ (Attributes)
- `embed_tokens`
- `gradient_checkpointing`
- `layers`
- `norm`
- `padding_idx`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, config: LlamaConfig)`
- `_update_causal_mask(self, attention_mask, input_tensor)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool], cache_position: Optional[torch.LongTensor]) -> Union[Tuple, BaseModelOutputWithPast]`
- `get_input_embeddings(self)`
- `set_input_embeddings(self, value)`

---

## Class: `LlamaPreTrainedModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModel`

### å±æ€§ (Attributes)
- `_no_split_modules`
- `_skip_keys_device_placement`
- `_supports_cache_class`
- `_supports_flash_attn_2`
- `_supports_sdpa`
- `base_model_prefix`
- `config_class`
- `supports_gradient_checkpointing`

### æ–¹æ³• (Methods)
- `_init_weights(self, module)`
- `_reset_cache(self)`
- `_setup_cache(self, cache_cls, max_batch_size, max_cache_len: Optional[int])`

---

## Class: `LlamaRMSNorm`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `variance_epsilon`
- `weight`

### æ–¹æ³• (Methods)
- `__init__(self, hidden_size, eps)`
- `forward(self, hidden_states)`

---

## Class: `LlamaRingFlashAttention2`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaAttention`

### å±æ€§ (Attributes)
- `_flash_attn_uses_top_left_mask`

### æ–¹æ³• (Methods)
- `__init__(self, *args, **kwargs)`
- `_flash_attention_forward(self, query_states, key_states, value_states, attention_mask, query_length, dropout, softmax_scale)`
- `_upad_input(self, query_layer, key_layer, value_layer, attention_mask, query_length)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.LongTensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Cache], output_attentions: bool, use_cache: bool, cache_position: Optional[torch.LongTensor], **kwargs) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `LlamaRotaryEmbedding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `base`
- `dim`
- `max_position_embeddings`
- `max_seq_len_cached`
- `scaling_factor`

### æ–¹æ³• (Methods)
- `__init__(self, dim, max_position_embeddings, base, device, scaling_factor)`
- `cos_cached(self)`
- `forward(self, x, position_ids, seq_len)`
- `sin_cached(self)`

---

## Class: `LlamaSdpaAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaAttention`

### æ–¹æ³• (Methods)
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_value: Optional[Cache], output_attentions: bool, use_cache: bool, cache_position: Optional[torch.LongTensor]) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `LlavaConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaConfig`

### å±æ€§ (Attributes)
- `do_sample: bool`
- `max_new_tokens: int`
- `model_type`
- `temperature: float`
- `top_p: Optional[float]`

---

## Class: `LlavaGemmaConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_gemma`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `GemmaConfig`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaGemmaForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_gemma`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `GemmaForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool], cache_position: Optional[torch.LongTensor]) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaGemmaModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_gemma`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `GemmaModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: GemmaConfig)`

---

## Class: `LlavaLlamaForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlamaForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool], modalities: Optional[List[str]], dpo_forward: Optional[bool], cache_position) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], modalities: Optional[List[str]], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaLlamaModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_llama`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `LlamaModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: LlamaConfig)`

---

## Class: `LlavaMetaForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_arch`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ABC`

### æ–¹æ³• (Methods)
- `add_token_per_frame(self, image_feature)`
- `add_token_per_grid(self, image_feature)`
- `encode_images(self, images)`
- `encode_multimodals(self, videos_or_images, video_idx_in_batch, split_sizes)`
- `get_2dPool(self, image_feature, stride)`
- `get_model(self)`
- `get_vision_tower(self)`
- `initialize_vision_tokenizer(self, model_args, tokenizer)`
- `prepare_inputs_labels_for_multimodal(self, input_ids, position_ids, attention_mask, past_key_values, labels, images, modalities, image_sizes)`

---

## Class: `LlavaMetaModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_arch`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `get_vision_tower(self)`
- `initialize_vision_modules(self, model_args, fsdp)`

---

## Class: `LlavaMistralConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mistral`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MistralConfig`

### å±æ€§ (Attributes)
- `do_sample: bool`
- `max_new_tokens: int`
- `model_type`
- `temperature: float`
- `top_p: Optional[float]`

---

## Class: `LlavaMistralForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mistral`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MistralForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool], cache_position) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaMistralModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mistral`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `MistralModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: MistralConfig)`

---

## Class: `LlavaMixtralConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mixtral`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MixtralConfig`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaMixtralForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mixtral`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MixtralForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool], modalities: Optional[List[str]], dpo_forward: Optional[bool], cache_position) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], modalities: Optional[List[str]], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaMixtralModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mixtral`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `MixtralModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: MixtralConfig)`

---

## Class: `LlavaMptConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mpt`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MptConfig`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaMptForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mpt`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MptForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `generation_config`
- `lm_head`
- `supports_gradient_checkpointing`
- `transformer`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `_set_gradient_checkpointing(self, module, value)`
- `forward(self, input_ids: Optional[torch.LongTensor], past_key_values: Optional[Tuple[Tuple[torch.Tensor, torch.Tensor], ...]], attention_mask: Optional[torch.Tensor], inputs_embeds: Optional[torch.Tensor], labels: Optional[torch.Tensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool], cache_position, images)`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaMptModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_mpt`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `MptModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: MptConfig)`
- `embed_tokens(self, x)`

---

## Class: `LlavaQwenConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_qwen`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Qwen2Config`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaQwenForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_qwen`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Qwen2ForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool], modalities: Optional[List[str]], dpo_forward: Optional[bool], cache_position) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], modalities: Optional[List[str]], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaQwenModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_qwen`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `Qwen2Model`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: Qwen2Config)`

---

## Class: `LlavaQwenMoeConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_qwen_moe`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Qwen2MoeConfig`

### å±æ€§ (Attributes)
- `model_type`

---

## Class: `LlavaQwenMoeForCausalLM`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_qwen_moe`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Qwen2MoeForCausalLM`, `LlavaMetaForCausalLM`

### å±æ€§ (Attributes)
- `config_class`
- `lm_head`
- `model`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, input_ids: torch.LongTensor, attention_mask: Optional[torch.Tensor], position_ids: Optional[torch.LongTensor], past_key_values: Optional[List[torch.FloatTensor]], inputs_embeds: Optional[torch.FloatTensor], labels: Optional[torch.LongTensor], use_cache: Optional[bool], output_attentions: Optional[bool], output_hidden_states: Optional[bool], images: Optional[torch.FloatTensor], image_sizes: Optional[List[List[int]]], return_dict: Optional[bool], modalities: Optional[List[str]], dpo_forward: Optional[bool], cache_position) -> Union[Tuple, CausalLMOutputWithPast]`
- `generate(self, inputs: Optional[torch.Tensor], images: Optional[torch.Tensor], image_sizes: Optional[torch.Tensor], modalities: Optional[List[str]], **kwargs) -> Union[GenerateOutput, torch.LongTensor]`
- `get_model(self)`
- `prepare_inputs_for_generation(self, input_ids, past_key_values, inputs_embeds, **kwargs)`

---

## Class: `LlavaQwenMoeModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `llava_qwen_moe`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `LlavaMetaModel`, `Qwen2MoeModel`

### å±æ€§ (Attributes)
- `config_class`

### æ–¹æ³• (Methods)
- `__init__(self, config: Qwen2MoeConfig)`

---

## Class: `MLCDEncoder`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `gradient_checkpointing`
- `layers`

### æ–¹æ³• (Methods)
- `__init__(self, config: MLCDVisionConfig)`
- `forward(self, inputs_embeds, rotary_pos_emb, output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, BaseModelOutput]`

---

## Class: `MLCDEncoderLayer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `embed_dim`
- `layer_norm1`
- `layer_norm2`
- `mlp`
- `self_attn`

### æ–¹æ³• (Methods)
- `__init__(self, config: MLCDVisionConfig)`
- `forward(self, hidden_states: torch.Tensor, rotary_pos_emb: torch.Tensor) -> Tuple[torch.FloatTensor]`

---

## Class: `MLCDMLP`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `CLIPMLP`

### æ–¹æ³• (Methods)
- `__init__(self, config: MLCDVisionConfig)`

---

## Class: `MLCDPreTrainedModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModel`

### å±æ€§ (Attributes)
- `_supports_sdpa`
- `base_model_prefix`
- `config_class`
- `supports_gradient_checkpointing`

### æ–¹æ³• (Methods)
- `_init_weights(self, module)`

---

## Class: `MLCDSdpaAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.nn.Module`

### å±æ€§ (Attributes)
- `config`
- `dropout`
- `embed_dim`
- `head_dim`
- `k_proj`
- `num_heads`
- `out_proj`
- `q_proj`
- `scale`
- `v_proj`

### æ–¹æ³• (Methods)
- `__init__(self, config: MLCDVisionConfig)`
- `forward(self, hidden_states: torch.Tensor, rotary_pos_emb: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor]]`

---

## Class: `MLCDVisionConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `CLIPVisionConfig`

### å±æ€§ (Attributes)
- `model_type`

### æ–¹æ³• (Methods)
- `__init__(self, **kwargs)`

---

## Class: `MLCDVisionEmbeddings`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `torch.nn.Module`

### å±æ€§ (Attributes)
- `class_embedding`
- `config`
- `embed_dim`
- `image_size`
- `num_patches`
- `num_positions`
- `patch_embedding`
- `patch_size`

### æ–¹æ³• (Methods)
- `__init__(self, config: MLCDVisionConfig)`
- `forward(self, pixel_values: torch.FloatTensor) -> torch.Tensor`

---

## Class: `MLCDVisionModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MLCDPreTrainedModel`

### å±æ€§ (Attributes)
- `_no_split_modules`
- `config_class`
- `main_input_name`
- `vision_model`

### æ–¹æ³• (Methods)
- `__init__(self, config: MLCDVisionConfig)`
- `forward(self, pixel_values: Optional[torch.FloatTensor], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, BaseModelOutputWithPooling]`
- `get_input_embeddings(self) -> nn.Module`

---

## Class: `MLCDVisionTower`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mlcd_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `is_loaded`
- `select_feature`
- `select_layer`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `config(self)`
- `device(self)`
- `dtype(self)`
- `dummy_feature(self)`
- `feature_select(self, image_forward_outs)`
- `forward(self, images)`
- `hidden_size(self)`
- `image_size(self)`
- `load_model(self, device_map)`
- `num_patches(self)`
- `num_patches_per_side(self)`

---

## Class: `MLCDVisionTowerS2`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `mlcd_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `MLCDVisionTower`

### å±æ€§ (Attributes)
- `s2_image_size`
- `s2_scales`
- `s2_split_size`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `forward(self, images)`
- `forward_feature(self, images)`
- `hidden_size(self)`
- `load_model(self, device_map)`

---

## Class: `MLCDVisionTransformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `vit_rope2d_hf`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `class_pos_emb`
- `config`
- `embeddings`
- `encoder`
- `post_layernorm`
- `pre_layrnorm`
- `vision_rotary_embedding`

### æ–¹æ³• (Methods)
- `__init__(self, config: MLCDVisionConfig)`
- `forward(self, pixel_values: Optional[torch.FloatTensor], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, BaseModelOutputWithPooling]`
- `rot_pos_emb(self, grid_thw)`

---

## Class: `MaskedDrop`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `masked_drop`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `mode`
- `ratio`
- `ratio_lower`
- `ratio_upper`
- `skip_percentage`

### æ–¹æ³• (Methods)
- `__init__(self, model_args)`
- `config(self)`
- `forward(self, image_features, *args, **kwargs)`
- `random_masking(self, x, len_keep)`

---

## Class: `MaxPooler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### æ–¹æ³• (Methods)
- `forward(self, x: BaseModelOutput, attention_mask: TensorType)`

---

## Class: `MeanPooler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### æ–¹æ³• (Methods)
- `forward(self, x: BaseModelOutput, attention_mask: TensorType)`

---

## Class: `Mlp`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `act`
- `drop`
- `fc1`
- `fc2`
- `ffn_ln`

### æ–¹æ³• (Methods)
- `__init__(self, in_features, hidden_features, out_features, act_layer, norm_layer, drop, subln)`
- `forward(self, x)`

---

## Class: `ModelArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### å±æ€§ (Attributes)
- `add_faster_video: Optional[bool]`
- `delay_load: Optional[bool]`
- `faster_token_stride: Optional[int]`
- `freeze_backbone: bool`
- `mm_mask_drop_mode: str`
- `mm_mask_drop_ratio: float`
- `mm_mask_drop_ratio_lower: Optional[float]`
- `mm_mask_drop_ratio_upper: Optional[float]`
- `mm_mask_drop_skip_percentage: float`
- `mm_newline_position: Optional[str]`
- `mm_patch_merge_type: Optional[str]`
- `mm_perceiver_depth: Optional[int]`
- `mm_perceiver_ff_mult: Optional[float]`
- `mm_perceiver_latents: Optional[int]`
- `mm_perceiver_pretrained: Optional[str]`
- `mm_projector_type: Optional[str]`
- `mm_qformer_depth: Optional[int]`
- `mm_qformer_latents: Optional[int]`
- `mm_qformer_pretrained: Optional[str]`
- `mm_resampler_type: Optional[str]`
- `mm_spatial_pool_mode: str`
- `mm_spatial_pool_out_channels: Optional[int]`
- `mm_spatial_pool_stride: Optional[int]`
- `mm_tunable_parts: Optional[str]`
- `mm_use_im_patch_token: bool`
- `mm_use_im_start_end: bool`
- `mm_vision_select_feature: Optional[str]`
- `mm_vision_select_layer: Optional[int]`
- `model_class_name: Optional[str]`
- `model_name_or_path: Optional[str]`
- `pos_skipping_range: Optional[int]`
- `pretrain_mm_mlp_adapter: Optional[str]`
- `rope_scaling_factor: Optional[float]`
- `rope_scaling_type: Optional[str]`
- `s2: Optional[bool]`
- `s2_scales: Optional[str]`
- `tune_mm_mlp_adapter: bool`
- `tune_mm_vision_resampler: bool`
- `unfreeze_language_model: bool`
- `unfreeze_mm_vision_tower: bool`
- `use_pos_skipping: Optional[bool]`
- `version: Optional[str]`
- `vision_tower: Optional[str]`
- `vision_tower_pretrained: Optional[str]`

---

## Class: `ModelConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_config`

### å±æ€§ (Attributes)
- `attn_implementation: Optional[str]`
- `bnb_4bit_quant_type: Optional[str]`
- `load_in_4bit: bool`
- `load_in_8bit: bool`
- `lora_alpha: Optional[int]`
- `lora_dropout: Optional[float]`
- `lora_modules_to_save: Optional[List[str]]`
- `lora_r: Optional[int]`
- `lora_target_modules: Optional[List[str]]`
- `model_name_or_path: Optional[str]`
- `model_revision: str`
- `torch_dtype: Optional[str]`
- `trust_remote_code: bool`
- `use_bnb_nested_quant: bool`
- `use_peft: bool`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `to_dict(self)`

---

## Class: `ModelWorker`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model_worker`

### å±æ€§ (Attributes)
- `controller_addr`
- `is_multimodal`
- `worker_addr`
- `worker_id`

### æ–¹æ³• (Methods)
- `__init__(self, controller_addr, worker_addr, sgl_endpoint, worker_id, no_register, model_name)`
- `__init__(self, controller_addr, worker_addr, worker_id, no_register, model_path, model_base, model_name, load_8bit, load_4bit)`
- `generate_stream(self, params)`
- `generate_stream_gate(self, params)`
- `get_queue_length(self)`
- `get_status(self)`
- `register_to_controller(self)`
- `send_heart_beat(self)`

---

## Class: `ModifiedResNet`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modified_resnet`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `_inplanes`
- `act1`
- `act2`
- `act3`
- `attnpool`
- `avgpool`
- `bn1`
- `bn2`
- `bn3`
- `conv1`
- `conv2`
- `conv3`
- `image_size`
- `layer1`
- `layer2`
- `layer3`
- `layer4`
- `output_dim`

### æ–¹æ³• (Methods)
- `__init__(self, layers, output_dim, heads, image_size, width)`
- `_make_layer(self, planes, blocks, stride)`
- `forward(self, x)`
- `init_parameters(self)`
- `lock(self, unlocked_groups, freeze_bn_stats)`
- `set_grad_checkpointing(self, enable)`
- `stem(self, x)`

---

## Class: `OpenCLIPVisionTower`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `open_clip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `is_loaded`
- `model_name`
- `pretrained`
- `select_feature`
- `select_layer`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, args, delay_load)`
- `config(self)`
- `device(self)`
- `dtype(self)`
- `dummy_feature(self)`
- `feature_select(self, image_forward_outs)`
- `forward(self, images)`
- `forward_visual(self, x, output_hidden_states)`
- `hidden_size(self)`
- `image_size(self)`
- `load_model(self, device_map)`
- `num_patches(self)`
- `num_patches_per_side(self)`

---

## Class: `PPOConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `ppo_config`

### å±æ€§ (Attributes)
- `accelerator_kwargs: JSONDict`
- `adap_kl_ctrl: bool`
- `backward_batch_size: tyro.conf.Suppress[int]`
- `batch_size: int`
- `cliprange: float`
- `cliprange_value: float`
- `compare_steps: int`
- `early_stopping: bool`
- `exp_name: str`
- `forward_batch_size: Optional[int]`
- `gamma: float`
- `global_backward_batch_size: tyro.conf.Suppress[int]`
- `global_batch_size: tyro.conf.Suppress[int]`
- `gradient_accumulation_steps: int`
- `horizon: Optional[float]`
- `init_kl_coef: Optional[float]`
- `is_encoder_decoder: Optional[tyro.conf.Suppress[bool]]`
- `is_peft_model: Optional[tyro.conf.Suppress[bool]]`
- `kl_penalty: Literal['kl', 'abs', 'mse', 'full']`
- `lam: float`
- `learning_rate: float`
- `log_with: Optional[Literal['wandb', 'tensorboard']]`
- `max_grad_norm: Optional[float]`
- `mini_batch_size: int`
- `model_name: Optional[str]`
- `optimize_cuda_cache: Optional[bool]`
- `optimize_device_cache: Optional[bool]`
- `ppo_epochs: int`
- `project_kwargs: JSONDict`
- `push_to_hub_if_best_kwargs: JSONDict`
- `query_dataset: Optional[str]`
- `ratio_threshold: float`
- `remove_unused_columns: bool`
- `reward_model: Optional[str]`
- `score_clip: Optional[float]`
- `seed: int`
- `steps: int`
- `target: Optional[float]`
- `target_kl: float`
- `task_name: Optional[str]`
- `tracker_kwargs: JSONDict`
- `tracker_project_name: str`
- `use_score_norm: bool`
- `use_score_scaling: bool`
- `vf_coef: float`
- `whiten_rewards: bool`
- `world_size: tyro.conf.Suppress[int]`

### æ–¹æ³• (Methods)
- `__post_init__(self)`
- `to_dict(self)`

---

## Class: `PPODecorators`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `core`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `optimize_device_cache`

### æ–¹æ³• (Methods)
- `empty_device_cache(cls)`

---

## Class: `PPOTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `ppo_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BaseTrainer`

### å±æ€§ (Attributes)
- `_signature_columns`
- `_tag_names`
- `accelerator`
- `current_step`
- `data_collator`
- `dataset`
- `is_distributed`
- `is_encoder_decoder`
- `is_peft_model`
- `is_using_text_environment`
- `lr_scheduler`
- `model`
- `model_params`
- `optional_peft_ctx`
- `running`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, config: PPOConfig, model: PreTrainedModelWrapper, ref_model: Optional[PreTrainedModelWrapper], tokenizer: PreTrainedTokenizerBase, dataset: Optional[Union[torch.utils.data.Dataset, Dataset]], optimizer: Optional[torch.optim.Optimizer], data_collator: Optional[typing.Callable], num_shared_layers: Optional[int], lr_scheduler: Optional[torch.optim.lr_scheduler._LRScheduler])`
- `_early_stop(self, policykl)`
- `_filter_kwargs(self, kwargs, target_func)`
- `_generate_batched(self, model: PreTrainedModelWrapper, query_tensors: List[torch.Tensor], length_sampler: Callable, batch_size: int, return_prompt: bool, pad_to_multiple_of: int, remove_padding: bool, **generation_kwargs)`
- `_kl_penalty(self, logprob: torch.FloatTensor, ref_logprob: torch.FloatTensor) -> torch.FloatTensor`
- `_prepare_deepspeed(self, model: PreTrainedModelWrapper)`
- `_remove_unused_columns(self, dataset: 'Dataset')`
- `_save_pretrained(self, save_directory: str) -> None`
- `_set_signature_columns_if_needed(self)`
- `_show_tokens(self, tokens, masks)`
- `_step_safety_checker(self, batch_size: int, queries: List[torch.LongTensor], responses: List[torch.LongTensor], scores: List[torch.FloatTensor], masks: Optional[List[torch.LongTensor]])`
- `batched_forward_pass(self, model: PreTrainedModelWrapper, queries: torch.Tensor, responses: torch.Tensor, model_inputs: dict, return_logits: bool, response_masks: Optional[torch.Tensor])`
- `compute_advantages(self, values: torch.FloatTensor, rewards: torch.FloatTensor, mask: torch.FloatTensor)`
- `compute_rewards(self, scores: torch.FloatTensor, logprobs: torch.FloatTensor, ref_logprobs: torch.FloatTensor, masks: torch.LongTensor)`
- `create_model_card(self, path: str, model_name: Optional[str]) -> None`
- `gather_stats(self, stats)`
- `generate(self, query_tensor: Union[torch.Tensor, List[torch.Tensor]], length_sampler: Callable, batch_size: int, return_prompt: bool, generate_ref_response: bool, **generation_kwargs)`
- `log_stats(self, stats: dict, batch: dict, rewards: List[torch.FloatTensor], columns_to_log: List[str])`
- `loss(self, old_logprobs: torch.FloatTensor, values: torch.FloatTensor, logits: torch.FloatTensor, vpreds: torch.FloatTensor, logprobs: torch.FloatTensor, mask: torch.LongTensor, advantages: torch.FloatTensor, returns: torch.FloatTensor)`
- `prepare_dataloader(self, dataset: Union[torch.utils.data.Dataset, Dataset], data_collator)`
- `prepare_model_inputs(self, queries: torch.Tensor, responses: torch.Tensor)`
- `record_step_stats(self, kl_coef: float, **data)`
- `step(self, queries: List[torch.LongTensor], responses: List[torch.LongTensor], scores: List[torch.FloatTensor], response_masks: Optional[List[torch.LongTensor]])`
- `train_minibatch(self, old_logprobs: torch.FloatTensor, values: torch.FloatTensor, logprobs: torch.FloatTensor, logits: torch.FloatTensor, vpreds: torch.FloatTensor, mask: torch.LongTensor, advantages: torch.FloatTensor, returns: torch.FloatTensor)`

---

## Class: `PatchDropout`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `exclude_first_token`
- `prob`

### æ–¹æ³• (Methods)
- `__init__(self, prob, exclude_first_token)`
- `forward(self, x)`

---

## Class: `PatchEmbed`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `img_size`
- `num_patches`
- `patch_shape`
- `patch_size`
- `proj`

### æ–¹æ³• (Methods)
- `__init__(self, img_size, patch_size, in_chans, embed_dim)`
- `forward(self, x, **kwargs)`

---

## Class: `PerPromptStatTracker`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### å±æ€§ (Attributes)
- `buffer_size`
- `min_count`
- `stats`

### æ–¹æ³• (Methods)
- `__init__(self, buffer_size, min_count)`
- `get_stats(self)`
- `update(self, prompts, rewards)`

---

## Class: `PerceiverAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `perceiver`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `heads`
- `norm_latents`
- `norm_media`
- `scale`
- `to_kv`
- `to_out`
- `to_q`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `forward(self, x, latents)`

---

## Class: `PerceiverResampler`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `perceiver`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `depth`
- `ff_mult`
- `num_latents`
- `perceiver`
- `pretrained`

### æ–¹æ³• (Methods)
- `__init__(self, model_args, vision_tower)`
- `config(self)`
- `forward(self, image_features, *args, **kwargs)`

---

## Class: `PerceiverResamplerModule`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `perceiver`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `frame_embs`
- `latents`
- `layers`
- `media_time_embs`
- `norm`

### æ–¹æ³• (Methods)
- `__init__(self)`
- `forward(self, x)`

---

## Class: `PoolerProjector`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `pooler_projector`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `_config`
- `conv_pool`
- `hw`
- `proj`

### æ–¹æ³• (Methods)
- `__init__(self, config, vision_cfg)`
- `config(self)`
- `forward(self, x, *args, **kwargs)`

---

## Class: `PreTrainedModelWrapper`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_base`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `is_loaded_in_4bit`
- `is_loaded_in_8bit`
- `is_sequential_parallel`
- `policy_adapter_name`
- `prepare_inputs_for_generation`
- `pretrained_model`
- `rm_adapter_name`
- `supported_args`
- `supported_modules`
- `supported_pretrained_model_architectures`
- `supported_rm_modules`
- `supports_rm_adapter`
- `transformers_parent_class`

### æ–¹æ³• (Methods)
- `__init__(self, pretrained_model, score_module, supports_rm_adapter, rm_adapter_name, **kwargs)`
- `_get_checkpoint_from_hub(cls, pretrained_model, pretrained_model_name_or_path, index_filename, token, model_name, model_index_name)`
- `_get_current_device(cls)`
- `_split_kwargs(cls, kwargs)`
- `add_and_load_reward_modeling_adapter(cls, pretrained_model, adapter_model_id, adapter_name, token)`
- `compute_reward_score(self, input_ids, attention_mask, **kwargs)`
- `from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)`
- `post_init(self, *args, **kwargs)`
- `push_to_hub(self, *args, **kwargs)`
- `save_pretrained(self, *args, **kwargs)`
- `state_dict(self, *args, **kwargs)`

---

## Class: `Predictor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `predict`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `BasePredictor`

### æ–¹æ³• (Methods)
- `predict(self, image: Path, prompt: str, top_p: float, temperature: float, max_tokens: int) -> ConcatenateIterator[str]`
- `setup(self) -> None`

---

## Class: `PretrainedConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `hf_model`

---

## Class: `Qformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `qformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `depth`
- `num_latents`
- `pretrained`

### æ–¹æ³• (Methods)
- `__init__(self, model_args, vision_tower)`
- `build_Qformer(self, vision_width, cross_attention_freq, num_query_token)`
- `config(self)`
- `forward(self, image_features, *args, **kwargs)`
- `hidden_size(self)`

---

## Class: `QuickGELU`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### æ–¹æ³• (Methods)
- `forward(self, x: torch.Tensor)`

---

## Class: `RMSnorm`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `variance_epsilon`
- `weight`

### æ–¹æ³• (Methods)
- `__init__(self, hidden_size, eps)`
- `forward(self, hidden_states)`

---

## Class: `RelativePositionBias`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `num_relative_distance`
- `relative_position_bias_table`
- `window_size`

### æ–¹æ³• (Methods)
- `__init__(self, window_size, num_heads)`
- `forward(self)`

---

## Class: `ResidualAttentionBlock`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `ln_1`
- `ln_2`
- `ls_1`
- `ls_2`
- `mlp`
- `xattn`

### æ–¹æ³• (Methods)
- `__init__(self, d_model: int, n_head: int, mlp_ratio: float, ls_init_value: float, act_layer: Callable, norm_layer: Callable, xattn: bool)`
- `attention(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor])`
- `forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor])`

---

## Class: `ResizeMaxSize`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transform`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `fill`
- `fn`
- `interpolation`
- `max_size`

### æ–¹æ³• (Methods)
- `__init__(self, max_size, interpolation, fn, fill)`
- `forward(self, img)`

---

## Class: `RewardConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `reward_config`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `TrainingArguments`

### å±æ€§ (Attributes)
- `max_length: Optional[int]`

---

## Class: `RewardDataCollatorWithPadding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### å±æ€§ (Attributes)
- `max_length: Optional[int]`
- `pad_to_multiple_of: Optional[int]`
- `padding: Union[bool, str]`
- `return_tensors: str`
- `tokenizer: PreTrainedTokenizerBase`

### æ–¹æ³• (Methods)
- `__call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]`

---

## Class: `RewardTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `reward_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### æ–¹æ³• (Methods)
- `__init__(self, model: Union[PreTrainedModel, nn.Module], args: Optional[RewardConfig], data_collator: Optional[DataCollator], train_dataset: Optional[Dataset], eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]], tokenizer: Optional[PreTrainedTokenizerBase], model_init: Optional[Callable[[], PreTrainedModel]], compute_metrics: Optional[Callable[[EvalPrediction], Dict]], callbacks: Optional[List[TrainerCallback]], optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR], preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]], max_length: Optional[int], peft_config: Optional[Dict])`
- `compute_loss(self, model: Union[PreTrainedModel, nn.Module], inputs: Dict[str, Union[torch.Tensor, Any]], return_outputs) -> Union[torch.Tensor, Tuple[torch.Tensor, Dict[str, torch.Tensor]]]`
- `prediction_step(self, model: Union[PreTrainedModel, nn.Module], inputs: Dict[str, Union[torch.Tensor, Any]], prediction_loss_only: bool, ignore_keys: Optional[List[str]]) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]`

---

## Class: `RunningMoments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### å±æ€§ (Attributes)
- `accelerator`
- `count`
- `mean`
- `std`
- `var`

### æ–¹æ³• (Methods)
- `__init__(self, accelerator)`
- `update(self, xs: torch.Tensor) -> Tuple[float, float]`

---

## Class: `SFTTrainer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `sft_trainer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Trainer`

### å±æ€§ (Attributes)
- `_tag_names`
- `_trainer_supports_neftune`
- `dataset_batch_size`
- `dataset_num_proc`

### æ–¹æ³• (Methods)
- `__init__(self, model: Union[PreTrainedModel, nn.Module, str], args: TrainingArguments, data_collator: Optional[DataCollator], train_dataset: Optional[Dataset], eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]], tokenizer: Optional[PreTrainedTokenizerBase], model_init: Optional[Callable[[], PreTrainedModel]], compute_metrics: Optional[Callable[[EvalPrediction], Dict]], callbacks: Optional[List[TrainerCallback]], optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR], preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]], peft_config: Optional['PeftConfig'], dataset_text_field: Optional[str], packing: Optional[bool], formatting_func: Optional[Callable], max_seq_length: Optional[int], infinite: Optional[bool], num_of_sequences: Optional[int], chars_per_token: Optional[float], dataset_num_proc: Optional[int], dataset_batch_size: int, neftune_noise_alpha: Optional[float], model_init_kwargs: Optional[Dict], dataset_kwargs: Optional[Dict])`
- `_prepare_dataset(self, dataset, tokenizer, packing, dataset_text_field, max_seq_length, formatting_func, num_of_sequences, chars_per_token, remove_unused_columns, append_concat_token, add_special_tokens)`
- `_prepare_non_packed_dataloader(self, tokenizer, dataset, dataset_text_field, max_seq_length, formatting_func, add_special_tokens, remove_unused_columns)`
- `_prepare_packed_dataloader(self, tokenizer, dataset, dataset_text_field, max_seq_length, num_of_sequences, chars_per_token, formatting_func, append_concat_token, add_special_tokens)`
- `_trl_activate_neftune(self, model)`
- `push_to_hub(self, commit_message: Optional[str], blocking: bool, **kwargs) -> str`
- `train(self, *args, **kwargs)`

---

## Class: `SeparatorStyle`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `conversation`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `Enum`

### å±æ€§ (Attributes)
- `CHATML`
- `GEMMA`
- `LLAMA_2`
- `LLAMA_3`
- `MPT`
- `PLAIN`
- `QWEN`
- `SINGLE`
- `TWO`

---

## Class: `SigLipAttention`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `dropout`
- `embed_dim`
- `head_dim`
- `k_proj`
- `num_heads`
- `out_proj`
- `q_proj`
- `scale`
- `v_proj`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor], output_attentions: Optional[bool]) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]`

---

## Class: `SigLipEncoder`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `gradient_checkpointing`
- `layers`

### æ–¹æ³• (Methods)
- `__init__(self, config: SigLipVisionConfig)`
- `forward(self, inputs_embeds, attention_mask: Optional[torch.Tensor], output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, BaseModelOutput]`

---

## Class: `SigLipEncoderLayer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `embed_dim`
- `layer_norm1`
- `layer_norm2`
- `mlp`
- `self_attn`

### æ–¹æ³• (Methods)
- `__init__(self, config: SigLipVisionConfig)`
- `forward(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor, output_attentions: Optional[bool]) -> Tuple[torch.FloatTensor]`

---

## Class: `SigLipImageProcessor`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### å±æ€§ (Attributes)
- `crop_size`
- `data_format`
- `image_mean`
- `image_std`
- `resample`
- `rescale_factor`
- `size`

### æ–¹æ³• (Methods)
- `__init__(self, image_mean, image_std, size, crop_size: Dict[str, int], resample, rescale_factor, data_format)`
- `preprocess(self, images, return_tensors)`

---

## Class: `SigLipMLP`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `activation_fn`
- `config`
- `fc1`
- `fc2`

### æ–¹æ³• (Methods)
- `__init__(self, config)`
- `forward(self, hidden_states: torch.Tensor) -> torch.Tensor`

---

## Class: `SigLipMultiheadAttentionPoolingHead`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `attention`
- `layernorm`
- `mlp`
- `probe`

### æ–¹æ³• (Methods)
- `__init__(self, config: SigLipVisionConfig)`
- `forward(self, hidden_state)`

---

## Class: `SigLipPreTrainedModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PreTrainedModel`

### å±æ€§ (Attributes)
- `base_model_prefix`
- `config_class`
- `supports_gradient_checkpointing`

### æ–¹æ³• (Methods)
- `_init_weights(self, module)`

---

## Class: `SigLipVisionConfig`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `PretrainedConfig`

### å±æ€§ (Attributes)
- `attention_dropout`
- `hidden_act`
- `hidden_size`
- `image_mean`
- `image_size`
- `intermediate_size`
- `layer_norm_eps`
- `model_type`
- `num_attention_heads`
- `num_channels`
- `num_hidden_layers`
- `patch_size`

### æ–¹æ³• (Methods)
- `__init__(self, hidden_size, image_mean, intermediate_size, num_hidden_layers, num_attention_heads, num_channels, image_size, patch_size, hidden_act, layer_norm_eps, attention_dropout, **kwargs)`
- `from_pretrained(cls, pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs) -> 'PretrainedConfig'`

---

## Class: `SigLipVisionEmbeddings`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `embed_dim`
- `image_size`
- `num_patches`
- `num_positions`
- `patch_embedding`
- `patch_size`
- `position_embedding`

### æ–¹æ³• (Methods)
- `__init__(self, config: SigLipVisionConfig)`
- `forward(self, pixel_values: torch.FloatTensor) -> torch.Tensor`

---

## Class: `SigLipVisionModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `SigLipPreTrainedModel`

### å±æ€§ (Attributes)
- `_no_split_modules`
- `config_class`
- `main_input_name`
- `vision_model`

### æ–¹æ³• (Methods)
- `__init__(self, config: SigLipVisionConfig)`
- `forward(self, pixel_values, output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, BaseModelOutputWithPooling]`
- `get_input_embeddings(self) -> nn.Module`

---

## Class: `SigLipVisionModelOutput`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `ModelOutput`

### å±æ€§ (Attributes)
- `attentions: Optional[Tuple[torch.FloatTensor]]`
- `hidden_states: Optional[Tuple[torch.FloatTensor]]`
- `image_embeds: Optional[torch.FloatTensor]`
- `last_hidden_state: torch.FloatTensor`

---

## Class: `SigLipVisionTower`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `image_processor`
- `is_loaded`
- `vision_tower_name`

### æ–¹æ³• (Methods)
- `__init__(self, vision_tower, vision_tower_cfg, delay_load)`
- `device(self)`
- `dtype(self)`
- `dummy_feature(self)`
- `forward(self, images)`
- `hidden_size(self)`
- `image_size(self)`
- `load_model(self, device_map)`
- `num_patches(self)`
- `num_patches_per_side(self)`

---

## Class: `SigLipVisionTransformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `siglip_encoder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `config`
- `embeddings`
- `encoder`
- `head`
- `post_layernorm`

### æ–¹æ³• (Methods)
- `__init__(self, config: SigLipVisionConfig)`
- `forward(self, pixel_values, output_attentions: Optional[bool], output_hidden_states: Optional[bool], return_dict: Optional[bool]) -> Union[Tuple, BaseModelOutputWithPooling]`

---

## Class: `SimpleResBlock`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `builder`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `pre_norm`
- `proj`

### æ–¹æ³• (Methods)
- `__init__(self, channels)`
- `forward(self, x)`

---

## Class: `SimpleTokenizer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `tokenizer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `all_special_ids`
- `bpe_ranks`
- `byte_decoder`
- `byte_encoder`
- `cache`
- `decoder`
- `encoder`
- `pat`
- `vocab_size`

### æ–¹æ³• (Methods)
- `__init__(self, bpe_path: str, special_tokens)`
- `bpe(self, token)`
- `decode(self, tokens)`
- `encode(self, text)`

---

## Class: `SpatialPool`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `spatial_pool`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `mode`
- `out_channels`
- `stride`

### æ–¹æ³• (Methods)
- `__init__(self, model_args, vision_tower)`
- `config(self)`
- `forward(self, image_features, images, *args, **kwargs)`
- `hidden_size(self)`

---

## Class: `StreamToLogger`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `utils`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `object`

### å±æ€§ (Attributes)
- `linebuf`
- `log_level`
- `logger`
- `terminal`

### æ–¹æ³• (Methods)
- `__getattr__(self, attr)`
- `__init__(self, logger, log_level)`
- `flush(self)`
- `write(self, buf)`

---

## Class: `StringStoppingCriteria`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `base_environment`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `StoppingCriteria`

### å±æ€§ (Attributes)
- `first_call`
- `stop_strings`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__call__(self, input_ids, scores, **kwargs)`
- `__init__(self, stop_strings, tokenizer)`

---

## Class: `SwiGLU`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `eva_vit_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `act`
- `drop`
- `ffn_ln`
- `w1`
- `w2`
- `w3`

### æ–¹æ³• (Methods)
- `__init__(self, in_features, hidden_features, out_features, act_layer, drop, norm_layer, subln)`
- `forward(self, x)`

---

## Class: `TextEnvironment`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `base_environment`

### å±æ€§ (Attributes)
- `call_token`
- `current_device`
- `is_encoder_decoder`
- `max_length`
- `max_tool_response`
- `max_turns`
- `model`
- `prompt`
- `request_token`
- `response_token`
- `reward_fn`
- `submit_token`
- `tokenizer`

### æ–¹æ³• (Methods)
- `__init__(self, model, tokenizer, tools, reward_fn, prompt, max_turns, max_tool_reponse, max_length, generation_kwargs)`
- `_generate_batched(self, query_tensors, batch_size: int, pad_to_multiple_of: int)`
- `compute_reward(self, histories, **reward_kwargs)`
- `generate(self, histories)`
- `parse_tool_call(self, text)`
- `run(self, queries, **rewards_kwargs)`
- `step(self, history)`
- `task_end_check(self, history, model_turn)`
- `tasks_end_check(self, histories, model_turn)`

---

## Class: `TextHistory`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `base_environment`

### å±æ€§ (Attributes)
- `completed`
- `model_color`
- `prompt_color`
- `reward`
- `reward_color`
- `system_color`
- `system_spans`
- `text`
- `text_spans`
- `token_masks`
- `token_spans`
- `tokens`
- `truncated`

### æ–¹æ³• (Methods)
- `__init__(self, text, tokens, system)`
- `append_segment(self, text, tokens, system)`
- `complete(self, truncated)`
- `last_text_segment(self)`
- `show_colour_legend(self)`
- `show_text(self, show_legend)`
- `show_tokens(self, tokenizer, show_legend)`
- `split_query_response_tokens(self)`

---

## Class: `TextTransformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `context_length`
- `ln_final`
- `output_dim`
- `positional_embedding`
- `text_projection`
- `token_embedding`
- `transformer`
- `vocab_size`
- `width`
- `xattn`

### æ–¹æ³• (Methods)
- `__init__(self, context_length: int, vocab_size: int, width: int, heads: int, layers: int, ls_init_value: float, output_dim: int, act_layer: Callable, norm_layer: Callable, xattn: bool, attn_mask: bool)`
- `build_attention_mask(self)`
- `forward(self, text, return_all_features: bool)`
- `get_num_layers(self)`
- `init_parameters(self)`
- `no_weight_decay(self)`
- `set_grad_checkpointing(self, enable)`

---

## Class: `TimmModel`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `timm_model`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `head`
- `image_size`
- `trunk`

### æ–¹æ³• (Methods)
- `__init__(self, model_name, embed_dim, image_size, pool, proj, proj_bias, drop, pretrained)`
- `forward(self, x)`
- `lock(self, unlocked_groups, freeze_bn_stats)`
- `set_grad_checkpointing(self, enable)`

---

## Class: `TrainingArguments`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `train`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `transformers.TrainingArguments`, `transformers.TrainingArguments`

### å±æ€§ (Attributes)
- `attn_implementation: str`
- `auto_find_batch_size: bool`
- `beta: float`
- `bits: int`
- `cache_dir: Optional[str]`
- `double_quant: bool`
- `dpo_alpha: float`
- `freeze_mm_mlp_adapter: bool`
- `freeze_mm_vision_resampler: bool`
- `gamma: float`
- `generate_during_eval: bool`
- `gradient_checkpointing: bool`
- `group_by_modality_length: bool`
- `group_by_modality_length_auto: bool`
- `group_by_varlen: bool`
- `lora_alpha: int`
- `lora_bias: str`
- `lora_dropout: float`
- `lora_enable: bool`
- `lora_r: int`
- `lora_weight_path: str`
- `mm_projector_lr: Optional[float]`
- `mm_vision_tower_lr: Optional[float]`
- `model_max_length: int`
- `mpt_attn_impl: Optional[str]`
- `optim: str`
- `precompute_ref_log_probs: bool`
- `quant_type: str`
- `remove_unused_columns: bool`
- `verbose_logging: bool`

---

## Class: `Transformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `grad_checkpointing`
- `layers`
- `resblocks`
- `width`

### æ–¹æ³• (Methods)
- `__init__(self, width: int, layers: int, heads: int, mlp_ratio: float, ls_init_value: float, act_layer: Callable, norm_layer: Callable, xattn: bool)`
- `forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor])`
- `get_cast_dtype(self) -> torch.dtype`

---

## Class: `ValueHead`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `modeling_value_head`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `dropout`
- `flatten`
- `summary`

### æ–¹æ³• (Methods)
- `__init__(self, config, **kwargs)`
- `forward(self, hidden_states)`

---

## Class: `VisionRotaryEmbedding`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `rope`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### æ–¹æ³• (Methods)
- `__init__(self, dim, pt_seq_len, ft_seq_len, custom_freqs, freqs_for, theta, max_freq, num_freqs)`
- `__init__(self, dim: int, theta: float) -> None`
- `forward(self, seqlen: int) -> torch.Tensor`
- `forward(self, t, start_index)`

---

## Class: `VisionRotaryEmbeddingFast`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `rope`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`, `nn.Module`

### å±æ€§ (Attributes)
- `patch_dropout`

### æ–¹æ³• (Methods)
- `__init__(self, dim, pt_seq_len, ft_seq_len, custom_freqs, freqs_for, theta, max_freq, num_freqs, patch_dropout)`
- `forward(self, t, patch_indices_keep)`

---

## Class: `VisionTransformer`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `transformer`

### ç»§æ‰¿å…³ç³» (Inheritance)
- ç»§æ‰¿è‡ª (Inherits from): `nn.Module`

### å±æ€§ (Attributes)
- `class_embedding`
- `conv1`
- `global_average_pool`
- `grid_size`
- `image_size`
- `ln_post`
- `ln_pre`
- `output_dim`
- `patch_dropout`
- `patch_size`
- `positional_embedding`
- `proj`
- `transformer`

### æ–¹æ³• (Methods)
- `__init__(self, image_size: int, patch_size: int, width: int, layers: int, heads: int, mlp_ratio: float, ls_init_value: float, patch_dropout: float, global_average_pool: bool, output_dim: int, act_layer: Callable, norm_layer: Callable, xattn: bool)`
- `forward(self, x: torch.Tensor, return_all_features: bool)`
- `get_num_layers(self)`
- `lock(self, unlocked_groups, freeze_bn_stats)`
- `no_weight_decay(self)`
- `set_grad_checkpointing(self, enable)`

---

## Class: `WorkerInfo`

- **è¯­è¨€ (Language):** python
- **æ¨¡å—/æ–‡ä»¶ (Module/File):** `controller`

### å±æ€§ (Attributes)
- `check_heart_beat: bool`
- `last_heart_beat: str`
- `model_names: List[str]`
- `queue_length: int`
- `speed: int`

---


[ä¿¡æ¯] UML å›¾è¡¨ 'uml_diagram.png' ä¹Ÿå·²é€šè¿‡ WebSocket ç›´æ¥å‘é€ã€‚
2025-06-08 17:24:45.870 | INFO     | agents.umlagent:update_plan_status:153 - Marked step 3 as completed in plan plan_1749374619
2025-06-08 17:24:45.870 | INFO     | agents.base:run:133 - Executing step 10/20
2025-06-08 17:25:02.347 | INFO     | agents.tool_call:think:64 - âœ¨ uml agnet çš„æƒ³æ³•ä¸º: Using tools response: Using tools response: å·²æˆåŠŸç”ŸæˆLLaVA-NeXTé¡¹ç›®çš„UMLç±»å›¾ï¼Œå¹¶å®Œæˆäº†å¯¹é¡¹ç›®çš„æ€»ç»“åˆ†æã€‚ç°åœ¨å¯ä»¥ç»“æŸä»»åŠ¡äº†ã€‚

![](D:\deep_learning\codes\umlagent\app\workspace\tmp_codes\LLaVA-NeXT\uml_diagram.png)
2025-06-08 17:25:02.348 | INFO     | agents.tool_call:think:66 - ğŸ› ï¸ uml agnet é€‰æ‹©äº† 1 ä¸ªå·¥å…·
2025-06-08 17:25:02.348 | INFO     | agents.tool_call:think:71 - ğŸ§° é€‰æ‹©çš„å·¥å…·ä¿¡æ¯: ['terminate']
2025-06-08 17:25:02.348 | INFO     | agents.tool_call:think:89 - ğŸ§° å·¥å…·çš„å‚æ•°æ˜¯: ['{"status": "success"}']
2025-06-08 17:25:02.348 | INFO     | agents.tool_call:_handle_special_tool:210 - ğŸ Special tool 'terminate' has completed the task!
2025-06-08 17:25:02.349 | INFO     | agents.tool_call:act:142 - ğŸ¯ å·¥å…· 'terminate' å®Œæˆäº†å®ƒçš„ä»»åŠ¡! å…¶æ‰§è¡Œç»“æœä¸º:  `å·¥å…·:terminate`çš„è§‚æµ‹ç»“æœè¾“å‡ºä¸º :
The interaction has been completed with status: success
2025-06-08 17:26:52.958 | INFO     | main:websocket_endpoint:65 - WebSocket connection disconnected from 127.0.0.1:54437
2025-06-08 17:26:52.958 | INFO     | main:websocket_endpoint:72 - Cleaned up resources for 127.0.0.1:54437
